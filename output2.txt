using world size: 1, data-parallel size: 1, context-parallel size: 1, hierarchical context-parallel sizes: Nonetensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0
Number of virtual stages per pipeline stage: None
using torch.float32 for parameters ...
------------------------ arguments ------------------------
  account_for_embedding_in_pipeline_split ......... False
  account_for_loss_in_pipeline_split .............. False
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.95
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... True
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  align_grad_reduce ............................... True
  align_param_gather .............................. False
  app_tag_run_name ................................ None
  app_tag_run_version ............................. 0.0.0
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... False
  async_save ...................................... None
  async_tensor_model_parallel_allreduce ........... True
  attention_backend ............................... AttnBackend.auto
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  calc_ft_timeouts ................................ False
  calculate_per_token_loss ........................ False
  check_for_large_grads ........................... False
  check_for_nan_in_loss_and_grad .................. True
  check_for_spiky_loss ............................ False
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_assume_constant_structure .................. False
  ckpt_convert_format ............................. None
  ckpt_convert_save ............................... None
  ckpt_convert_update_legacy_dist_opt_format ...... False
  ckpt_format ..................................... torch_dist
  ckpt_fully_parallel_load ........................ False
  ckpt_fully_parallel_save ........................ True
  ckpt_fully_parallel_save_deprecated ............. False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  config_logger_dir ............................... 
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  cp_comm_type .................................... ['p2p']
  create_attention_mask_in_dataloader ............. True
  cross_entropy_fusion_impl ....................... native
  cross_entropy_loss_fusion ....................... False
  cuda_graph_scope ................................ full
  cuda_graph_warmup_steps ......................... 3
  data_args_path .................................. None
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_sharding_strategy ................. no_shard
  data_parallel_size .............................. 1
  data_path ....................................... ['/users/jimmys2/meg-gpt2_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_average_in_collective ....................... False
  ddp_bucket_size ................................. None
  ddp_num_buckets ................................. None
  ddp_pad_buckets_for_high_nccl_busbw ............. False
  decoder_first_pipeline_num_layers ............... None
  decoder_last_pipeline_num_layers ................ None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  decrease_batch_size_if_needed ................... False
  defer_embedding_wgrad_compute ................... False
  deprecated_use_mcore_models ..................... False
  deterministic_mode .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_bf16_reduced_precision_matmul ........... False
  disable_mamba_mem_eff_path ...................... False
  disable_straggler_on_startup .................... False
  dist_ckpt_format_deprecated ..................... None
  dist_ckpt_strictness ............................ assume_ok_unexpected
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_cuda_graph ............................... False
  enable_experimental ............................. False
  enable_ft_package ............................... False
  enable_gloo_process_groups ...................... True
  enable_msc ...................................... True
  enable_one_logger ............................... True
  encoder_num_layers .............................. 1
  encoder_pipeline_model_parallel_size ............ 0
  encoder_seq_length .............................. 256
  encoder_tensor_model_parallel_size .............. 0
  end_weight_decay ................................ 0.1
  eod_mask_loss ................................... False
  error_injection_rate ............................ 0
  error_injection_type ............................ transient_error
  eval_interval ................................... 1000
  eval_iters ...................................... 40
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  exp_avg_dtype ................................... torch.float32
  exp_avg_sq_dtype ................................ torch.float32
  expert_model_parallel_size ...................... 1
  expert_tensor_parallel_size ..................... 1
  external_cuda_graph ............................. False
  ffn_hidden_size ................................. 2048
  finetune ........................................ False
  first_last_layers_bf16 .......................... False
  flash_decode .................................... False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_param_gather ................................ False
  fp8_recipe ...................................... delayed
  fp8_wgrad ....................................... True
  fsdp_double_buffer .............................. False
  global_batch_size ............................... 64
  grad_reduce_in_bf16 ............................. False
  gradient_accumulation_fusion .................... True
  gradient_reduce_div_fusion ...................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  heterogeneous_layers_config_encoded_json ........ None
  heterogeneous_layers_config_path ................ None
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 512
  hierarchical_context_parallel_sizes ............. None
  high_priority_stream_groups ..................... []
  hybrid_attention_ratio .......................... 0.0
  hybrid_mlp_ratio ................................ 0.0
  hybrid_override_pattern ......................... None
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... -1
  inference_dynamic_batching ...................... False
  inference_dynamic_batching_buffer_guaranteed_fraction  0.2
  inference_dynamic_batching_buffer_overflow_factor  None
  inference_dynamic_batching_buffer_size_gb ....... 40.0
  inference_dynamic_batching_chunk_size ........... 256
  inference_dynamic_batching_max_requests_override  None
  inference_dynamic_batching_max_tokens_override .. None
  inference_max_batch_size ........................ 8
  inference_max_seq_length ........................ 2560
  inference_rng_tracker ........................... False
  init_method_std ................................. 0.006
  init_method_xavier_uniform ...................... False
  init_model_with_meta_device ..................... False
  initial_loss_scale .............................. 4294967296
  inprocess_active_world_size ..................... 1
  inprocess_barrier_timeout ....................... 120
  inprocess_completion_timeout .................... 120
  inprocess_empty_cuda_cache ...................... False
  inprocess_granularity ........................... node
  inprocess_hard_timeout .......................... 90
  inprocess_heartbeat_interval .................... 30
  inprocess_heartbeat_timeout ..................... 60
  inprocess_last_call_wait ........................ 1
  inprocess_max_iterations ........................ None
  inprocess_monitor_process_interval .............. 1.0
  inprocess_monitor_thread_interval ............... 1.0
  inprocess_progress_watchdog_interval ............ 1.0
  inprocess_restart ............................... False
  inprocess_soft_timeout .......................... 60
  inprocess_termination_grace_time ................ 1
  is_hybrid_model ................................. False
  iter_per_epoch .................................. 1250
  iterations_to_skip .............................. []
  keep_fp8_transpose_cache_when_using_custom_fsdp . False
  kv_channels ..................................... 64
  kv_lora_rank .................................... 32
  lazy_mpu_init ................................... None
  load ............................................ /users/jimmys2/ckpt
  load_model_opt_format ........................... False
  local_rank ...................................... 0
  log_interval .................................... 1
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  logging_level ................................... None
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 6e-05
  lr_decay_iters .................................. 860
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  lr_wsd_decay_iters .............................. None
  lr_wsd_decay_samples ............................ None
  lr_wsd_decay_style .............................. exponential
  main_grads_dtype ................................ torch.float32
  main_params_dtype ............................... torch.float32
  make_vocab_size_divisible_by .................... 128
  mamba_head_dim .................................. 64
  mamba_num_groups ................................ 8
  mamba_num_heads ................................. None
  mamba_state_dim ................................. 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  max_tokens_to_oom ............................... 12000
  memory_snapshot_path ............................ snapshot.pickle
  merge_file ...................................... /users/jimmys2/oscar/gpt2-merges.txt
  micro_batch_size ................................ 4
  microbatch_group_size_per_vp_stage .............. None
  mid_level_dataset_surplus ....................... 0.005
  min_loss_scale .................................. 1.0
  min_lr .......................................... 6e-06
  mlp_chunks_for_prefill .......................... 1
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_apply_probs_on_input ........................ False
  moe_aux_loss_coeff .............................. 0.0
  moe_enable_deepep ............................... False
  moe_expert_capacity_factor ...................... None
  moe_extended_tp ................................. False
  moe_ffn_hidden_size ............................. None
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_layer_freq .................................. 1
  moe_layer_recompute ............................. False
  moe_pad_expert_input_to_capacity ................ False
  moe_per_layer_logging ........................... False
  moe_permute_fusion .............................. False
  moe_router_bias_update_rate ..................... 0.001
  moe_router_dtype ................................ None
  moe_router_enable_expert_bias ................... False
  moe_router_force_load_balancing ................. False
  moe_router_group_topk ........................... None
  moe_router_load_balancing_type .................. aux_loss
  moe_router_num_groups ........................... None
  moe_router_padding_for_fp8 ...................... False
  moe_router_pre_softmax .......................... False
  moe_router_score_function ....................... softmax
  moe_router_topk ................................. 2
  moe_router_topk_scaling_factor .................. None
  moe_shared_expert_intermediate_size ............. None
  moe_shared_expert_overlap ....................... False
  moe_token_dispatcher_type ....................... allgather
  moe_token_drop_policy ........................... probs
  moe_use_legacy_grouped_gemm ..................... False
  moe_use_upcycling ............................... False
  moe_z_loss_coeff ................................ None
  mrope_section ................................... None
  mscale .......................................... 1.0
  mscale_all_dim .................................. 1.0
  mtp_loss_scaling_factor ......................... 0.1
  mtp_num_layers .................................. None
  multi_latent_attention .......................... False
  nccl_all_reduce_for_prefill ..................... False
  nccl_communicator_config_path ................... None
  nccl_ub ......................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_rope_freq .................................... None
  no_save_optim ................................... None
  no_save_rng ..................................... None
  non_persistent_ckpt_type ........................ None
  non_persistent_global_ckpt_dir .................. None
  non_persistent_local_ckpt_algo .................. fully_parallel
  non_persistent_local_ckpt_dir ................... None
  non_persistent_save_interval .................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  num_attention_heads ............................. 8
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_dataset_builder_threads ..................... 1
  num_distributed_optimizer_instances ............. 1
  num_experts ..................................... None
  num_layers ...................................... 1
  num_layers_at_end_in_bf16 ....................... 1
  num_layers_at_start_in_bf16 ..................... 1
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_virtual_stages_per_pipeline_rank ............ None
  num_workers ..................................... 2
  object_storage_cache_path ....................... None
  one_logger_async ................................ False
  one_logger_project .............................. megatron-lm
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  optimizer_cpu_offload ........................... False
  optimizer_offload_fraction ...................... 1.0
  output_bert_embeddings .......................... False
  overlap_cpu_optimizer_d2h_h2d ................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_p2p_comm_warmup_flush ................... False
  overlap_param_gather ............................ False
  overlap_param_gather_with_optimizer_step ........ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float32
  patch_dim ....................................... 16
  per_split_data_args_path ........................ None
  perform_initialization .......................... True
  pin_cpu_grads ................................... True
  pin_cpu_params .................................. True
  pipeline_model_parallel_comm_backend ............ None
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  q_lora_rank ..................................... None
  qk_head_dim ..................................... 128
  qk_l2_norm ...................................... False
  qk_layernorm .................................... False
  qk_pos_emb_head_dim ............................. 64
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_modules ............................... None
  recompute_num_layers ............................ None
  record_memory_history ........................... False
  relative_attention_max_distance ................. 128
  relative_attention_num_buckets .................. 32
  replication ..................................... False
  replication_factor .............................. 2
  replication_jump ................................ None
  rerun_mode ...................................... disabled
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  result_rejected_tracker_filename ................ None
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rope_scaling_factor ............................. 8.0
  rotary_base ..................................... 10000
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_scaling_factor ........................... 1.0
  rotary_seq_len_interpolation_factor ............. None
  run_workload_inspector_server ................... False
  sample_rate ..................................... 1.0
  save ............................................ /users/jimmys2/ckpt
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 256
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  skipped_train_samples ........................... 0
  spec ............................................ None
  split ........................................... 98,2,0
  squared_relu .................................... False
  start_weight_decay .............................. 0.1
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  suggested_communication_unit_size ............... None
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  symmetric_ar_type ............................... None
  te_rng_tracker .................................. False
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. /users/jimmys2/tensorboard
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  tiktoken_num_special_tokens ..................... 1000
  tiktoken_pattern ................................ None
  tiktoken_special_tokens ......................... None
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  torch_fsdp2_reshard_after_forward ............... True
  tp_comm_bootstrap_backend ....................... nccl
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  train_data_path ................................. None
  train_iters ..................................... 1000
  train_samples ................................... None
  train_sync_interval ............................. None
  transformer_impl ................................ local
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_custom_fsdp ................................. False
  use_dist_ckpt ................................... True
  use_dist_ckpt_deprecated ........................ False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_legacy_models ............................... False
  use_mp_args_from_checkpoint_args ................ False
  use_one_sent_docs ............................... False
  use_persistent_ckpt_worker ...................... False
  use_precision_aware_optimizer ................... False
  use_pytorch_profiler ............................ False
  use_ring_exchange_p2p ........................... False
  use_rope_scaling ................................ False
  use_rotary_position_embeddings .................. False
  use_sharp ....................................... False
  use_tokenizer_model_from_checkpoint_args ........ True
  use_torch_fsdp2 ................................. False
  use_torch_optimizer_for_cpu_offload ............. False
  use_tp_pp_dp_mapping ............................ False
  v_head_dim ...................................... 128
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /users/jimmys2/oscar/gpt2-vocab.json
  vocab_size ...................................... None
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.1
  weight_decay_incr_style ......................... constant
  wgrad_deferral_limit ............................ 0
  world_size ...................................... 1
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
INFO:megatron.core.num_microbatches_calculator:setting number of microbatches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
WARNING: TensorBoard writing requested but is not available (are you using PyTorch 1.1.0 or later?), no TensorBoard logs will be written.
WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it
WARNING:megatron.core.rerun_state_machine:RerunStateMachine initialized in mode RerunMode.DISABLED
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/users/jimmys2/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/users/jimmys2/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.138 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
>>> done with compiling and loading fused kernels. Compilation time: 0.361 seconds
time to initialize megatron (seconds): 0.750
[after megatron is initialized] datetime: 2025-06-16 07:58:42 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 29433344
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, pad_buckets_for_high_nccl_busbw=False, average_in_collective=False, fp8_param_gather=False, use_custom_fsdp=False, data_parallel_sharding_strategy='no_shard', gradient_reduce_div_fusion=True, suggested_communication_unit_size=None, preserve_fp32_weights=True, keep_fp8_transpose_cache_when_using_custom_fsdp=False, nccl_ub=False, fsdp_double_buffer=False)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
Params for bucket 1 (29433344 elements, 29433344 padded size):
	decoder.layers.0.self_attention.linear_proj.weight
	embedding.position_embeddings.weight
	decoder.layers.0.input_layernorm.weight
	decoder.layers.0.input_layernorm.bias
	decoder.layers.0.self_attention.linear_proj.bias
	decoder.final_layernorm.bias
	decoder.final_layernorm.weight
	decoder.layers.0.mlp.linear_fc2.bias
	decoder.layers.0.mlp.linear_fc2.weight
	decoder.layers.0.mlp.linear_fc1.bias
	decoder.layers.0.mlp.linear_fc1.weight
	decoder.layers.0.pre_mlp_layernorm.bias
	decoder.layers.0.pre_mlp_layernorm.weight
	decoder.layers.0.self_attention.linear_qkv.bias
	decoder.layers.0.self_attention.linear_qkv.weight
	embedding.word_embeddings.weight
INFO:megatron.core.optimizer:Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=6e-05, min_lr=6e-06, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.1, fp16=False, bf16=False, params_dtype=torch.float32, use_precision_aware_optimizer=False, store_param_remainders=True, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=1.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f4909538450>, config_logger_dir='')
INFO:megatron.core.optimizer_param_scheduler:> learning rate decay style: cosine
WARNING: could not find the metadata file /users/jimmys2/ckpt/latest_checkpointed_iteration.txt
    will not load any checkpoints and will start from random
(min, max) time across ranks (ms):
    load-checkpoint ................................: (0.33, 0.33)
[after model, optimizer, and learning rate scheduler are built] datetime: 2025-06-16 07:58:42 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      64000
    validation: 5120
    test:       2560
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.98), (0.98, 1.0), None]
> building train, validation, and test datasets for GPT ...
INFO:megatron.core.datasets.blended_megatron_dataset_builder:Building GPTDataset splits with sizes=(64000, 5120, 2560) and config=GPTDatasetConfig(random_seed=1234, sequence_length=256, blend=(['/users/jimmys2/meg-gpt2_text_document'], None), blend_per_split=None, split='98,2,0', split_matrix=[(0, 0.98), (0.98, 1.0), None], num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f490a63d0d0>, mid_level_dataset_surplus=0.005, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, object_storage_cache_path=None)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /users/jimmys2/meg-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from adf57b594c7b8e0217de8b32c8caceca-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from adf57b594c7b8e0217de8b32c8caceca-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from adf57b594c7b8e0217de8b32c8caceca-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 895423
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from b302b16c0fabe4c75cb6c6a364e4bd9a-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from b302b16c0fabe4c75cb6c6a364e4bd9a-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from b302b16c0fabe4c75cb6c6a364e4bd9a-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 19964
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2025-06-16 07:58:42 
done with setup ...
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (88.54, 88.54)
    train/valid/test-data-iterators-setup ..........: (109.04, 109.04)
training ...
Setting rerun_state_machine.current_iteration to 0...
[before the start of training step] datetime: 2025-06-16 07:58:42 
 [2025-06-16 07:58:43] iteration        1/    1000 | consumed samples:           64 | elapsed time per iteration (ms): 1067.8 | learning rate: 6.976744E-06 | global batch size:    64 | lm loss: 1.083304E+01 | loss scale: 1.0 | grad norm: 1.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
Number of parameters in transformer block in billions:  0.00
Number of parameters in embedding layers in billions: 0.03
Total number of parameters in billions: 0.03
Number of parameters in most loaded shard in billions: 0.0289
Theoretical memory footprints: weight and optimizer=496.18 MB
[Rank 0] (after 1 iterations) memory (MB) | allocated: 474.2451171875 | max allocated: 602.3525390625 | reserved: 656.0 | max reserved: 656.0
 [2025-06-16 07:58:44] iteration        2/    1000 | consumed samples:          128 | elapsed time per iteration (ms): 588.1 | learning rate: 1.395349E-05 | global batch size:    64 | lm loss: 1.083330E+01 | loss scale: 1.0 | grad norm: 1.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:44] iteration        3/    1000 | consumed samples:          192 | elapsed time per iteration (ms): 575.5 | learning rate: 2.093023E-05 | global batch size:    64 | lm loss: 1.082773E+01 | loss scale: 1.0 | grad norm: 1.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:45] iteration        4/    1000 | consumed samples:          256 | elapsed time per iteration (ms): 573.1 | learning rate: 2.790698E-05 | global batch size:    64 | lm loss: 1.082116E+01 | loss scale: 1.0 | grad norm: 1.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:45] iteration        5/    1000 | consumed samples:          320 | elapsed time per iteration (ms): 577.7 | learning rate: 3.488372E-05 | global batch size:    64 | lm loss: 1.080355E+01 | loss scale: 1.0 | grad norm: 1.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:46] iteration        6/    1000 | consumed samples:          384 | elapsed time per iteration (ms): 576.5 | learning rate: 4.186046E-05 | global batch size:    64 | lm loss: 1.078428E+01 | loss scale: 1.0 | grad norm: 1.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:46] iteration        7/    1000 | consumed samples:          448 | elapsed time per iteration (ms): 573.9 | learning rate: 4.883721E-05 | global batch size:    64 | lm loss: 1.075549E+01 | loss scale: 1.0 | grad norm: 1.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:47] iteration        8/    1000 | consumed samples:          512 | elapsed time per iteration (ms): 575.5 | learning rate: 5.581395E-05 | global batch size:    64 | lm loss: 1.071652E+01 | loss scale: 1.0 | grad norm: 2.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:48] iteration        9/    1000 | consumed samples:          576 | elapsed time per iteration (ms): 576.4 | learning rate: 5.999997E-05 | global batch size:    64 | lm loss: 1.067479E+01 | loss scale: 1.0 | grad norm: 2.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:48] iteration       10/    1000 | consumed samples:          640 | elapsed time per iteration (ms): 573.3 | learning rate: 5.999964E-05 | global batch size:    64 | lm loss: 1.060803E+01 | loss scale: 1.0 | grad norm: 2.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:49] iteration       11/    1000 | consumed samples:          704 | elapsed time per iteration (ms): 574.4 | learning rate: 5.999894E-05 | global batch size:    64 | lm loss: 1.056627E+01 | loss scale: 1.0 | grad norm: 1.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:49] iteration       12/    1000 | consumed samples:          768 | elapsed time per iteration (ms): 581.5 | learning rate: 5.999787E-05 | global batch size:    64 | lm loss: 1.051462E+01 | loss scale: 1.0 | grad norm: 1.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:50] iteration       13/    1000 | consumed samples:          832 | elapsed time per iteration (ms): 576.2 | learning rate: 5.999644E-05 | global batch size:    64 | lm loss: 1.048705E+01 | loss scale: 1.0 | grad norm: 1.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:50] iteration       14/    1000 | consumed samples:          896 | elapsed time per iteration (ms): 576.1 | learning rate: 5.999464E-05 | global batch size:    64 | lm loss: 1.044493E+01 | loss scale: 1.0 | grad norm: 1.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:51] iteration       15/    1000 | consumed samples:          960 | elapsed time per iteration (ms): 573.0 | learning rate: 5.999247E-05 | global batch size:    64 | lm loss: 1.042346E+01 | loss scale: 1.0 | grad norm: 1.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:52] iteration       16/    1000 | consumed samples:         1024 | elapsed time per iteration (ms): 572.6 | learning rate: 5.998994E-05 | global batch size:    64 | lm loss: 1.039783E+01 | loss scale: 1.0 | grad norm: 1.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:52] iteration       17/    1000 | consumed samples:         1088 | elapsed time per iteration (ms): 574.5 | learning rate: 5.998703E-05 | global batch size:    64 | lm loss: 1.036879E+01 | loss scale: 1.0 | grad norm: 1.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:53] iteration       18/    1000 | consumed samples:         1152 | elapsed time per iteration (ms): 574.5 | learning rate: 5.998376E-05 | global batch size:    64 | lm loss: 1.033872E+01 | loss scale: 1.0 | grad norm: 1.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:53] iteration       19/    1000 | consumed samples:         1216 | elapsed time per iteration (ms): 576.2 | learning rate: 5.998012E-05 | global batch size:    64 | lm loss: 1.031340E+01 | loss scale: 1.0 | grad norm: 1.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:54] iteration       20/    1000 | consumed samples:         1280 | elapsed time per iteration (ms): 573.3 | learning rate: 5.997612E-05 | global batch size:    64 | lm loss: 1.028700E+01 | loss scale: 1.0 | grad norm: 1.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:54] iteration       21/    1000 | consumed samples:         1344 | elapsed time per iteration (ms): 572.4 | learning rate: 5.997174E-05 | global batch size:    64 | lm loss: 1.025614E+01 | loss scale: 1.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:55] iteration       22/    1000 | consumed samples:         1408 | elapsed time per iteration (ms): 575.7 | learning rate: 5.996700E-05 | global batch size:    64 | lm loss: 1.023746E+01 | loss scale: 1.0 | grad norm: 1.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:56] iteration       23/    1000 | consumed samples:         1472 | elapsed time per iteration (ms): 575.4 | learning rate: 5.996189E-05 | global batch size:    64 | lm loss: 1.018819E+01 | loss scale: 1.0 | grad norm: 1.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:56] iteration       24/    1000 | consumed samples:         1536 | elapsed time per iteration (ms): 577.5 | learning rate: 5.995642E-05 | global batch size:    64 | lm loss: 1.017372E+01 | loss scale: 1.0 | grad norm: 1.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:57] iteration       25/    1000 | consumed samples:         1600 | elapsed time per iteration (ms): 577.2 | learning rate: 5.995058E-05 | global batch size:    64 | lm loss: 1.012997E+01 | loss scale: 1.0 | grad norm: 1.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:57] iteration       26/    1000 | consumed samples:         1664 | elapsed time per iteration (ms): 575.7 | learning rate: 5.994437E-05 | global batch size:    64 | lm loss: 1.010085E+01 | loss scale: 1.0 | grad norm: 1.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:58] iteration       27/    1000 | consumed samples:         1728 | elapsed time per iteration (ms): 574.0 | learning rate: 5.993779E-05 | global batch size:    64 | lm loss: 1.007573E+01 | loss scale: 1.0 | grad norm: 1.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:58] iteration       28/    1000 | consumed samples:         1792 | elapsed time per iteration (ms): 572.2 | learning rate: 5.993085E-05 | global batch size:    64 | lm loss: 1.003759E+01 | loss scale: 1.0 | grad norm: 1.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:58:59] iteration       29/    1000 | consumed samples:         1856 | elapsed time per iteration (ms): 572.3 | learning rate: 5.992354E-05 | global batch size:    64 | lm loss: 1.001558E+01 | loss scale: 1.0 | grad norm: 1.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:00] iteration       30/    1000 | consumed samples:         1920 | elapsed time per iteration (ms): 572.3 | learning rate: 5.991587E-05 | global batch size:    64 | lm loss: 9.998425E+00 | loss scale: 1.0 | grad norm: 1.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:00] iteration       31/    1000 | consumed samples:         1984 | elapsed time per iteration (ms): 572.6 | learning rate: 5.990782E-05 | global batch size:    64 | lm loss: 9.951900E+00 | loss scale: 1.0 | grad norm: 1.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:01] iteration       32/    1000 | consumed samples:         2048 | elapsed time per iteration (ms): 574.9 | learning rate: 5.989942E-05 | global batch size:    64 | lm loss: 9.927305E+00 | loss scale: 1.0 | grad norm: 1.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:01] iteration       33/    1000 | consumed samples:         2112 | elapsed time per iteration (ms): 575.6 | learning rate: 5.989064E-05 | global batch size:    64 | lm loss: 9.892081E+00 | loss scale: 1.0 | grad norm: 1.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:02] iteration       34/    1000 | consumed samples:         2176 | elapsed time per iteration (ms): 576.4 | learning rate: 5.988150E-05 | global batch size:    64 | lm loss: 9.839650E+00 | loss scale: 1.0 | grad norm: 1.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:03] iteration       35/    1000 | consumed samples:         2240 | elapsed time per iteration (ms): 575.5 | learning rate: 5.987199E-05 | global batch size:    64 | lm loss: 9.845144E+00 | loss scale: 1.0 | grad norm: 1.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:03] iteration       36/    1000 | consumed samples:         2304 | elapsed time per iteration (ms): 575.6 | learning rate: 5.986212E-05 | global batch size:    64 | lm loss: 9.821671E+00 | loss scale: 1.0 | grad norm: 1.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:04] iteration       37/    1000 | consumed samples:         2368 | elapsed time per iteration (ms): 573.9 | learning rate: 5.985188E-05 | global batch size:    64 | lm loss: 9.776834E+00 | loss scale: 1.0 | grad norm: 1.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:04] iteration       38/    1000 | consumed samples:         2432 | elapsed time per iteration (ms): 574.4 | learning rate: 5.984128E-05 | global batch size:    64 | lm loss: 9.737392E+00 | loss scale: 1.0 | grad norm: 1.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:05] iteration       39/    1000 | consumed samples:         2496 | elapsed time per iteration (ms): 574.6 | learning rate: 5.983031E-05 | global batch size:    64 | lm loss: 9.714263E+00 | loss scale: 1.0 | grad norm: 1.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:05] iteration       40/    1000 | consumed samples:         2560 | elapsed time per iteration (ms): 576.8 | learning rate: 5.981898E-05 | global batch size:    64 | lm loss: 9.692879E+00 | loss scale: 1.0 | grad norm: 1.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:06] iteration       41/    1000 | consumed samples:         2624 | elapsed time per iteration (ms): 574.1 | learning rate: 5.980727E-05 | global batch size:    64 | lm loss: 9.684596E+00 | loss scale: 1.0 | grad norm: 1.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:07] iteration       42/    1000 | consumed samples:         2688 | elapsed time per iteration (ms): 572.0 | learning rate: 5.979521E-05 | global batch size:    64 | lm loss: 9.597437E+00 | loss scale: 1.0 | grad norm: 1.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:07] iteration       43/    1000 | consumed samples:         2752 | elapsed time per iteration (ms): 573.0 | learning rate: 5.978278E-05 | global batch size:    64 | lm loss: 9.609070E+00 | loss scale: 1.0 | grad norm: 1.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:08] iteration       44/    1000 | consumed samples:         2816 | elapsed time per iteration (ms): 572.1 | learning rate: 5.976999E-05 | global batch size:    64 | lm loss: 9.521665E+00 | loss scale: 1.0 | grad norm: 1.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:08] iteration       45/    1000 | consumed samples:         2880 | elapsed time per iteration (ms): 572.7 | learning rate: 5.975683E-05 | global batch size:    64 | lm loss: 9.563496E+00 | loss scale: 1.0 | grad norm: 1.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:09] iteration       46/    1000 | consumed samples:         2944 | elapsed time per iteration (ms): 574.4 | learning rate: 5.974330E-05 | global batch size:    64 | lm loss: 9.517279E+00 | loss scale: 1.0 | grad norm: 1.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:09] iteration       47/    1000 | consumed samples:         3008 | elapsed time per iteration (ms): 573.9 | learning rate: 5.972942E-05 | global batch size:    64 | lm loss: 9.487729E+00 | loss scale: 1.0 | grad norm: 1.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:10] iteration       48/    1000 | consumed samples:         3072 | elapsed time per iteration (ms): 576.0 | learning rate: 5.971517E-05 | global batch size:    64 | lm loss: 9.476898E+00 | loss scale: 1.0 | grad norm: 1.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:11] iteration       49/    1000 | consumed samples:         3136 | elapsed time per iteration (ms): 573.7 | learning rate: 5.970055E-05 | global batch size:    64 | lm loss: 9.416852E+00 | loss scale: 1.0 | grad norm: 1.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:11] iteration       50/    1000 | consumed samples:         3200 | elapsed time per iteration (ms): 574.1 | learning rate: 5.968557E-05 | global batch size:    64 | lm loss: 9.382631E+00 | loss scale: 1.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:12] iteration       51/    1000 | consumed samples:         3264 | elapsed time per iteration (ms): 575.2 | learning rate: 5.967023E-05 | global batch size:    64 | lm loss: 9.345813E+00 | loss scale: 1.0 | grad norm: 1.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:12] iteration       52/    1000 | consumed samples:         3328 | elapsed time per iteration (ms): 575.9 | learning rate: 5.965453E-05 | global batch size:    64 | lm loss: 9.345997E+00 | loss scale: 1.0 | grad norm: 1.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:13] iteration       53/    1000 | consumed samples:         3392 | elapsed time per iteration (ms): 573.7 | learning rate: 5.963846E-05 | global batch size:    64 | lm loss: 9.340117E+00 | loss scale: 1.0 | grad norm: 1.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:13] iteration       54/    1000 | consumed samples:         3456 | elapsed time per iteration (ms): 572.1 | learning rate: 5.962203E-05 | global batch size:    64 | lm loss: 9.282445E+00 | loss scale: 1.0 | grad norm: 1.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:14] iteration       55/    1000 | consumed samples:         3520 | elapsed time per iteration (ms): 572.4 | learning rate: 5.960523E-05 | global batch size:    64 | lm loss: 9.247032E+00 | loss scale: 1.0 | grad norm: 1.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:15] iteration       56/    1000 | consumed samples:         3584 | elapsed time per iteration (ms): 574.3 | learning rate: 5.958808E-05 | global batch size:    64 | lm loss: 9.228395E+00 | loss scale: 1.0 | grad norm: 1.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:15] iteration       57/    1000 | consumed samples:         3648 | elapsed time per iteration (ms): 573.2 | learning rate: 5.957056E-05 | global batch size:    64 | lm loss: 9.190282E+00 | loss scale: 1.0 | grad norm: 1.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:16] iteration       58/    1000 | consumed samples:         3712 | elapsed time per iteration (ms): 574.2 | learning rate: 5.955268E-05 | global batch size:    64 | lm loss: 9.158806E+00 | loss scale: 1.0 | grad norm: 1.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:16] iteration       59/    1000 | consumed samples:         3776 | elapsed time per iteration (ms): 574.7 | learning rate: 5.953444E-05 | global batch size:    64 | lm loss: 9.197199E+00 | loss scale: 1.0 | grad norm: 1.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:17] iteration       60/    1000 | consumed samples:         3840 | elapsed time per iteration (ms): 575.6 | learning rate: 5.951584E-05 | global batch size:    64 | lm loss: 9.117296E+00 | loss scale: 1.0 | grad norm: 1.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:17] iteration       61/    1000 | consumed samples:         3904 | elapsed time per iteration (ms): 575.4 | learning rate: 5.949688E-05 | global batch size:    64 | lm loss: 9.084952E+00 | loss scale: 1.0 | grad norm: 1.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:18] iteration       62/    1000 | consumed samples:         3968 | elapsed time per iteration (ms): 575.5 | learning rate: 5.947755E-05 | global batch size:    64 | lm loss: 9.098591E+00 | loss scale: 1.0 | grad norm: 1.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:19] iteration       63/    1000 | consumed samples:         4032 | elapsed time per iteration (ms): 574.3 | learning rate: 5.945787E-05 | global batch size:    64 | lm loss: 9.065295E+00 | loss scale: 1.0 | grad norm: 1.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:19] iteration       64/    1000 | consumed samples:         4096 | elapsed time per iteration (ms): 574.3 | learning rate: 5.943782E-05 | global batch size:    64 | lm loss: 9.019298E+00 | loss scale: 1.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:20] iteration       65/    1000 | consumed samples:         4160 | elapsed time per iteration (ms): 574.3 | learning rate: 5.941742E-05 | global batch size:    64 | lm loss: 9.036554E+00 | loss scale: 1.0 | grad norm: 1.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:20] iteration       66/    1000 | consumed samples:         4224 | elapsed time per iteration (ms): 575.4 | learning rate: 5.939665E-05 | global batch size:    64 | lm loss: 8.990969E+00 | loss scale: 1.0 | grad norm: 1.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:21] iteration       67/    1000 | consumed samples:         4288 | elapsed time per iteration (ms): 574.7 | learning rate: 5.937553E-05 | global batch size:    64 | lm loss: 8.938916E+00 | loss scale: 1.0 | grad norm: 1.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:21] iteration       68/    1000 | consumed samples:         4352 | elapsed time per iteration (ms): 572.7 | learning rate: 5.935405E-05 | global batch size:    64 | lm loss: 8.903219E+00 | loss scale: 1.0 | grad norm: 1.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:22] iteration       69/    1000 | consumed samples:         4416 | elapsed time per iteration (ms): 571.8 | learning rate: 5.933221E-05 | global batch size:    64 | lm loss: 8.960495E+00 | loss scale: 1.0 | grad norm: 1.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:23] iteration       70/    1000 | consumed samples:         4480 | elapsed time per iteration (ms): 572.1 | learning rate: 5.931001E-05 | global batch size:    64 | lm loss: 8.880134E+00 | loss scale: 1.0 | grad norm: 1.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:23] iteration       71/    1000 | consumed samples:         4544 | elapsed time per iteration (ms): 574.7 | learning rate: 5.928745E-05 | global batch size:    64 | lm loss: 8.940172E+00 | loss scale: 1.0 | grad norm: 1.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:24] iteration       72/    1000 | consumed samples:         4608 | elapsed time per iteration (ms): 575.4 | learning rate: 5.926453E-05 | global batch size:    64 | lm loss: 8.843051E+00 | loss scale: 1.0 | grad norm: 3.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:24] iteration       73/    1000 | consumed samples:         4672 | elapsed time per iteration (ms): 576.7 | learning rate: 5.924126E-05 | global batch size:    64 | lm loss: 8.952997E+00 | loss scale: 1.0 | grad norm: 1.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:25] iteration       74/    1000 | consumed samples:         4736 | elapsed time per iteration (ms): 573.1 | learning rate: 5.921763E-05 | global batch size:    64 | lm loss: 8.844209E+00 | loss scale: 1.0 | grad norm: 1.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:25] iteration       75/    1000 | consumed samples:         4800 | elapsed time per iteration (ms): 573.1 | learning rate: 5.919364E-05 | global batch size:    64 | lm loss: 8.773966E+00 | loss scale: 1.0 | grad norm: 1.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:26] iteration       76/    1000 | consumed samples:         4864 | elapsed time per iteration (ms): 573.1 | learning rate: 5.916930E-05 | global batch size:    64 | lm loss: 8.788147E+00 | loss scale: 1.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:27] iteration       77/    1000 | consumed samples:         4928 | elapsed time per iteration (ms): 574.0 | learning rate: 5.914459E-05 | global batch size:    64 | lm loss: 8.765889E+00 | loss scale: 1.0 | grad norm: 1.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:27] iteration       78/    1000 | consumed samples:         4992 | elapsed time per iteration (ms): 579.8 | learning rate: 5.911954E-05 | global batch size:    64 | lm loss: 8.690145E+00 | loss scale: 1.0 | grad norm: 1.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:28] iteration       79/    1000 | consumed samples:         5056 | elapsed time per iteration (ms): 574.8 | learning rate: 5.909413E-05 | global batch size:    64 | lm loss: 8.696629E+00 | loss scale: 1.0 | grad norm: 1.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:28] iteration       80/    1000 | consumed samples:         5120 | elapsed time per iteration (ms): 573.8 | learning rate: 5.906836E-05 | global batch size:    64 | lm loss: 8.648525E+00 | loss scale: 1.0 | grad norm: 1.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:29] iteration       81/    1000 | consumed samples:         5184 | elapsed time per iteration (ms): 575.1 | learning rate: 5.904224E-05 | global batch size:    64 | lm loss: 8.696000E+00 | loss scale: 1.0 | grad norm: 1.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:30] iteration       82/    1000 | consumed samples:         5248 | elapsed time per iteration (ms): 573.5 | learning rate: 5.901576E-05 | global batch size:    64 | lm loss: 8.687271E+00 | loss scale: 1.0 | grad norm: 1.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:30] iteration       83/    1000 | consumed samples:         5312 | elapsed time per iteration (ms): 572.1 | learning rate: 5.898893E-05 | global batch size:    64 | lm loss: 8.651207E+00 | loss scale: 1.0 | grad norm: 1.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:31] iteration       84/    1000 | consumed samples:         5376 | elapsed time per iteration (ms): 572.1 | learning rate: 5.896174E-05 | global batch size:    64 | lm loss: 8.620419E+00 | loss scale: 1.0 | grad norm: 1.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:31] iteration       85/    1000 | consumed samples:         5440 | elapsed time per iteration (ms): 571.8 | learning rate: 5.893420E-05 | global batch size:    64 | lm loss: 8.555182E+00 | loss scale: 1.0 | grad norm: 1.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:32] iteration       86/    1000 | consumed samples:         5504 | elapsed time per iteration (ms): 572.2 | learning rate: 5.890631E-05 | global batch size:    64 | lm loss: 8.575818E+00 | loss scale: 1.0 | grad norm: 1.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:32] iteration       87/    1000 | consumed samples:         5568 | elapsed time per iteration (ms): 578.2 | learning rate: 5.887806E-05 | global batch size:    64 | lm loss: 8.546076E+00 | loss scale: 1.0 | grad norm: 1.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:33] iteration       88/    1000 | consumed samples:         5632 | elapsed time per iteration (ms): 575.5 | learning rate: 5.884947E-05 | global batch size:    64 | lm loss: 8.516696E+00 | loss scale: 1.0 | grad norm: 1.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:34] iteration       89/    1000 | consumed samples:         5696 | elapsed time per iteration (ms): 572.9 | learning rate: 5.882052E-05 | global batch size:    64 | lm loss: 8.514518E+00 | loss scale: 1.0 | grad norm: 1.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:34] iteration       90/    1000 | consumed samples:         5760 | elapsed time per iteration (ms): 572.2 | learning rate: 5.879122E-05 | global batch size:    64 | lm loss: 8.583608E+00 | loss scale: 1.0 | grad norm: 1.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:35] iteration       91/    1000 | consumed samples:         5824 | elapsed time per iteration (ms): 572.5 | learning rate: 5.876157E-05 | global batch size:    64 | lm loss: 8.545493E+00 | loss scale: 1.0 | grad norm: 1.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:35] iteration       92/    1000 | consumed samples:         5888 | elapsed time per iteration (ms): 572.4 | learning rate: 5.873157E-05 | global batch size:    64 | lm loss: 8.423203E+00 | loss scale: 1.0 | grad norm: 1.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:36] iteration       93/    1000 | consumed samples:         5952 | elapsed time per iteration (ms): 572.5 | learning rate: 5.870121E-05 | global batch size:    64 | lm loss: 8.423222E+00 | loss scale: 1.0 | grad norm: 1.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:36] iteration       94/    1000 | consumed samples:         6016 | elapsed time per iteration (ms): 573.9 | learning rate: 5.867051E-05 | global batch size:    64 | lm loss: 8.417561E+00 | loss scale: 1.0 | grad norm: 1.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:37] iteration       95/    1000 | consumed samples:         6080 | elapsed time per iteration (ms): 572.4 | learning rate: 5.863946E-05 | global batch size:    64 | lm loss: 8.459480E+00 | loss scale: 1.0 | grad norm: 1.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:38] iteration       96/    1000 | consumed samples:         6144 | elapsed time per iteration (ms): 571.5 | learning rate: 5.860806E-05 | global batch size:    64 | lm loss: 8.438161E+00 | loss scale: 1.0 | grad norm: 1.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:38] iteration       97/    1000 | consumed samples:         6208 | elapsed time per iteration (ms): 571.6 | learning rate: 5.857630E-05 | global batch size:    64 | lm loss: 8.353364E+00 | loss scale: 1.0 | grad norm: 1.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:39] iteration       98/    1000 | consumed samples:         6272 | elapsed time per iteration (ms): 571.6 | learning rate: 5.854421E-05 | global batch size:    64 | lm loss: 8.390489E+00 | loss scale: 1.0 | grad norm: 1.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:39] iteration       99/    1000 | consumed samples:         6336 | elapsed time per iteration (ms): 572.9 | learning rate: 5.851176E-05 | global batch size:    64 | lm loss: 8.318955E+00 | loss scale: 1.0 | grad norm: 1.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:40] iteration      100/    1000 | consumed samples:         6400 | elapsed time per iteration (ms): 572.7 | learning rate: 5.847897E-05 | global batch size:    64 | lm loss: 8.336149E+00 | loss scale: 1.0 | grad norm: 1.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:40] iteration      101/    1000 | consumed samples:         6464 | elapsed time per iteration (ms): 571.3 | learning rate: 5.844583E-05 | global batch size:    64 | lm loss: 8.336145E+00 | loss scale: 1.0 | grad norm: 1.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:41] iteration      102/    1000 | consumed samples:         6528 | elapsed time per iteration (ms): 572.0 | learning rate: 5.841234E-05 | global batch size:    64 | lm loss: 8.246436E+00 | loss scale: 1.0 | grad norm: 1.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:42] iteration      103/    1000 | consumed samples:         6592 | elapsed time per iteration (ms): 572.2 | learning rate: 5.837851E-05 | global batch size:    64 | lm loss: 8.284790E+00 | loss scale: 1.0 | grad norm: 1.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:42] iteration      104/    1000 | consumed samples:         6656 | elapsed time per iteration (ms): 573.2 | learning rate: 5.834433E-05 | global batch size:    64 | lm loss: 8.321958E+00 | loss scale: 1.0 | grad norm: 1.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:43] iteration      105/    1000 | consumed samples:         6720 | elapsed time per iteration (ms): 572.1 | learning rate: 5.830981E-05 | global batch size:    64 | lm loss: 8.322073E+00 | loss scale: 1.0 | grad norm: 1.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:43] iteration      106/    1000 | consumed samples:         6784 | elapsed time per iteration (ms): 573.1 | learning rate: 5.827494E-05 | global batch size:    64 | lm loss: 8.255566E+00 | loss scale: 1.0 | grad norm: 1.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:44] iteration      107/    1000 | consumed samples:         6848 | elapsed time per iteration (ms): 571.9 | learning rate: 5.823973E-05 | global batch size:    64 | lm loss: 8.214089E+00 | loss scale: 1.0 | grad norm: 1.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:44] iteration      108/    1000 | consumed samples:         6912 | elapsed time per iteration (ms): 571.8 | learning rate: 5.820417E-05 | global batch size:    64 | lm loss: 8.322932E+00 | loss scale: 1.0 | grad norm: 1.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:45] iteration      109/    1000 | consumed samples:         6976 | elapsed time per iteration (ms): 572.3 | learning rate: 5.816827E-05 | global batch size:    64 | lm loss: 8.239985E+00 | loss scale: 1.0 | grad norm: 1.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:46] iteration      110/    1000 | consumed samples:         7040 | elapsed time per iteration (ms): 572.0 | learning rate: 5.813203E-05 | global batch size:    64 | lm loss: 8.307835E+00 | loss scale: 1.0 | grad norm: 1.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:46] iteration      111/    1000 | consumed samples:         7104 | elapsed time per iteration (ms): 572.3 | learning rate: 5.809545E-05 | global batch size:    64 | lm loss: 8.203623E+00 | loss scale: 1.0 | grad norm: 1.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:47] iteration      112/    1000 | consumed samples:         7168 | elapsed time per iteration (ms): 573.0 | learning rate: 5.805852E-05 | global batch size:    64 | lm loss: 8.121770E+00 | loss scale: 1.0 | grad norm: 1.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:47] iteration      113/    1000 | consumed samples:         7232 | elapsed time per iteration (ms): 571.9 | learning rate: 5.802125E-05 | global batch size:    64 | lm loss: 8.214334E+00 | loss scale: 1.0 | grad norm: 1.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:48] iteration      114/    1000 | consumed samples:         7296 | elapsed time per iteration (ms): 571.8 | learning rate: 5.798365E-05 | global batch size:    64 | lm loss: 8.104322E+00 | loss scale: 1.0 | grad norm: 1.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:48] iteration      115/    1000 | consumed samples:         7360 | elapsed time per iteration (ms): 571.9 | learning rate: 5.794570E-05 | global batch size:    64 | lm loss: 8.166730E+00 | loss scale: 1.0 | grad norm: 1.549 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:49] iteration      116/    1000 | consumed samples:         7424 | elapsed time per iteration (ms): 572.7 | learning rate: 5.790741E-05 | global batch size:    64 | lm loss: 8.018740E+00 | loss scale: 1.0 | grad norm: 1.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:50] iteration      117/    1000 | consumed samples:         7488 | elapsed time per iteration (ms): 572.5 | learning rate: 5.786879E-05 | global batch size:    64 | lm loss: 8.125555E+00 | loss scale: 1.0 | grad norm: 1.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:50] iteration      118/    1000 | consumed samples:         7552 | elapsed time per iteration (ms): 572.2 | learning rate: 5.782982E-05 | global batch size:    64 | lm loss: 8.096382E+00 | loss scale: 1.0 | grad norm: 1.586 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:51] iteration      119/    1000 | consumed samples:         7616 | elapsed time per iteration (ms): 573.0 | learning rate: 5.779052E-05 | global batch size:    64 | lm loss: 8.087505E+00 | loss scale: 1.0 | grad norm: 1.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:51] iteration      120/    1000 | consumed samples:         7680 | elapsed time per iteration (ms): 572.0 | learning rate: 5.775088E-05 | global batch size:    64 | lm loss: 8.067334E+00 | loss scale: 1.0 | grad norm: 1.575 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:52] iteration      121/    1000 | consumed samples:         7744 | elapsed time per iteration (ms): 572.2 | learning rate: 5.771090E-05 | global batch size:    64 | lm loss: 8.068745E+00 | loss scale: 1.0 | grad norm: 1.532 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:52] iteration      122/    1000 | consumed samples:         7808 | elapsed time per iteration (ms): 572.3 | learning rate: 5.767059E-05 | global batch size:    64 | lm loss: 8.086737E+00 | loss scale: 1.0 | grad norm: 1.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:53] iteration      123/    1000 | consumed samples:         7872 | elapsed time per iteration (ms): 572.1 | learning rate: 5.762994E-05 | global batch size:    64 | lm loss: 8.037698E+00 | loss scale: 1.0 | grad norm: 1.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:54] iteration      124/    1000 | consumed samples:         7936 | elapsed time per iteration (ms): 571.9 | learning rate: 5.758895E-05 | global batch size:    64 | lm loss: 8.017384E+00 | loss scale: 1.0 | grad norm: 1.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:54] iteration      125/    1000 | consumed samples:         8000 | elapsed time per iteration (ms): 573.1 | learning rate: 5.754763E-05 | global batch size:    64 | lm loss: 8.013348E+00 | loss scale: 1.0 | grad norm: 1.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:55] iteration      126/    1000 | consumed samples:         8064 | elapsed time per iteration (ms): 572.2 | learning rate: 5.750598E-05 | global batch size:    64 | lm loss: 8.032367E+00 | loss scale: 1.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:55] iteration      127/    1000 | consumed samples:         8128 | elapsed time per iteration (ms): 574.3 | learning rate: 5.746399E-05 | global batch size:    64 | lm loss: 8.031411E+00 | loss scale: 1.0 | grad norm: 1.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:56] iteration      128/    1000 | consumed samples:         8192 | elapsed time per iteration (ms): 571.9 | learning rate: 5.742167E-05 | global batch size:    64 | lm loss: 7.989677E+00 | loss scale: 1.0 | grad norm: 1.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:56] iteration      129/    1000 | consumed samples:         8256 | elapsed time per iteration (ms): 572.7 | learning rate: 5.737902E-05 | global batch size:    64 | lm loss: 7.962598E+00 | loss scale: 1.0 | grad norm: 1.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:57] iteration      130/    1000 | consumed samples:         8320 | elapsed time per iteration (ms): 571.1 | learning rate: 5.733603E-05 | global batch size:    64 | lm loss: 7.954435E+00 | loss scale: 1.0 | grad norm: 1.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:58] iteration      131/    1000 | consumed samples:         8384 | elapsed time per iteration (ms): 571.9 | learning rate: 5.729271E-05 | global batch size:    64 | lm loss: 7.933495E+00 | loss scale: 1.0 | grad norm: 1.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:58] iteration      132/    1000 | consumed samples:         8448 | elapsed time per iteration (ms): 572.8 | learning rate: 5.724907E-05 | global batch size:    64 | lm loss: 7.949561E+00 | loss scale: 1.0 | grad norm: 1.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:59] iteration      133/    1000 | consumed samples:         8512 | elapsed time per iteration (ms): 572.1 | learning rate: 5.720509E-05 | global batch size:    64 | lm loss: 7.863489E+00 | loss scale: 1.0 | grad norm: 1.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 07:59:59] iteration      134/    1000 | consumed samples:         8576 | elapsed time per iteration (ms): 572.8 | learning rate: 5.716078E-05 | global batch size:    64 | lm loss: 7.917139E+00 | loss scale: 1.0 | grad norm: 1.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:00] iteration      135/    1000 | consumed samples:         8640 | elapsed time per iteration (ms): 572.1 | learning rate: 5.711615E-05 | global batch size:    64 | lm loss: 7.951181E+00 | loss scale: 1.0 | grad norm: 1.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:00] iteration      136/    1000 | consumed samples:         8704 | elapsed time per iteration (ms): 571.9 | learning rate: 5.707118E-05 | global batch size:    64 | lm loss: 7.926891E+00 | loss scale: 1.0 | grad norm: 1.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:01] iteration      137/    1000 | consumed samples:         8768 | elapsed time per iteration (ms): 572.7 | learning rate: 5.702589E-05 | global batch size:    64 | lm loss: 7.893746E+00 | loss scale: 1.0 | grad norm: 1.390 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:02] iteration      138/    1000 | consumed samples:         8832 | elapsed time per iteration (ms): 573.1 | learning rate: 5.698027E-05 | global batch size:    64 | lm loss: 7.941154E+00 | loss scale: 1.0 | grad norm: 1.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:02] iteration      139/    1000 | consumed samples:         8896 | elapsed time per iteration (ms): 571.8 | learning rate: 5.693432E-05 | global batch size:    64 | lm loss: 7.934343E+00 | loss scale: 1.0 | grad norm: 1.359 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:03] iteration      140/    1000 | consumed samples:         8960 | elapsed time per iteration (ms): 571.5 | learning rate: 5.688805E-05 | global batch size:    64 | lm loss: 7.939887E+00 | loss scale: 1.0 | grad norm: 1.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:03] iteration      141/    1000 | consumed samples:         9024 | elapsed time per iteration (ms): 571.9 | learning rate: 5.684145E-05 | global batch size:    64 | lm loss: 7.982736E+00 | loss scale: 1.0 | grad norm: 1.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:04] iteration      142/    1000 | consumed samples:         9088 | elapsed time per iteration (ms): 572.4 | learning rate: 5.679454E-05 | global batch size:    64 | lm loss: 7.886754E+00 | loss scale: 1.0 | grad norm: 1.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:04] iteration      143/    1000 | consumed samples:         9152 | elapsed time per iteration (ms): 572.9 | learning rate: 5.674729E-05 | global batch size:    64 | lm loss: 7.800840E+00 | loss scale: 1.0 | grad norm: 1.343 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:05] iteration      144/    1000 | consumed samples:         9216 | elapsed time per iteration (ms): 572.2 | learning rate: 5.669972E-05 | global batch size:    64 | lm loss: 7.847180E+00 | loss scale: 1.0 | grad norm: 1.354 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:06] iteration      145/    1000 | consumed samples:         9280 | elapsed time per iteration (ms): 573.3 | learning rate: 5.665183E-05 | global batch size:    64 | lm loss: 7.855557E+00 | loss scale: 1.0 | grad norm: 1.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:06] iteration      146/    1000 | consumed samples:         9344 | elapsed time per iteration (ms): 571.8 | learning rate: 5.660361E-05 | global batch size:    64 | lm loss: 7.816354E+00 | loss scale: 1.0 | grad norm: 1.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:07] iteration      147/    1000 | consumed samples:         9408 | elapsed time per iteration (ms): 572.3 | learning rate: 5.655508E-05 | global batch size:    64 | lm loss: 7.938944E+00 | loss scale: 1.0 | grad norm: 1.271 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:07] iteration      148/    1000 | consumed samples:         9472 | elapsed time per iteration (ms): 573.4 | learning rate: 5.650623E-05 | global batch size:    64 | lm loss: 7.882336E+00 | loss scale: 1.0 | grad norm: 1.227 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:08] iteration      149/    1000 | consumed samples:         9536 | elapsed time per iteration (ms): 571.8 | learning rate: 5.645705E-05 | global batch size:    64 | lm loss: 7.809830E+00 | loss scale: 1.0 | grad norm: 1.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:08] iteration      150/    1000 | consumed samples:         9600 | elapsed time per iteration (ms): 571.4 | learning rate: 5.640755E-05 | global batch size:    64 | lm loss: 7.843364E+00 | loss scale: 1.0 | grad norm: 1.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:09] iteration      151/    1000 | consumed samples:         9664 | elapsed time per iteration (ms): 572.5 | learning rate: 5.635774E-05 | global batch size:    64 | lm loss: 7.794796E+00 | loss scale: 1.0 | grad norm: 1.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:10] iteration      152/    1000 | consumed samples:         9728 | elapsed time per iteration (ms): 572.6 | learning rate: 5.630761E-05 | global batch size:    64 | lm loss: 7.855505E+00 | loss scale: 1.0 | grad norm: 1.164 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:10] iteration      153/    1000 | consumed samples:         9792 | elapsed time per iteration (ms): 572.3 | learning rate: 5.625716E-05 | global batch size:    64 | lm loss: 7.805504E+00 | loss scale: 1.0 | grad norm: 1.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:11] iteration      154/    1000 | consumed samples:         9856 | elapsed time per iteration (ms): 572.7 | learning rate: 5.620639E-05 | global batch size:    64 | lm loss: 7.725643E+00 | loss scale: 1.0 | grad norm: 1.151 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:11] iteration      155/    1000 | consumed samples:         9920 | elapsed time per iteration (ms): 572.5 | learning rate: 5.615531E-05 | global batch size:    64 | lm loss: 7.711818E+00 | loss scale: 1.0 | grad norm: 1.183 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:12] iteration      156/    1000 | consumed samples:         9984 | elapsed time per iteration (ms): 572.1 | learning rate: 5.610391E-05 | global batch size:    64 | lm loss: 7.742424E+00 | loss scale: 1.0 | grad norm: 1.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:12] iteration      157/    1000 | consumed samples:        10048 | elapsed time per iteration (ms): 572.0 | learning rate: 5.605220E-05 | global batch size:    64 | lm loss: 7.783557E+00 | loss scale: 1.0 | grad norm: 1.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:13] iteration      158/    1000 | consumed samples:        10112 | elapsed time per iteration (ms): 572.9 | learning rate: 5.600018E-05 | global batch size:    64 | lm loss: 7.758935E+00 | loss scale: 1.0 | grad norm: 1.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:14] iteration      159/    1000 | consumed samples:        10176 | elapsed time per iteration (ms): 571.9 | learning rate: 5.594784E-05 | global batch size:    64 | lm loss: 7.706881E+00 | loss scale: 1.0 | grad norm: 1.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:14] iteration      160/    1000 | consumed samples:        10240 | elapsed time per iteration (ms): 572.7 | learning rate: 5.589519E-05 | global batch size:    64 | lm loss: 7.803375E+00 | loss scale: 1.0 | grad norm: 1.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:15] iteration      161/    1000 | consumed samples:        10304 | elapsed time per iteration (ms): 572.1 | learning rate: 5.584223E-05 | global batch size:    64 | lm loss: 7.714490E+00 | loss scale: 1.0 | grad norm: 1.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:15] iteration      162/    1000 | consumed samples:        10368 | elapsed time per iteration (ms): 572.7 | learning rate: 5.578895E-05 | global batch size:    64 | lm loss: 7.799275E+00 | loss scale: 1.0 | grad norm: 1.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:16] iteration      163/    1000 | consumed samples:        10432 | elapsed time per iteration (ms): 572.4 | learning rate: 5.573537E-05 | global batch size:    64 | lm loss: 7.708713E+00 | loss scale: 1.0 | grad norm: 1.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:16] iteration      164/    1000 | consumed samples:        10496 | elapsed time per iteration (ms): 572.0 | learning rate: 5.568147E-05 | global batch size:    64 | lm loss: 7.573939E+00 | loss scale: 1.0 | grad norm: 1.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:17] iteration      165/    1000 | consumed samples:        10560 | elapsed time per iteration (ms): 572.1 | learning rate: 5.562727E-05 | global batch size:    64 | lm loss: 7.706456E+00 | loss scale: 1.0 | grad norm: 1.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:18] iteration      166/    1000 | consumed samples:        10624 | elapsed time per iteration (ms): 572.2 | learning rate: 5.557276E-05 | global batch size:    64 | lm loss: 7.674857E+00 | loss scale: 1.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:18] iteration      167/    1000 | consumed samples:        10688 | elapsed time per iteration (ms): 573.1 | learning rate: 5.551794E-05 | global batch size:    64 | lm loss: 7.719921E+00 | loss scale: 1.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:19] iteration      168/    1000 | consumed samples:        10752 | elapsed time per iteration (ms): 572.1 | learning rate: 5.546282E-05 | global batch size:    64 | lm loss: 7.664444E+00 | loss scale: 1.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:19] iteration      169/    1000 | consumed samples:        10816 | elapsed time per iteration (ms): 572.4 | learning rate: 5.540738E-05 | global batch size:    64 | lm loss: 7.613155E+00 | loss scale: 1.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:20] iteration      170/    1000 | consumed samples:        10880 | elapsed time per iteration (ms): 572.5 | learning rate: 5.535165E-05 | global batch size:    64 | lm loss: 7.633412E+00 | loss scale: 1.0 | grad norm: 0.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:20] iteration      171/    1000 | consumed samples:        10944 | elapsed time per iteration (ms): 571.7 | learning rate: 5.529561E-05 | global batch size:    64 | lm loss: 7.717263E+00 | loss scale: 1.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:21] iteration      172/    1000 | consumed samples:        11008 | elapsed time per iteration (ms): 573.5 | learning rate: 5.523927E-05 | global batch size:    64 | lm loss: 7.771657E+00 | loss scale: 1.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:22] iteration      173/    1000 | consumed samples:        11072 | elapsed time per iteration (ms): 571.7 | learning rate: 5.518262E-05 | global batch size:    64 | lm loss: 7.625735E+00 | loss scale: 1.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:22] iteration      174/    1000 | consumed samples:        11136 | elapsed time per iteration (ms): 572.1 | learning rate: 5.512567E-05 | global batch size:    64 | lm loss: 7.581598E+00 | loss scale: 1.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:23] iteration      175/    1000 | consumed samples:        11200 | elapsed time per iteration (ms): 572.5 | learning rate: 5.506842E-05 | global batch size:    64 | lm loss: 7.700853E+00 | loss scale: 1.0 | grad norm: 0.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:23] iteration      176/    1000 | consumed samples:        11264 | elapsed time per iteration (ms): 571.8 | learning rate: 5.501087E-05 | global batch size:    64 | lm loss: 7.738677E+00 | loss scale: 1.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:24] iteration      177/    1000 | consumed samples:        11328 | elapsed time per iteration (ms): 572.4 | learning rate: 5.495302E-05 | global batch size:    64 | lm loss: 7.700360E+00 | loss scale: 1.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:24] iteration      178/    1000 | consumed samples:        11392 | elapsed time per iteration (ms): 571.9 | learning rate: 5.489488E-05 | global batch size:    64 | lm loss: 7.564275E+00 | loss scale: 1.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:25] iteration      179/    1000 | consumed samples:        11456 | elapsed time per iteration (ms): 573.7 | learning rate: 5.483643E-05 | global batch size:    64 | lm loss: 7.484324E+00 | loss scale: 1.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:26] iteration      180/    1000 | consumed samples:        11520 | elapsed time per iteration (ms): 571.7 | learning rate: 5.477769E-05 | global batch size:    64 | lm loss: 7.567245E+00 | loss scale: 1.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:26] iteration      181/    1000 | consumed samples:        11584 | elapsed time per iteration (ms): 571.9 | learning rate: 5.471865E-05 | global batch size:    64 | lm loss: 7.583879E+00 | loss scale: 1.0 | grad norm: 0.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:27] iteration      182/    1000 | consumed samples:        11648 | elapsed time per iteration (ms): 573.4 | learning rate: 5.465931E-05 | global batch size:    64 | lm loss: 7.662927E+00 | loss scale: 1.0 | grad norm: 1.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:27] iteration      183/    1000 | consumed samples:        11712 | elapsed time per iteration (ms): 572.0 | learning rate: 5.459968E-05 | global batch size:    64 | lm loss: 7.679224E+00 | loss scale: 1.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:28] iteration      184/    1000 | consumed samples:        11776 | elapsed time per iteration (ms): 572.3 | learning rate: 5.453975E-05 | global batch size:    64 | lm loss: 7.521184E+00 | loss scale: 1.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:28] iteration      185/    1000 | consumed samples:        11840 | elapsed time per iteration (ms): 572.9 | learning rate: 5.447953E-05 | global batch size:    64 | lm loss: 7.559429E+00 | loss scale: 1.0 | grad norm: 0.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:29] iteration      186/    1000 | consumed samples:        11904 | elapsed time per iteration (ms): 572.3 | learning rate: 5.441902E-05 | global batch size:    64 | lm loss: 7.649375E+00 | loss scale: 1.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:30] iteration      187/    1000 | consumed samples:        11968 | elapsed time per iteration (ms): 572.0 | learning rate: 5.435822E-05 | global batch size:    64 | lm loss: 7.640651E+00 | loss scale: 1.0 | grad norm: 0.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:30] iteration      188/    1000 | consumed samples:        12032 | elapsed time per iteration (ms): 571.6 | learning rate: 5.429713E-05 | global batch size:    64 | lm loss: 7.682540E+00 | loss scale: 1.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:31] iteration      189/    1000 | consumed samples:        12096 | elapsed time per iteration (ms): 571.9 | learning rate: 5.423574E-05 | global batch size:    64 | lm loss: 7.550087E+00 | loss scale: 1.0 | grad norm: 0.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:31] iteration      190/    1000 | consumed samples:        12160 | elapsed time per iteration (ms): 573.2 | learning rate: 5.417407E-05 | global batch size:    64 | lm loss: 7.537870E+00 | loss scale: 1.0 | grad norm: 1.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:32] iteration      191/    1000 | consumed samples:        12224 | elapsed time per iteration (ms): 571.7 | learning rate: 5.411211E-05 | global batch size:    64 | lm loss: 7.524974E+00 | loss scale: 1.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:32] iteration      192/    1000 | consumed samples:        12288 | elapsed time per iteration (ms): 571.8 | learning rate: 5.404986E-05 | global batch size:    64 | lm loss: 7.583674E+00 | loss scale: 1.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:33] iteration      193/    1000 | consumed samples:        12352 | elapsed time per iteration (ms): 573.0 | learning rate: 5.398733E-05 | global batch size:    64 | lm loss: 7.636415E+00 | loss scale: 1.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:34] iteration      194/    1000 | consumed samples:        12416 | elapsed time per iteration (ms): 572.8 | learning rate: 5.392451E-05 | global batch size:    64 | lm loss: 7.522254E+00 | loss scale: 1.0 | grad norm: 0.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:34] iteration      195/    1000 | consumed samples:        12480 | elapsed time per iteration (ms): 572.0 | learning rate: 5.386140E-05 | global batch size:    64 | lm loss: 7.534953E+00 | loss scale: 1.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:35] iteration      196/    1000 | consumed samples:        12544 | elapsed time per iteration (ms): 572.0 | learning rate: 5.379801E-05 | global batch size:    64 | lm loss: 7.561055E+00 | loss scale: 1.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:35] iteration      197/    1000 | consumed samples:        12608 | elapsed time per iteration (ms): 572.7 | learning rate: 5.373434E-05 | global batch size:    64 | lm loss: 7.529715E+00 | loss scale: 1.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:36] iteration      198/    1000 | consumed samples:        12672 | elapsed time per iteration (ms): 571.9 | learning rate: 5.367038E-05 | global batch size:    64 | lm loss: 7.640881E+00 | loss scale: 1.0 | grad norm: 0.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:36] iteration      199/    1000 | consumed samples:        12736 | elapsed time per iteration (ms): 573.4 | learning rate: 5.360615E-05 | global batch size:    64 | lm loss: 7.545477E+00 | loss scale: 1.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:37] iteration      200/    1000 | consumed samples:        12800 | elapsed time per iteration (ms): 572.0 | learning rate: 5.354163E-05 | global batch size:    64 | lm loss: 7.606598E+00 | loss scale: 1.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:38] iteration      201/    1000 | consumed samples:        12864 | elapsed time per iteration (ms): 571.6 | learning rate: 5.347684E-05 | global batch size:    64 | lm loss: 7.690606E+00 | loss scale: 1.0 | grad norm: 0.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:38] iteration      202/    1000 | consumed samples:        12928 | elapsed time per iteration (ms): 574.0 | learning rate: 5.341176E-05 | global batch size:    64 | lm loss: 7.438580E+00 | loss scale: 1.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:39] iteration      203/    1000 | consumed samples:        12992 | elapsed time per iteration (ms): 572.8 | learning rate: 5.334641E-05 | global batch size:    64 | lm loss: 7.576996E+00 | loss scale: 1.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:39] iteration      204/    1000 | consumed samples:        13056 | elapsed time per iteration (ms): 571.0 | learning rate: 5.328078E-05 | global batch size:    64 | lm loss: 7.546226E+00 | loss scale: 1.0 | grad norm: 0.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:40] iteration      205/    1000 | consumed samples:        13120 | elapsed time per iteration (ms): 572.0 | learning rate: 5.321487E-05 | global batch size:    64 | lm loss: 7.453189E+00 | loss scale: 1.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:41] iteration      206/    1000 | consumed samples:        13184 | elapsed time per iteration (ms): 572.2 | learning rate: 5.314869E-05 | global batch size:    64 | lm loss: 7.511153E+00 | loss scale: 1.0 | grad norm: 0.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:41] iteration      207/    1000 | consumed samples:        13248 | elapsed time per iteration (ms): 572.0 | learning rate: 5.308223E-05 | global batch size:    64 | lm loss: 7.482664E+00 | loss scale: 1.0 | grad norm: 0.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:42] iteration      208/    1000 | consumed samples:        13312 | elapsed time per iteration (ms): 572.4 | learning rate: 5.301550E-05 | global batch size:    64 | lm loss: 7.573900E+00 | loss scale: 1.0 | grad norm: 0.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:42] iteration      209/    1000 | consumed samples:        13376 | elapsed time per iteration (ms): 573.4 | learning rate: 5.294850E-05 | global batch size:    64 | lm loss: 7.492212E+00 | loss scale: 1.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:43] iteration      210/    1000 | consumed samples:        13440 | elapsed time per iteration (ms): 573.0 | learning rate: 5.288123E-05 | global batch size:    64 | lm loss: 7.526259E+00 | loss scale: 1.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:43] iteration      211/    1000 | consumed samples:        13504 | elapsed time per iteration (ms): 571.3 | learning rate: 5.281368E-05 | global batch size:    64 | lm loss: 7.513941E+00 | loss scale: 1.0 | grad norm: 0.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:44] iteration      212/    1000 | consumed samples:        13568 | elapsed time per iteration (ms): 571.2 | learning rate: 5.274587E-05 | global batch size:    64 | lm loss: 7.446911E+00 | loss scale: 1.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:45] iteration      213/    1000 | consumed samples:        13632 | elapsed time per iteration (ms): 573.0 | learning rate: 5.267779E-05 | global batch size:    64 | lm loss: 7.397903E+00 | loss scale: 1.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:45] iteration      214/    1000 | consumed samples:        13696 | elapsed time per iteration (ms): 571.8 | learning rate: 5.260944E-05 | global batch size:    64 | lm loss: 7.488048E+00 | loss scale: 1.0 | grad norm: 0.584 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:46] iteration      215/    1000 | consumed samples:        13760 | elapsed time per iteration (ms): 572.1 | learning rate: 5.254082E-05 | global batch size:    64 | lm loss: 7.422181E+00 | loss scale: 1.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:46] iteration      216/    1000 | consumed samples:        13824 | elapsed time per iteration (ms): 572.3 | learning rate: 5.247194E-05 | global batch size:    64 | lm loss: 7.497725E+00 | loss scale: 1.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:47] iteration      217/    1000 | consumed samples:        13888 | elapsed time per iteration (ms): 571.9 | learning rate: 5.240279E-05 | global batch size:    64 | lm loss: 7.496538E+00 | loss scale: 1.0 | grad norm: 0.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:47] iteration      218/    1000 | consumed samples:        13952 | elapsed time per iteration (ms): 572.4 | learning rate: 5.233337E-05 | global batch size:    64 | lm loss: 7.471330E+00 | loss scale: 1.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:48] iteration      219/    1000 | consumed samples:        14016 | elapsed time per iteration (ms): 572.3 | learning rate: 5.226370E-05 | global batch size:    64 | lm loss: 7.582762E+00 | loss scale: 1.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:49] iteration      220/    1000 | consumed samples:        14080 | elapsed time per iteration (ms): 572.0 | learning rate: 5.219376E-05 | global batch size:    64 | lm loss: 7.391379E+00 | loss scale: 1.0 | grad norm: 0.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:49] iteration      221/    1000 | consumed samples:        14144 | elapsed time per iteration (ms): 572.3 | learning rate: 5.212356E-05 | global batch size:    64 | lm loss: 7.421879E+00 | loss scale: 1.0 | grad norm: 0.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:50] iteration      222/    1000 | consumed samples:        14208 | elapsed time per iteration (ms): 572.1 | learning rate: 5.205310E-05 | global batch size:    64 | lm loss: 7.504329E+00 | loss scale: 1.0 | grad norm: 0.603 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:50] iteration      223/    1000 | consumed samples:        14272 | elapsed time per iteration (ms): 572.2 | learning rate: 5.198238E-05 | global batch size:    64 | lm loss: 7.536220E+00 | loss scale: 1.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:51] iteration      224/    1000 | consumed samples:        14336 | elapsed time per iteration (ms): 574.4 | learning rate: 5.191140E-05 | global batch size:    64 | lm loss: 7.401150E+00 | loss scale: 1.0 | grad norm: 1.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:51] iteration      225/    1000 | consumed samples:        14400 | elapsed time per iteration (ms): 570.8 | learning rate: 5.184016E-05 | global batch size:    64 | lm loss: 7.410324E+00 | loss scale: 1.0 | grad norm: 0.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:52] iteration      226/    1000 | consumed samples:        14464 | elapsed time per iteration (ms): 571.4 | learning rate: 5.176867E-05 | global batch size:    64 | lm loss: 7.360391E+00 | loss scale: 1.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:53] iteration      227/    1000 | consumed samples:        14528 | elapsed time per iteration (ms): 572.6 | learning rate: 5.169692E-05 | global batch size:    64 | lm loss: 7.427717E+00 | loss scale: 1.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:53] iteration      228/    1000 | consumed samples:        14592 | elapsed time per iteration (ms): 572.1 | learning rate: 5.162492E-05 | global batch size:    64 | lm loss: 7.562253E+00 | loss scale: 1.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:54] iteration      229/    1000 | consumed samples:        14656 | elapsed time per iteration (ms): 572.5 | learning rate: 5.155267E-05 | global batch size:    64 | lm loss: 7.357595E+00 | loss scale: 1.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:54] iteration      230/    1000 | consumed samples:        14720 | elapsed time per iteration (ms): 572.1 | learning rate: 5.148016E-05 | global batch size:    64 | lm loss: 7.490138E+00 | loss scale: 1.0 | grad norm: 0.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:55] iteration      231/    1000 | consumed samples:        14784 | elapsed time per iteration (ms): 572.6 | learning rate: 5.140740E-05 | global batch size:    64 | lm loss: 7.321827E+00 | loss scale: 1.0 | grad norm: 0.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:55] iteration      232/    1000 | consumed samples:        14848 | elapsed time per iteration (ms): 572.1 | learning rate: 5.133439E-05 | global batch size:    64 | lm loss: 7.482674E+00 | loss scale: 1.0 | grad norm: 0.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:56] iteration      233/    1000 | consumed samples:        14912 | elapsed time per iteration (ms): 572.1 | learning rate: 5.126113E-05 | global batch size:    64 | lm loss: 7.390180E+00 | loss scale: 1.0 | grad norm: 0.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:57] iteration      234/    1000 | consumed samples:        14976 | elapsed time per iteration (ms): 573.0 | learning rate: 5.118762E-05 | global batch size:    64 | lm loss: 7.368655E+00 | loss scale: 1.0 | grad norm: 0.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:57] iteration      235/    1000 | consumed samples:        15040 | elapsed time per iteration (ms): 571.4 | learning rate: 5.111386E-05 | global batch size:    64 | lm loss: 7.305375E+00 | loss scale: 1.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:58] iteration      236/    1000 | consumed samples:        15104 | elapsed time per iteration (ms): 572.6 | learning rate: 5.103986E-05 | global batch size:    64 | lm loss: 7.318608E+00 | loss scale: 1.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:58] iteration      237/    1000 | consumed samples:        15168 | elapsed time per iteration (ms): 572.0 | learning rate: 5.096561E-05 | global batch size:    64 | lm loss: 7.477734E+00 | loss scale: 1.0 | grad norm: 0.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:59] iteration      238/    1000 | consumed samples:        15232 | elapsed time per iteration (ms): 572.7 | learning rate: 5.089111E-05 | global batch size:    64 | lm loss: 7.411280E+00 | loss scale: 1.0 | grad norm: 0.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:00:59] iteration      239/    1000 | consumed samples:        15296 | elapsed time per iteration (ms): 572.6 | learning rate: 5.081638E-05 | global batch size:    64 | lm loss: 7.406944E+00 | loss scale: 1.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:00] iteration      240/    1000 | consumed samples:        15360 | elapsed time per iteration (ms): 572.8 | learning rate: 5.074140E-05 | global batch size:    64 | lm loss: 7.369900E+00 | loss scale: 1.0 | grad norm: 0.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:01] iteration      241/    1000 | consumed samples:        15424 | elapsed time per iteration (ms): 571.5 | learning rate: 5.066617E-05 | global batch size:    64 | lm loss: 7.306117E+00 | loss scale: 1.0 | grad norm: 0.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:01] iteration      242/    1000 | consumed samples:        15488 | elapsed time per iteration (ms): 572.9 | learning rate: 5.059072E-05 | global batch size:    64 | lm loss: 7.298653E+00 | loss scale: 1.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:02] iteration      243/    1000 | consumed samples:        15552 | elapsed time per iteration (ms): 572.5 | learning rate: 5.051501E-05 | global batch size:    64 | lm loss: 7.379014E+00 | loss scale: 1.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:02] iteration      244/    1000 | consumed samples:        15616 | elapsed time per iteration (ms): 572.1 | learning rate: 5.043907E-05 | global batch size:    64 | lm loss: 7.337142E+00 | loss scale: 1.0 | grad norm: 0.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:03] iteration      245/    1000 | consumed samples:        15680 | elapsed time per iteration (ms): 573.7 | learning rate: 5.036289E-05 | global batch size:    64 | lm loss: 7.320498E+00 | loss scale: 1.0 | grad norm: 0.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:03] iteration      246/    1000 | consumed samples:        15744 | elapsed time per iteration (ms): 571.8 | learning rate: 5.028648E-05 | global batch size:    64 | lm loss: 7.381459E+00 | loss scale: 1.0 | grad norm: 0.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:04] iteration      247/    1000 | consumed samples:        15808 | elapsed time per iteration (ms): 571.9 | learning rate: 5.020983E-05 | global batch size:    64 | lm loss: 7.390684E+00 | loss scale: 1.0 | grad norm: 0.570 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:05] iteration      248/    1000 | consumed samples:        15872 | elapsed time per iteration (ms): 572.1 | learning rate: 5.013295E-05 | global batch size:    64 | lm loss: 7.279361E+00 | loss scale: 1.0 | grad norm: 0.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:05] iteration      249/    1000 | consumed samples:        15936 | elapsed time per iteration (ms): 572.8 | learning rate: 5.005583E-05 | global batch size:    64 | lm loss: 7.346303E+00 | loss scale: 1.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:06] iteration      250/    1000 | consumed samples:        16000 | elapsed time per iteration (ms): 571.7 | learning rate: 4.997848E-05 | global batch size:    64 | lm loss: 7.389145E+00 | loss scale: 1.0 | grad norm: 0.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:06] iteration      251/    1000 | consumed samples:        16064 | elapsed time per iteration (ms): 572.7 | learning rate: 4.990090E-05 | global batch size:    64 | lm loss: 7.294164E+00 | loss scale: 1.0 | grad norm: 0.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:07] iteration      252/    1000 | consumed samples:        16128 | elapsed time per iteration (ms): 572.4 | learning rate: 4.982309E-05 | global batch size:    64 | lm loss: 7.402777E+00 | loss scale: 1.0 | grad norm: 0.557 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:07] iteration      253/    1000 | consumed samples:        16192 | elapsed time per iteration (ms): 573.0 | learning rate: 4.974506E-05 | global batch size:    64 | lm loss: 7.252671E+00 | loss scale: 1.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:08] iteration      254/    1000 | consumed samples:        16256 | elapsed time per iteration (ms): 571.5 | learning rate: 4.966679E-05 | global batch size:    64 | lm loss: 7.362764E+00 | loss scale: 1.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:09] iteration      255/    1000 | consumed samples:        16320 | elapsed time per iteration (ms): 571.9 | learning rate: 4.958830E-05 | global batch size:    64 | lm loss: 7.471643E+00 | loss scale: 1.0 | grad norm: 0.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:09] iteration      256/    1000 | consumed samples:        16384 | elapsed time per iteration (ms): 573.2 | learning rate: 4.950957E-05 | global batch size:    64 | lm loss: 7.222782E+00 | loss scale: 1.0 | grad norm: 1.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:10] iteration      257/    1000 | consumed samples:        16448 | elapsed time per iteration (ms): 572.0 | learning rate: 4.943063E-05 | global batch size:    64 | lm loss: 7.436595E+00 | loss scale: 1.0 | grad norm: 0.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:10] iteration      258/    1000 | consumed samples:        16512 | elapsed time per iteration (ms): 572.6 | learning rate: 4.935146E-05 | global batch size:    64 | lm loss: 7.410456E+00 | loss scale: 1.0 | grad norm: 0.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:11] iteration      259/    1000 | consumed samples:        16576 | elapsed time per iteration (ms): 572.5 | learning rate: 4.927207E-05 | global batch size:    64 | lm loss: 7.402411E+00 | loss scale: 1.0 | grad norm: 0.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:11] iteration      260/    1000 | consumed samples:        16640 | elapsed time per iteration (ms): 572.1 | learning rate: 4.919246E-05 | global batch size:    64 | lm loss: 7.250634E+00 | loss scale: 1.0 | grad norm: 0.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:12] iteration      261/    1000 | consumed samples:        16704 | elapsed time per iteration (ms): 573.0 | learning rate: 4.911263E-05 | global batch size:    64 | lm loss: 7.349916E+00 | loss scale: 1.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:13] iteration      262/    1000 | consumed samples:        16768 | elapsed time per iteration (ms): 572.8 | learning rate: 4.903257E-05 | global batch size:    64 | lm loss: 7.320434E+00 | loss scale: 1.0 | grad norm: 0.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:13] iteration      263/    1000 | consumed samples:        16832 | elapsed time per iteration (ms): 572.8 | learning rate: 4.895230E-05 | global batch size:    64 | lm loss: 7.239245E+00 | loss scale: 1.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:14] iteration      264/    1000 | consumed samples:        16896 | elapsed time per iteration (ms): 572.5 | learning rate: 4.887181E-05 | global batch size:    64 | lm loss: 7.381006E+00 | loss scale: 1.0 | grad norm: 0.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:14] iteration      265/    1000 | consumed samples:        16960 | elapsed time per iteration (ms): 572.2 | learning rate: 4.879111E-05 | global batch size:    64 | lm loss: 7.298939E+00 | loss scale: 1.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:15] iteration      266/    1000 | consumed samples:        17024 | elapsed time per iteration (ms): 572.1 | learning rate: 4.871019E-05 | global batch size:    64 | lm loss: 7.370318E+00 | loss scale: 1.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:15] iteration      267/    1000 | consumed samples:        17088 | elapsed time per iteration (ms): 572.2 | learning rate: 4.862906E-05 | global batch size:    64 | lm loss: 7.265194E+00 | loss scale: 1.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:16] iteration      268/    1000 | consumed samples:        17152 | elapsed time per iteration (ms): 572.4 | learning rate: 4.854771E-05 | global batch size:    64 | lm loss: 7.351542E+00 | loss scale: 1.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:17] iteration      269/    1000 | consumed samples:        17216 | elapsed time per iteration (ms): 571.8 | learning rate: 4.846615E-05 | global batch size:    64 | lm loss: 7.346539E+00 | loss scale: 1.0 | grad norm: 0.575 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:17] iteration      270/    1000 | consumed samples:        17280 | elapsed time per iteration (ms): 573.8 | learning rate: 4.838439E-05 | global batch size:    64 | lm loss: 7.333715E+00 | loss scale: 1.0 | grad norm: 0.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:18] iteration      271/    1000 | consumed samples:        17344 | elapsed time per iteration (ms): 571.8 | learning rate: 4.830241E-05 | global batch size:    64 | lm loss: 7.379158E+00 | loss scale: 1.0 | grad norm: 0.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:18] iteration      272/    1000 | consumed samples:        17408 | elapsed time per iteration (ms): 571.6 | learning rate: 4.822022E-05 | global batch size:    64 | lm loss: 7.246853E+00 | loss scale: 1.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:19] iteration      273/    1000 | consumed samples:        17472 | elapsed time per iteration (ms): 572.3 | learning rate: 4.813783E-05 | global batch size:    64 | lm loss: 7.353370E+00 | loss scale: 1.0 | grad norm: 0.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:19] iteration      274/    1000 | consumed samples:        17536 | elapsed time per iteration (ms): 572.1 | learning rate: 4.805523E-05 | global batch size:    64 | lm loss: 7.340643E+00 | loss scale: 1.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:20] iteration      275/    1000 | consumed samples:        17600 | elapsed time per iteration (ms): 572.3 | learning rate: 4.797243E-05 | global batch size:    64 | lm loss: 7.321087E+00 | loss scale: 1.0 | grad norm: 0.574 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:21] iteration      276/    1000 | consumed samples:        17664 | elapsed time per iteration (ms): 572.3 | learning rate: 4.788942E-05 | global batch size:    64 | lm loss: 7.236008E+00 | loss scale: 1.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:21] iteration      277/    1000 | consumed samples:        17728 | elapsed time per iteration (ms): 572.8 | learning rate: 4.780621E-05 | global batch size:    64 | lm loss: 7.275432E+00 | loss scale: 1.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:22] iteration      278/    1000 | consumed samples:        17792 | elapsed time per iteration (ms): 571.7 | learning rate: 4.772279E-05 | global batch size:    64 | lm loss: 7.453699E+00 | loss scale: 1.0 | grad norm: 0.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:22] iteration      279/    1000 | consumed samples:        17856 | elapsed time per iteration (ms): 572.7 | learning rate: 4.763918E-05 | global batch size:    64 | lm loss: 7.400574E+00 | loss scale: 1.0 | grad norm: 1.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:23] iteration      280/    1000 | consumed samples:        17920 | elapsed time per iteration (ms): 572.6 | learning rate: 4.755537E-05 | global batch size:    64 | lm loss: 7.263723E+00 | loss scale: 1.0 | grad norm: 1.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:23] iteration      281/    1000 | consumed samples:        17984 | elapsed time per iteration (ms): 571.7 | learning rate: 4.747136E-05 | global batch size:    64 | lm loss: 7.323401E+00 | loss scale: 1.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:24] iteration      282/    1000 | consumed samples:        18048 | elapsed time per iteration (ms): 571.9 | learning rate: 4.738716E-05 | global batch size:    64 | lm loss: 7.276505E+00 | loss scale: 1.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:25] iteration      283/    1000 | consumed samples:        18112 | elapsed time per iteration (ms): 571.8 | learning rate: 4.730275E-05 | global batch size:    64 | lm loss: 7.350159E+00 | loss scale: 1.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:25] iteration      284/    1000 | consumed samples:        18176 | elapsed time per iteration (ms): 572.5 | learning rate: 4.721815E-05 | global batch size:    64 | lm loss: 7.325212E+00 | loss scale: 1.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:26] iteration      285/    1000 | consumed samples:        18240 | elapsed time per iteration (ms): 573.1 | learning rate: 4.713336E-05 | global batch size:    64 | lm loss: 7.356062E+00 | loss scale: 1.0 | grad norm: 1.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:26] iteration      286/    1000 | consumed samples:        18304 | elapsed time per iteration (ms): 571.7 | learning rate: 4.704838E-05 | global batch size:    64 | lm loss: 7.273488E+00 | loss scale: 1.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:27] iteration      287/    1000 | consumed samples:        18368 | elapsed time per iteration (ms): 571.8 | learning rate: 4.696320E-05 | global batch size:    64 | lm loss: 7.305852E+00 | loss scale: 1.0 | grad norm: 0.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:27] iteration      288/    1000 | consumed samples:        18432 | elapsed time per iteration (ms): 572.6 | learning rate: 4.687784E-05 | global batch size:    64 | lm loss: 7.278710E+00 | loss scale: 1.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:28] iteration      289/    1000 | consumed samples:        18496 | elapsed time per iteration (ms): 572.0 | learning rate: 4.679228E-05 | global batch size:    64 | lm loss: 7.297997E+00 | loss scale: 1.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:29] iteration      290/    1000 | consumed samples:        18560 | elapsed time per iteration (ms): 572.1 | learning rate: 4.670654E-05 | global batch size:    64 | lm loss: 7.421436E+00 | loss scale: 1.0 | grad norm: 0.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:29] iteration      291/    1000 | consumed samples:        18624 | elapsed time per iteration (ms): 572.5 | learning rate: 4.662061E-05 | global batch size:    64 | lm loss: 7.273851E+00 | loss scale: 1.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:30] iteration      292/    1000 | consumed samples:        18688 | elapsed time per iteration (ms): 572.4 | learning rate: 4.653450E-05 | global batch size:    64 | lm loss: 7.208935E+00 | loss scale: 1.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:30] iteration      293/    1000 | consumed samples:        18752 | elapsed time per iteration (ms): 572.6 | learning rate: 4.644820E-05 | global batch size:    64 | lm loss: 7.316900E+00 | loss scale: 1.0 | grad norm: 0.701 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:31] iteration      294/    1000 | consumed samples:        18816 | elapsed time per iteration (ms): 571.3 | learning rate: 4.636172E-05 | global batch size:    64 | lm loss: 7.240615E+00 | loss scale: 1.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:31] iteration      295/    1000 | consumed samples:        18880 | elapsed time per iteration (ms): 573.4 | learning rate: 4.627505E-05 | global batch size:    64 | lm loss: 7.262068E+00 | loss scale: 1.0 | grad norm: 0.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:32] iteration      296/    1000 | consumed samples:        18944 | elapsed time per iteration (ms): 571.7 | learning rate: 4.618821E-05 | global batch size:    64 | lm loss: 7.238802E+00 | loss scale: 1.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:33] iteration      297/    1000 | consumed samples:        19008 | elapsed time per iteration (ms): 572.7 | learning rate: 4.610119E-05 | global batch size:    64 | lm loss: 7.318020E+00 | loss scale: 1.0 | grad norm: 0.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:33] iteration      298/    1000 | consumed samples:        19072 | elapsed time per iteration (ms): 573.1 | learning rate: 4.601399E-05 | global batch size:    64 | lm loss: 7.250757E+00 | loss scale: 1.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:34] iteration      299/    1000 | consumed samples:        19136 | elapsed time per iteration (ms): 571.5 | learning rate: 4.592660E-05 | global batch size:    64 | lm loss: 7.229738E+00 | loss scale: 1.0 | grad norm: 0.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:34] iteration      300/    1000 | consumed samples:        19200 | elapsed time per iteration (ms): 572.1 | learning rate: 4.583905E-05 | global batch size:    64 | lm loss: 7.294851E+00 | loss scale: 1.0 | grad norm: 0.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:35] iteration      301/    1000 | consumed samples:        19264 | elapsed time per iteration (ms): 573.1 | learning rate: 4.575132E-05 | global batch size:    64 | lm loss: 7.169103E+00 | loss scale: 1.0 | grad norm: 0.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:35] iteration      302/    1000 | consumed samples:        19328 | elapsed time per iteration (ms): 571.9 | learning rate: 4.566342E-05 | global batch size:    64 | lm loss: 7.366071E+00 | loss scale: 1.0 | grad norm: 0.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:36] iteration      303/    1000 | consumed samples:        19392 | elapsed time per iteration (ms): 573.7 | learning rate: 4.557534E-05 | global batch size:    64 | lm loss: 7.123664E+00 | loss scale: 1.0 | grad norm: 0.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:37] iteration      304/    1000 | consumed samples:        19456 | elapsed time per iteration (ms): 571.3 | learning rate: 4.548709E-05 | global batch size:    64 | lm loss: 7.296824E+00 | loss scale: 1.0 | grad norm: 0.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:37] iteration      305/    1000 | consumed samples:        19520 | elapsed time per iteration (ms): 572.0 | learning rate: 4.539868E-05 | global batch size:    64 | lm loss: 7.205088E+00 | loss scale: 1.0 | grad norm: 0.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:38] iteration      306/    1000 | consumed samples:        19584 | elapsed time per iteration (ms): 573.1 | learning rate: 4.531009E-05 | global batch size:    64 | lm loss: 7.228707E+00 | loss scale: 1.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:38] iteration      307/    1000 | consumed samples:        19648 | elapsed time per iteration (ms): 572.0 | learning rate: 4.522134E-05 | global batch size:    64 | lm loss: 7.184329E+00 | loss scale: 1.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:39] iteration      308/    1000 | consumed samples:        19712 | elapsed time per iteration (ms): 572.0 | learning rate: 4.513241E-05 | global batch size:    64 | lm loss: 7.251068E+00 | loss scale: 1.0 | grad norm: 0.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:39] iteration      309/    1000 | consumed samples:        19776 | elapsed time per iteration (ms): 573.9 | learning rate: 4.504333E-05 | global batch size:    64 | lm loss: 7.316315E+00 | loss scale: 1.0 | grad norm: 0.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:40] iteration      310/    1000 | consumed samples:        19840 | elapsed time per iteration (ms): 570.9 | learning rate: 4.495408E-05 | global batch size:    64 | lm loss: 7.191540E+00 | loss scale: 1.0 | grad norm: 0.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:41] iteration      311/    1000 | consumed samples:        19904 | elapsed time per iteration (ms): 572.4 | learning rate: 4.486467E-05 | global batch size:    64 | lm loss: 7.327835E+00 | loss scale: 1.0 | grad norm: 0.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:41] iteration      312/    1000 | consumed samples:        19968 | elapsed time per iteration (ms): 572.7 | learning rate: 4.477509E-05 | global batch size:    64 | lm loss: 7.127344E+00 | loss scale: 1.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:42] iteration      313/    1000 | consumed samples:        20032 | elapsed time per iteration (ms): 572.7 | learning rate: 4.468536E-05 | global batch size:    64 | lm loss: 7.221992E+00 | loss scale: 1.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:42] iteration      314/    1000 | consumed samples:        20096 | elapsed time per iteration (ms): 572.6 | learning rate: 4.459546E-05 | global batch size:    64 | lm loss: 7.183560E+00 | loss scale: 1.0 | grad norm: 1.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:43] iteration      315/    1000 | consumed samples:        20160 | elapsed time per iteration (ms): 571.7 | learning rate: 4.450541E-05 | global batch size:    64 | lm loss: 7.201626E+00 | loss scale: 1.0 | grad norm: 0.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:43] iteration      316/    1000 | consumed samples:        20224 | elapsed time per iteration (ms): 572.8 | learning rate: 4.441521E-05 | global batch size:    64 | lm loss: 7.084419E+00 | loss scale: 1.0 | grad norm: 1.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:44] iteration      317/    1000 | consumed samples:        20288 | elapsed time per iteration (ms): 571.9 | learning rate: 4.432484E-05 | global batch size:    64 | lm loss: 7.348069E+00 | loss scale: 1.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:45] iteration      318/    1000 | consumed samples:        20352 | elapsed time per iteration (ms): 572.5 | learning rate: 4.423433E-05 | global batch size:    64 | lm loss: 7.106907E+00 | loss scale: 1.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:45] iteration      319/    1000 | consumed samples:        20416 | elapsed time per iteration (ms): 572.2 | learning rate: 4.414366E-05 | global batch size:    64 | lm loss: 7.254831E+00 | loss scale: 1.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:46] iteration      320/    1000 | consumed samples:        20480 | elapsed time per iteration (ms): 572.8 | learning rate: 4.405283E-05 | global batch size:    64 | lm loss: 7.165761E+00 | loss scale: 1.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:46] iteration      321/    1000 | consumed samples:        20544 | elapsed time per iteration (ms): 572.4 | learning rate: 4.396186E-05 | global batch size:    64 | lm loss: 7.178225E+00 | loss scale: 1.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:47] iteration      322/    1000 | consumed samples:        20608 | elapsed time per iteration (ms): 571.9 | learning rate: 4.387074E-05 | global batch size:    64 | lm loss: 7.206578E+00 | loss scale: 1.0 | grad norm: 0.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:47] iteration      323/    1000 | consumed samples:        20672 | elapsed time per iteration (ms): 572.3 | learning rate: 4.377947E-05 | global batch size:    64 | lm loss: 7.132746E+00 | loss scale: 1.0 | grad norm: 0.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:48] iteration      324/    1000 | consumed samples:        20736 | elapsed time per iteration (ms): 572.2 | learning rate: 4.368805E-05 | global batch size:    64 | lm loss: 7.087037E+00 | loss scale: 1.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:49] iteration      325/    1000 | consumed samples:        20800 | elapsed time per iteration (ms): 572.9 | learning rate: 4.359649E-05 | global batch size:    64 | lm loss: 7.232061E+00 | loss scale: 1.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:49] iteration      326/    1000 | consumed samples:        20864 | elapsed time per iteration (ms): 571.7 | learning rate: 4.350479E-05 | global batch size:    64 | lm loss: 7.256309E+00 | loss scale: 1.0 | grad norm: 0.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:50] iteration      327/    1000 | consumed samples:        20928 | elapsed time per iteration (ms): 572.2 | learning rate: 4.341294E-05 | global batch size:    64 | lm loss: 7.250839E+00 | loss scale: 1.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:50] iteration      328/    1000 | consumed samples:        20992 | elapsed time per iteration (ms): 572.6 | learning rate: 4.332095E-05 | global batch size:    64 | lm loss: 7.269726E+00 | loss scale: 1.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:51] iteration      329/    1000 | consumed samples:        21056 | elapsed time per iteration (ms): 572.1 | learning rate: 4.322881E-05 | global batch size:    64 | lm loss: 7.188832E+00 | loss scale: 1.0 | grad norm: 0.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:51] iteration      330/    1000 | consumed samples:        21120 | elapsed time per iteration (ms): 572.4 | learning rate: 4.313654E-05 | global batch size:    64 | lm loss: 7.256387E+00 | loss scale: 1.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:52] iteration      331/    1000 | consumed samples:        21184 | elapsed time per iteration (ms): 572.5 | learning rate: 4.304414E-05 | global batch size:    64 | lm loss: 7.305362E+00 | loss scale: 1.0 | grad norm: 0.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:53] iteration      332/    1000 | consumed samples:        21248 | elapsed time per iteration (ms): 572.4 | learning rate: 4.295159E-05 | global batch size:    64 | lm loss: 7.181171E+00 | loss scale: 1.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:53] iteration      333/    1000 | consumed samples:        21312 | elapsed time per iteration (ms): 571.8 | learning rate: 4.285891E-05 | global batch size:    64 | lm loss: 7.168859E+00 | loss scale: 1.0 | grad norm: 0.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:54] iteration      334/    1000 | consumed samples:        21376 | elapsed time per iteration (ms): 574.0 | learning rate: 4.276609E-05 | global batch size:    64 | lm loss: 7.220509E+00 | loss scale: 1.0 | grad norm: 0.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:54] iteration      335/    1000 | consumed samples:        21440 | elapsed time per iteration (ms): 571.6 | learning rate: 4.267315E-05 | global batch size:    64 | lm loss: 7.209799E+00 | loss scale: 1.0 | grad norm: 0.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:55] iteration      336/    1000 | consumed samples:        21504 | elapsed time per iteration (ms): 572.1 | learning rate: 4.258006E-05 | global batch size:    64 | lm loss: 7.162513E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:55] iteration      337/    1000 | consumed samples:        21568 | elapsed time per iteration (ms): 573.0 | learning rate: 4.248685E-05 | global batch size:    64 | lm loss: 7.079775E+00 | loss scale: 1.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:56] iteration      338/    1000 | consumed samples:        21632 | elapsed time per iteration (ms): 574.6 | learning rate: 4.239351E-05 | global batch size:    64 | lm loss: 7.208869E+00 | loss scale: 1.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:57] iteration      339/    1000 | consumed samples:        21696 | elapsed time per iteration (ms): 574.3 | learning rate: 4.230005E-05 | global batch size:    64 | lm loss: 7.224432E+00 | loss scale: 1.0 | grad norm: 0.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:57] iteration      340/    1000 | consumed samples:        21760 | elapsed time per iteration (ms): 579.1 | learning rate: 4.220645E-05 | global batch size:    64 | lm loss: 7.197394E+00 | loss scale: 1.0 | grad norm: 0.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:58] iteration      341/    1000 | consumed samples:        21824 | elapsed time per iteration (ms): 573.8 | learning rate: 4.211273E-05 | global batch size:    64 | lm loss: 7.156867E+00 | loss scale: 1.0 | grad norm: 0.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:58] iteration      342/    1000 | consumed samples:        21888 | elapsed time per iteration (ms): 574.2 | learning rate: 4.201889E-05 | global batch size:    64 | lm loss: 7.208978E+00 | loss scale: 1.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:01:59] iteration      343/    1000 | consumed samples:        21952 | elapsed time per iteration (ms): 574.3 | learning rate: 4.192492E-05 | global batch size:    64 | lm loss: 7.041099E+00 | loss scale: 1.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:00] iteration      344/    1000 | consumed samples:        22016 | elapsed time per iteration (ms): 574.1 | learning rate: 4.183083E-05 | global batch size:    64 | lm loss: 7.210023E+00 | loss scale: 1.0 | grad norm: 0.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:00] iteration      345/    1000 | consumed samples:        22080 | elapsed time per iteration (ms): 573.8 | learning rate: 4.173663E-05 | global batch size:    64 | lm loss: 7.175426E+00 | loss scale: 1.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:01] iteration      346/    1000 | consumed samples:        22144 | elapsed time per iteration (ms): 572.5 | learning rate: 4.164230E-05 | global batch size:    64 | lm loss: 7.127215E+00 | loss scale: 1.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:01] iteration      347/    1000 | consumed samples:        22208 | elapsed time per iteration (ms): 571.6 | learning rate: 4.154785E-05 | global batch size:    64 | lm loss: 7.175919E+00 | loss scale: 1.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:02] iteration      348/    1000 | consumed samples:        22272 | elapsed time per iteration (ms): 573.8 | learning rate: 4.145330E-05 | global batch size:    64 | lm loss: 7.107903E+00 | loss scale: 1.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:02] iteration      349/    1000 | consumed samples:        22336 | elapsed time per iteration (ms): 571.8 | learning rate: 4.135862E-05 | global batch size:    64 | lm loss: 7.236140E+00 | loss scale: 1.0 | grad norm: 0.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:03] iteration      350/    1000 | consumed samples:        22400 | elapsed time per iteration (ms): 573.1 | learning rate: 4.126383E-05 | global batch size:    64 | lm loss: 7.104825E+00 | loss scale: 1.0 | grad norm: 0.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:04] iteration      351/    1000 | consumed samples:        22464 | elapsed time per iteration (ms): 571.3 | learning rate: 4.116893E-05 | global batch size:    64 | lm loss: 7.140366E+00 | loss scale: 1.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:04] iteration      352/    1000 | consumed samples:        22528 | elapsed time per iteration (ms): 571.8 | learning rate: 4.107391E-05 | global batch size:    64 | lm loss: 7.149813E+00 | loss scale: 1.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:05] iteration      353/    1000 | consumed samples:        22592 | elapsed time per iteration (ms): 572.5 | learning rate: 4.097879E-05 | global batch size:    64 | lm loss: 7.187510E+00 | loss scale: 1.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:05] iteration      354/    1000 | consumed samples:        22656 | elapsed time per iteration (ms): 572.4 | learning rate: 4.088355E-05 | global batch size:    64 | lm loss: 7.124531E+00 | loss scale: 1.0 | grad norm: 0.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:06] iteration      355/    1000 | consumed samples:        22720 | elapsed time per iteration (ms): 573.4 | learning rate: 4.078821E-05 | global batch size:    64 | lm loss: 7.271389E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:06] iteration      356/    1000 | consumed samples:        22784 | elapsed time per iteration (ms): 573.2 | learning rate: 4.069277E-05 | global batch size:    64 | lm loss: 7.313162E+00 | loss scale: 1.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:07] iteration      357/    1000 | consumed samples:        22848 | elapsed time per iteration (ms): 573.3 | learning rate: 4.059722E-05 | global batch size:    64 | lm loss: 7.114447E+00 | loss scale: 1.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:08] iteration      358/    1000 | consumed samples:        22912 | elapsed time per iteration (ms): 575.1 | learning rate: 4.050157E-05 | global batch size:    64 | lm loss: 7.128383E+00 | loss scale: 1.0 | grad norm: 1.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:08] iteration      359/    1000 | consumed samples:        22976 | elapsed time per iteration (ms): 576.8 | learning rate: 4.040581E-05 | global batch size:    64 | lm loss: 7.199175E+00 | loss scale: 1.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:09] iteration      360/    1000 | consumed samples:        23040 | elapsed time per iteration (ms): 574.8 | learning rate: 4.030995E-05 | global batch size:    64 | lm loss: 7.158340E+00 | loss scale: 1.0 | grad norm: 1.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:09] iteration      361/    1000 | consumed samples:        23104 | elapsed time per iteration (ms): 574.5 | learning rate: 4.021400E-05 | global batch size:    64 | lm loss: 7.120609E+00 | loss scale: 1.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:10] iteration      362/    1000 | consumed samples:        23168 | elapsed time per iteration (ms): 574.3 | learning rate: 4.011794E-05 | global batch size:    64 | lm loss: 7.117965E+00 | loss scale: 1.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:10] iteration      363/    1000 | consumed samples:        23232 | elapsed time per iteration (ms): 573.5 | learning rate: 4.002179E-05 | global batch size:    64 | lm loss: 7.035376E+00 | loss scale: 1.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:11] iteration      364/    1000 | consumed samples:        23296 | elapsed time per iteration (ms): 574.0 | learning rate: 3.992554E-05 | global batch size:    64 | lm loss: 7.050077E+00 | loss scale: 1.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:12] iteration      365/    1000 | consumed samples:        23360 | elapsed time per iteration (ms): 572.4 | learning rate: 3.982920E-05 | global batch size:    64 | lm loss: 6.993221E+00 | loss scale: 1.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:12] iteration      366/    1000 | consumed samples:        23424 | elapsed time per iteration (ms): 572.1 | learning rate: 3.973277E-05 | global batch size:    64 | lm loss: 7.145328E+00 | loss scale: 1.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:13] iteration      367/    1000 | consumed samples:        23488 | elapsed time per iteration (ms): 573.3 | learning rate: 3.963624E-05 | global batch size:    64 | lm loss: 7.149008E+00 | loss scale: 1.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:13] iteration      368/    1000 | consumed samples:        23552 | elapsed time per iteration (ms): 573.5 | learning rate: 3.953962E-05 | global batch size:    64 | lm loss: 7.145076E+00 | loss scale: 1.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:14] iteration      369/    1000 | consumed samples:        23616 | elapsed time per iteration (ms): 572.1 | learning rate: 3.944292E-05 | global batch size:    64 | lm loss: 7.050214E+00 | loss scale: 1.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:14] iteration      370/    1000 | consumed samples:        23680 | elapsed time per iteration (ms): 573.7 | learning rate: 3.934613E-05 | global batch size:    64 | lm loss: 7.088505E+00 | loss scale: 1.0 | grad norm: 0.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:15] iteration      371/    1000 | consumed samples:        23744 | elapsed time per iteration (ms): 574.8 | learning rate: 3.924925E-05 | global batch size:    64 | lm loss: 7.011659E+00 | loss scale: 1.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:16] iteration      372/    1000 | consumed samples:        23808 | elapsed time per iteration (ms): 575.1 | learning rate: 3.915228E-05 | global batch size:    64 | lm loss: 6.963890E+00 | loss scale: 1.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:16] iteration      373/    1000 | consumed samples:        23872 | elapsed time per iteration (ms): 574.5 | learning rate: 3.905523E-05 | global batch size:    64 | lm loss: 7.213629E+00 | loss scale: 1.0 | grad norm: 0.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:17] iteration      374/    1000 | consumed samples:        23936 | elapsed time per iteration (ms): 573.2 | learning rate: 3.895810E-05 | global batch size:    64 | lm loss: 7.069201E+00 | loss scale: 1.0 | grad norm: 0.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:17] iteration      375/    1000 | consumed samples:        24000 | elapsed time per iteration (ms): 573.8 | learning rate: 3.886089E-05 | global batch size:    64 | lm loss: 7.066479E+00 | loss scale: 1.0 | grad norm: 0.669 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:18] iteration      376/    1000 | consumed samples:        24064 | elapsed time per iteration (ms): 574.8 | learning rate: 3.876360E-05 | global batch size:    64 | lm loss: 7.146582E+00 | loss scale: 1.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:18] iteration      377/    1000 | consumed samples:        24128 | elapsed time per iteration (ms): 576.8 | learning rate: 3.866623E-05 | global batch size:    64 | lm loss: 7.098938E+00 | loss scale: 1.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:19] iteration      378/    1000 | consumed samples:        24192 | elapsed time per iteration (ms): 574.5 | learning rate: 3.856878E-05 | global batch size:    64 | lm loss: 6.993666E+00 | loss scale: 1.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:20] iteration      379/    1000 | consumed samples:        24256 | elapsed time per iteration (ms): 574.9 | learning rate: 3.847126E-05 | global batch size:    64 | lm loss: 7.088673E+00 | loss scale: 1.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:20] iteration      380/    1000 | consumed samples:        24320 | elapsed time per iteration (ms): 574.8 | learning rate: 3.837366E-05 | global batch size:    64 | lm loss: 7.135818E+00 | loss scale: 1.0 | grad norm: 0.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:21] iteration      381/    1000 | consumed samples:        24384 | elapsed time per iteration (ms): 573.7 | learning rate: 3.827599E-05 | global batch size:    64 | lm loss: 7.220840E+00 | loss scale: 1.0 | grad norm: 0.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:21] iteration      382/    1000 | consumed samples:        24448 | elapsed time per iteration (ms): 574.1 | learning rate: 3.817824E-05 | global batch size:    64 | lm loss: 7.192095E+00 | loss scale: 1.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:22] iteration      383/    1000 | consumed samples:        24512 | elapsed time per iteration (ms): 574.1 | learning rate: 3.808043E-05 | global batch size:    64 | lm loss: 6.975794E+00 | loss scale: 1.0 | grad norm: 0.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:22] iteration      384/    1000 | consumed samples:        24576 | elapsed time per iteration (ms): 573.6 | learning rate: 3.798255E-05 | global batch size:    64 | lm loss: 7.186392E+00 | loss scale: 1.0 | grad norm: 0.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:23] iteration      385/    1000 | consumed samples:        24640 | elapsed time per iteration (ms): 574.3 | learning rate: 3.788460E-05 | global batch size:    64 | lm loss: 7.134368E+00 | loss scale: 1.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:24] iteration      386/    1000 | consumed samples:        24704 | elapsed time per iteration (ms): 575.2 | learning rate: 3.778658E-05 | global batch size:    64 | lm loss: 7.142549E+00 | loss scale: 1.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:24] iteration      387/    1000 | consumed samples:        24768 | elapsed time per iteration (ms): 574.0 | learning rate: 3.768850E-05 | global batch size:    64 | lm loss: 7.241455E+00 | loss scale: 1.0 | grad norm: 0.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:25] iteration      388/    1000 | consumed samples:        24832 | elapsed time per iteration (ms): 572.0 | learning rate: 3.759035E-05 | global batch size:    64 | lm loss: 7.161832E+00 | loss scale: 1.0 | grad norm: 0.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:25] iteration      389/    1000 | consumed samples:        24896 | elapsed time per iteration (ms): 571.8 | learning rate: 3.749215E-05 | global batch size:    64 | lm loss: 7.078736E+00 | loss scale: 1.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:26] iteration      390/    1000 | consumed samples:        24960 | elapsed time per iteration (ms): 572.0 | learning rate: 3.739388E-05 | global batch size:    64 | lm loss: 7.092772E+00 | loss scale: 1.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:26] iteration      391/    1000 | consumed samples:        25024 | elapsed time per iteration (ms): 572.8 | learning rate: 3.729555E-05 | global batch size:    64 | lm loss: 7.019351E+00 | loss scale: 1.0 | grad norm: 0.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:27] iteration      392/    1000 | consumed samples:        25088 | elapsed time per iteration (ms): 574.0 | learning rate: 3.719716E-05 | global batch size:    64 | lm loss: 7.046804E+00 | loss scale: 1.0 | grad norm: 0.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:28] iteration      393/    1000 | consumed samples:        25152 | elapsed time per iteration (ms): 574.2 | learning rate: 3.709871E-05 | global batch size:    64 | lm loss: 6.962238E+00 | loss scale: 1.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:28] iteration      394/    1000 | consumed samples:        25216 | elapsed time per iteration (ms): 574.2 | learning rate: 3.700022E-05 | global batch size:    64 | lm loss: 7.108763E+00 | loss scale: 1.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:29] iteration      395/    1000 | consumed samples:        25280 | elapsed time per iteration (ms): 575.3 | learning rate: 3.690166E-05 | global batch size:    64 | lm loss: 7.129899E+00 | loss scale: 1.0 | grad norm: 0.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:29] iteration      396/    1000 | consumed samples:        25344 | elapsed time per iteration (ms): 576.1 | learning rate: 3.680305E-05 | global batch size:    64 | lm loss: 6.972257E+00 | loss scale: 1.0 | grad norm: 1.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:30] iteration      397/    1000 | consumed samples:        25408 | elapsed time per iteration (ms): 575.2 | learning rate: 3.670439E-05 | global batch size:    64 | lm loss: 7.113462E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:31] iteration      398/    1000 | consumed samples:        25472 | elapsed time per iteration (ms): 576.3 | learning rate: 3.660568E-05 | global batch size:    64 | lm loss: 7.089234E+00 | loss scale: 1.0 | grad norm: 0.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:31] iteration      399/    1000 | consumed samples:        25536 | elapsed time per iteration (ms): 574.6 | learning rate: 3.650692E-05 | global batch size:    64 | lm loss: 7.099511E+00 | loss scale: 1.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:32] iteration      400/    1000 | consumed samples:        25600 | elapsed time per iteration (ms): 573.6 | learning rate: 3.640811E-05 | global batch size:    64 | lm loss: 7.054824E+00 | loss scale: 1.0 | grad norm: 1.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:32] iteration      401/    1000 | consumed samples:        25664 | elapsed time per iteration (ms): 572.6 | learning rate: 3.630926E-05 | global batch size:    64 | lm loss: 7.052826E+00 | loss scale: 1.0 | grad norm: 1.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:33] iteration      402/    1000 | consumed samples:        25728 | elapsed time per iteration (ms): 577.2 | learning rate: 3.621036E-05 | global batch size:    64 | lm loss: 6.933145E+00 | loss scale: 1.0 | grad norm: 0.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:33] iteration      403/    1000 | consumed samples:        25792 | elapsed time per iteration (ms): 576.8 | learning rate: 3.611142E-05 | global batch size:    64 | lm loss: 7.223933E+00 | loss scale: 1.0 | grad norm: 1.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:34] iteration      404/    1000 | consumed samples:        25856 | elapsed time per iteration (ms): 575.1 | learning rate: 3.601243E-05 | global batch size:    64 | lm loss: 7.079884E+00 | loss scale: 1.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:35] iteration      405/    1000 | consumed samples:        25920 | elapsed time per iteration (ms): 573.4 | learning rate: 3.591341E-05 | global batch size:    64 | lm loss: 7.174758E+00 | loss scale: 1.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:35] iteration      406/    1000 | consumed samples:        25984 | elapsed time per iteration (ms): 573.7 | learning rate: 3.581434E-05 | global batch size:    64 | lm loss: 7.067866E+00 | loss scale: 1.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:36] iteration      407/    1000 | consumed samples:        26048 | elapsed time per iteration (ms): 572.2 | learning rate: 3.571524E-05 | global batch size:    64 | lm loss: 7.185480E+00 | loss scale: 1.0 | grad norm: 1.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:36] iteration      408/    1000 | consumed samples:        26112 | elapsed time per iteration (ms): 571.9 | learning rate: 3.561610E-05 | global batch size:    64 | lm loss: 6.984553E+00 | loss scale: 1.0 | grad norm: 1.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:37] iteration      409/    1000 | consumed samples:        26176 | elapsed time per iteration (ms): 573.5 | learning rate: 3.551692E-05 | global batch size:    64 | lm loss: 7.132291E+00 | loss scale: 1.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:37] iteration      410/    1000 | consumed samples:        26240 | elapsed time per iteration (ms): 573.3 | learning rate: 3.541771E-05 | global batch size:    64 | lm loss: 7.043107E+00 | loss scale: 1.0 | grad norm: 1.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:38] iteration      411/    1000 | consumed samples:        26304 | elapsed time per iteration (ms): 573.9 | learning rate: 3.531847E-05 | global batch size:    64 | lm loss: 7.137520E+00 | loss scale: 1.0 | grad norm: 0.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:39] iteration      412/    1000 | consumed samples:        26368 | elapsed time per iteration (ms): 576.1 | learning rate: 3.521919E-05 | global batch size:    64 | lm loss: 7.026866E+00 | loss scale: 1.0 | grad norm: 1.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:39] iteration      413/    1000 | consumed samples:        26432 | elapsed time per iteration (ms): 574.0 | learning rate: 3.511989E-05 | global batch size:    64 | lm loss: 7.169341E+00 | loss scale: 1.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:40] iteration      414/    1000 | consumed samples:        26496 | elapsed time per iteration (ms): 579.3 | learning rate: 3.502055E-05 | global batch size:    64 | lm loss: 7.112107E+00 | loss scale: 1.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:40] iteration      415/    1000 | consumed samples:        26560 | elapsed time per iteration (ms): 574.2 | learning rate: 3.492119E-05 | global batch size:    64 | lm loss: 7.124896E+00 | loss scale: 1.0 | grad norm: 0.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:41] iteration      416/    1000 | consumed samples:        26624 | elapsed time per iteration (ms): 573.5 | learning rate: 3.482180E-05 | global batch size:    64 | lm loss: 7.099068E+00 | loss scale: 1.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:41] iteration      417/    1000 | consumed samples:        26688 | elapsed time per iteration (ms): 575.0 | learning rate: 3.472239E-05 | global batch size:    64 | lm loss: 7.072133E+00 | loss scale: 1.0 | grad norm: 0.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:42] iteration      418/    1000 | consumed samples:        26752 | elapsed time per iteration (ms): 576.3 | learning rate: 3.462295E-05 | global batch size:    64 | lm loss: 7.078975E+00 | loss scale: 1.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:43] iteration      419/    1000 | consumed samples:        26816 | elapsed time per iteration (ms): 574.6 | learning rate: 3.452349E-05 | global batch size:    64 | lm loss: 7.018066E+00 | loss scale: 1.0 | grad norm: 1.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:43] iteration      420/    1000 | consumed samples:        26880 | elapsed time per iteration (ms): 575.8 | learning rate: 3.442401E-05 | global batch size:    64 | lm loss: 7.084648E+00 | loss scale: 1.0 | grad norm: 0.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:44] iteration      421/    1000 | consumed samples:        26944 | elapsed time per iteration (ms): 575.0 | learning rate: 3.432452E-05 | global batch size:    64 | lm loss: 6.977464E+00 | loss scale: 1.0 | grad norm: 1.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:44] iteration      422/    1000 | consumed samples:        27008 | elapsed time per iteration (ms): 574.4 | learning rate: 3.422500E-05 | global batch size:    64 | lm loss: 7.035352E+00 | loss scale: 1.0 | grad norm: 1.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:45] iteration      423/    1000 | consumed samples:        27072 | elapsed time per iteration (ms): 574.4 | learning rate: 3.412547E-05 | global batch size:    64 | lm loss: 7.030546E+00 | loss scale: 1.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:45] iteration      424/    1000 | consumed samples:        27136 | elapsed time per iteration (ms): 579.1 | learning rate: 3.402592E-05 | global batch size:    64 | lm loss: 6.977574E+00 | loss scale: 1.0 | grad norm: 1.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:46] iteration      425/    1000 | consumed samples:        27200 | elapsed time per iteration (ms): 574.3 | learning rate: 3.392636E-05 | global batch size:    64 | lm loss: 7.109925E+00 | loss scale: 1.0 | grad norm: 1.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:47] iteration      426/    1000 | consumed samples:        27264 | elapsed time per iteration (ms): 575.4 | learning rate: 3.382678E-05 | global batch size:    64 | lm loss: 7.083705E+00 | loss scale: 1.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:47] iteration      427/    1000 | consumed samples:        27328 | elapsed time per iteration (ms): 574.5 | learning rate: 3.372720E-05 | global batch size:    64 | lm loss: 7.064807E+00 | loss scale: 1.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:48] iteration      428/    1000 | consumed samples:        27392 | elapsed time per iteration (ms): 574.3 | learning rate: 3.362760E-05 | global batch size:    64 | lm loss: 7.023304E+00 | loss scale: 1.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:48] iteration      429/    1000 | consumed samples:        27456 | elapsed time per iteration (ms): 575.8 | learning rate: 3.352799E-05 | global batch size:    64 | lm loss: 7.030224E+00 | loss scale: 1.0 | grad norm: 0.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:49] iteration      430/    1000 | consumed samples:        27520 | elapsed time per iteration (ms): 574.9 | learning rate: 3.342838E-05 | global batch size:    64 | lm loss: 7.016523E+00 | loss scale: 1.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:49] iteration      431/    1000 | consumed samples:        27584 | elapsed time per iteration (ms): 573.0 | learning rate: 3.332876E-05 | global batch size:    64 | lm loss: 6.975770E+00 | loss scale: 1.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:50] iteration      432/    1000 | consumed samples:        27648 | elapsed time per iteration (ms): 574.4 | learning rate: 3.322914E-05 | global batch size:    64 | lm loss: 7.052441E+00 | loss scale: 1.0 | grad norm: 0.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:51] iteration      433/    1000 | consumed samples:        27712 | elapsed time per iteration (ms): 572.5 | learning rate: 3.312952E-05 | global batch size:    64 | lm loss: 7.009369E+00 | loss scale: 1.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:51] iteration      434/    1000 | consumed samples:        27776 | elapsed time per iteration (ms): 573.5 | learning rate: 3.302989E-05 | global batch size:    64 | lm loss: 7.140897E+00 | loss scale: 1.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:52] iteration      435/    1000 | consumed samples:        27840 | elapsed time per iteration (ms): 574.1 | learning rate: 3.293026E-05 | global batch size:    64 | lm loss: 7.209428E+00 | loss scale: 1.0 | grad norm: 1.204 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:52] iteration      436/    1000 | consumed samples:        27904 | elapsed time per iteration (ms): 574.6 | learning rate: 3.283063E-05 | global batch size:    64 | lm loss: 6.994057E+00 | loss scale: 1.0 | grad norm: 1.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:53] iteration      437/    1000 | consumed samples:        27968 | elapsed time per iteration (ms): 576.6 | learning rate: 3.273101E-05 | global batch size:    64 | lm loss: 7.130158E+00 | loss scale: 1.0 | grad norm: 1.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:54] iteration      438/    1000 | consumed samples:        28032 | elapsed time per iteration (ms): 573.4 | learning rate: 3.263139E-05 | global batch size:    64 | lm loss: 6.895208E+00 | loss scale: 1.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:54] iteration      439/    1000 | consumed samples:        28096 | elapsed time per iteration (ms): 572.2 | learning rate: 3.253177E-05 | global batch size:    64 | lm loss: 7.002595E+00 | loss scale: 1.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:55] iteration      440/    1000 | consumed samples:        28160 | elapsed time per iteration (ms): 573.7 | learning rate: 3.243216E-05 | global batch size:    64 | lm loss: 6.877927E+00 | loss scale: 1.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:55] iteration      441/    1000 | consumed samples:        28224 | elapsed time per iteration (ms): 574.2 | learning rate: 3.233256E-05 | global batch size:    64 | lm loss: 7.142058E+00 | loss scale: 1.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:56] iteration      442/    1000 | consumed samples:        28288 | elapsed time per iteration (ms): 574.8 | learning rate: 3.223297E-05 | global batch size:    64 | lm loss: 7.130456E+00 | loss scale: 1.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:56] iteration      443/    1000 | consumed samples:        28352 | elapsed time per iteration (ms): 576.6 | learning rate: 3.213339E-05 | global batch size:    64 | lm loss: 7.092595E+00 | loss scale: 1.0 | grad norm: 1.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:57] iteration      444/    1000 | consumed samples:        28416 | elapsed time per iteration (ms): 572.7 | learning rate: 3.203382E-05 | global batch size:    64 | lm loss: 7.001563E+00 | loss scale: 1.0 | grad norm: 1.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:58] iteration      445/    1000 | consumed samples:        28480 | elapsed time per iteration (ms): 571.8 | learning rate: 3.193426E-05 | global batch size:    64 | lm loss: 6.986020E+00 | loss scale: 1.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:58] iteration      446/    1000 | consumed samples:        28544 | elapsed time per iteration (ms): 572.2 | learning rate: 3.183472E-05 | global batch size:    64 | lm loss: 7.126220E+00 | loss scale: 1.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:59] iteration      447/    1000 | consumed samples:        28608 | elapsed time per iteration (ms): 572.8 | learning rate: 3.173519E-05 | global batch size:    64 | lm loss: 6.831724E+00 | loss scale: 1.0 | grad norm: 1.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:02:59] iteration      448/    1000 | consumed samples:        28672 | elapsed time per iteration (ms): 572.6 | learning rate: 3.163568E-05 | global batch size:    64 | lm loss: 7.050341E+00 | loss scale: 1.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:00] iteration      449/    1000 | consumed samples:        28736 | elapsed time per iteration (ms): 572.2 | learning rate: 3.153619E-05 | global batch size:    64 | lm loss: 6.909424E+00 | loss scale: 1.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:00] iteration      450/    1000 | consumed samples:        28800 | elapsed time per iteration (ms): 571.8 | learning rate: 3.143672E-05 | global batch size:    64 | lm loss: 7.073241E+00 | loss scale: 1.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:01] iteration      451/    1000 | consumed samples:        28864 | elapsed time per iteration (ms): 572.5 | learning rate: 3.133727E-05 | global batch size:    64 | lm loss: 6.986821E+00 | loss scale: 1.0 | grad norm: 0.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:02] iteration      452/    1000 | consumed samples:        28928 | elapsed time per iteration (ms): 572.8 | learning rate: 3.123784E-05 | global batch size:    64 | lm loss: 7.053772E+00 | loss scale: 1.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:02] iteration      453/    1000 | consumed samples:        28992 | elapsed time per iteration (ms): 572.4 | learning rate: 3.113844E-05 | global batch size:    64 | lm loss: 6.919184E+00 | loss scale: 1.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:03] iteration      454/    1000 | consumed samples:        29056 | elapsed time per iteration (ms): 572.2 | learning rate: 3.103906E-05 | global batch size:    64 | lm loss: 6.956500E+00 | loss scale: 1.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:03] iteration      455/    1000 | consumed samples:        29120 | elapsed time per iteration (ms): 576.5 | learning rate: 3.093971E-05 | global batch size:    64 | lm loss: 6.923730E+00 | loss scale: 1.0 | grad norm: 0.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:04] iteration      456/    1000 | consumed samples:        29184 | elapsed time per iteration (ms): 574.7 | learning rate: 3.084039E-05 | global batch size:    64 | lm loss: 7.080750E+00 | loss scale: 1.0 | grad norm: 0.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:04] iteration      457/    1000 | consumed samples:        29248 | elapsed time per iteration (ms): 575.2 | learning rate: 3.074110E-05 | global batch size:    64 | lm loss: 6.940975E+00 | loss scale: 1.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:05] iteration      458/    1000 | consumed samples:        29312 | elapsed time per iteration (ms): 573.3 | learning rate: 3.064183E-05 | global batch size:    64 | lm loss: 6.991790E+00 | loss scale: 1.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:06] iteration      459/    1000 | consumed samples:        29376 | elapsed time per iteration (ms): 572.7 | learning rate: 3.054260E-05 | global batch size:    64 | lm loss: 7.102522E+00 | loss scale: 1.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:06] iteration      460/    1000 | consumed samples:        29440 | elapsed time per iteration (ms): 572.8 | learning rate: 3.044341E-05 | global batch size:    64 | lm loss: 6.943542E+00 | loss scale: 1.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:07] iteration      461/    1000 | consumed samples:        29504 | elapsed time per iteration (ms): 574.7 | learning rate: 3.034424E-05 | global batch size:    64 | lm loss: 7.104074E+00 | loss scale: 1.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:07] iteration      462/    1000 | consumed samples:        29568 | elapsed time per iteration (ms): 574.5 | learning rate: 3.024512E-05 | global batch size:    64 | lm loss: 7.000802E+00 | loss scale: 1.0 | grad norm: 0.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:08] iteration      463/    1000 | consumed samples:        29632 | elapsed time per iteration (ms): 575.0 | learning rate: 3.014603E-05 | global batch size:    64 | lm loss: 6.947737E+00 | loss scale: 1.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:08] iteration      464/    1000 | consumed samples:        29696 | elapsed time per iteration (ms): 573.3 | learning rate: 3.004698E-05 | global batch size:    64 | lm loss: 6.949141E+00 | loss scale: 1.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:09] iteration      465/    1000 | consumed samples:        29760 | elapsed time per iteration (ms): 573.8 | learning rate: 2.994797E-05 | global batch size:    64 | lm loss: 7.093202E+00 | loss scale: 1.0 | grad norm: 1.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:10] iteration      466/    1000 | consumed samples:        29824 | elapsed time per iteration (ms): 572.0 | learning rate: 2.984900E-05 | global batch size:    64 | lm loss: 7.137239E+00 | loss scale: 1.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:10] iteration      467/    1000 | consumed samples:        29888 | elapsed time per iteration (ms): 573.7 | learning rate: 2.975007E-05 | global batch size:    64 | lm loss: 6.865737E+00 | loss scale: 1.0 | grad norm: 1.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:11] iteration      468/    1000 | consumed samples:        29952 | elapsed time per iteration (ms): 574.7 | learning rate: 2.965119E-05 | global batch size:    64 | lm loss: 7.255801E+00 | loss scale: 1.0 | grad norm: 0.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:11] iteration      469/    1000 | consumed samples:        30016 | elapsed time per iteration (ms): 574.9 | learning rate: 2.955236E-05 | global batch size:    64 | lm loss: 6.909060E+00 | loss scale: 1.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:12] iteration      470/    1000 | consumed samples:        30080 | elapsed time per iteration (ms): 573.9 | learning rate: 2.945357E-05 | global batch size:    64 | lm loss: 7.071111E+00 | loss scale: 1.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:12] iteration      471/    1000 | consumed samples:        30144 | elapsed time per iteration (ms): 571.9 | learning rate: 2.935483E-05 | global batch size:    64 | lm loss: 6.875853E+00 | loss scale: 1.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:13] iteration      472/    1000 | consumed samples:        30208 | elapsed time per iteration (ms): 572.1 | learning rate: 2.925614E-05 | global batch size:    64 | lm loss: 6.878527E+00 | loss scale: 1.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:14] iteration      473/    1000 | consumed samples:        30272 | elapsed time per iteration (ms): 572.3 | learning rate: 2.915750E-05 | global batch size:    64 | lm loss: 7.070252E+00 | loss scale: 1.0 | grad norm: 0.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:14] iteration      474/    1000 | consumed samples:        30336 | elapsed time per iteration (ms): 573.4 | learning rate: 2.905891E-05 | global batch size:    64 | lm loss: 7.045511E+00 | loss scale: 1.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:15] iteration      475/    1000 | consumed samples:        30400 | elapsed time per iteration (ms): 573.0 | learning rate: 2.896038E-05 | global batch size:    64 | lm loss: 6.994950E+00 | loss scale: 1.0 | grad norm: 1.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:15] iteration      476/    1000 | consumed samples:        30464 | elapsed time per iteration (ms): 570.9 | learning rate: 2.886190E-05 | global batch size:    64 | lm loss: 7.011608E+00 | loss scale: 1.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:16] iteration      477/    1000 | consumed samples:        30528 | elapsed time per iteration (ms): 572.3 | learning rate: 2.876348E-05 | global batch size:    64 | lm loss: 6.939725E+00 | loss scale: 1.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:16] iteration      478/    1000 | consumed samples:        30592 | elapsed time per iteration (ms): 575.3 | learning rate: 2.866511E-05 | global batch size:    64 | lm loss: 6.986340E+00 | loss scale: 1.0 | grad norm: 1.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:17] iteration      479/    1000 | consumed samples:        30656 | elapsed time per iteration (ms): 574.0 | learning rate: 2.856681E-05 | global batch size:    64 | lm loss: 6.896735E+00 | loss scale: 1.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:18] iteration      480/    1000 | consumed samples:        30720 | elapsed time per iteration (ms): 573.0 | learning rate: 2.846856E-05 | global batch size:    64 | lm loss: 6.893528E+00 | loss scale: 1.0 | grad norm: 1.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:18] iteration      481/    1000 | consumed samples:        30784 | elapsed time per iteration (ms): 572.4 | learning rate: 2.837038E-05 | global batch size:    64 | lm loss: 6.951463E+00 | loss scale: 1.0 | grad norm: 1.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:19] iteration      482/    1000 | consumed samples:        30848 | elapsed time per iteration (ms): 572.1 | learning rate: 2.827226E-05 | global batch size:    64 | lm loss: 6.940909E+00 | loss scale: 1.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:19] iteration      483/    1000 | consumed samples:        30912 | elapsed time per iteration (ms): 572.9 | learning rate: 2.817420E-05 | global batch size:    64 | lm loss: 7.100181E+00 | loss scale: 1.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:20] iteration      484/    1000 | consumed samples:        30976 | elapsed time per iteration (ms): 572.2 | learning rate: 2.807621E-05 | global batch size:    64 | lm loss: 6.892660E+00 | loss scale: 1.0 | grad norm: 1.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:20] iteration      485/    1000 | consumed samples:        31040 | elapsed time per iteration (ms): 571.7 | learning rate: 2.797829E-05 | global batch size:    64 | lm loss: 7.117290E+00 | loss scale: 1.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:21] iteration      486/    1000 | consumed samples:        31104 | elapsed time per iteration (ms): 572.4 | learning rate: 2.788043E-05 | global batch size:    64 | lm loss: 6.913658E+00 | loss scale: 1.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:22] iteration      487/    1000 | consumed samples:        31168 | elapsed time per iteration (ms): 572.7 | learning rate: 2.778265E-05 | global batch size:    64 | lm loss: 7.100808E+00 | loss scale: 1.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:22] iteration      488/    1000 | consumed samples:        31232 | elapsed time per iteration (ms): 575.0 | learning rate: 2.768494E-05 | global batch size:    64 | lm loss: 7.017686E+00 | loss scale: 1.0 | grad norm: 1.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:23] iteration      489/    1000 | consumed samples:        31296 | elapsed time per iteration (ms): 575.7 | learning rate: 2.758729E-05 | global batch size:    64 | lm loss: 7.038564E+00 | loss scale: 1.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:23] iteration      490/    1000 | consumed samples:        31360 | elapsed time per iteration (ms): 573.6 | learning rate: 2.748972E-05 | global batch size:    64 | lm loss: 7.033812E+00 | loss scale: 1.0 | grad norm: 0.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:24] iteration      491/    1000 | consumed samples:        31424 | elapsed time per iteration (ms): 573.6 | learning rate: 2.739223E-05 | global batch size:    64 | lm loss: 7.068769E+00 | loss scale: 1.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:24] iteration      492/    1000 | consumed samples:        31488 | elapsed time per iteration (ms): 573.7 | learning rate: 2.729481E-05 | global batch size:    64 | lm loss: 7.047596E+00 | loss scale: 1.0 | grad norm: 1.201 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:25] iteration      493/    1000 | consumed samples:        31552 | elapsed time per iteration (ms): 572.3 | learning rate: 2.719747E-05 | global batch size:    64 | lm loss: 7.178223E+00 | loss scale: 1.0 | grad norm: 0.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:26] iteration      494/    1000 | consumed samples:        31616 | elapsed time per iteration (ms): 572.2 | learning rate: 2.710022E-05 | global batch size:    64 | lm loss: 6.829030E+00 | loss scale: 1.0 | grad norm: 0.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:26] iteration      495/    1000 | consumed samples:        31680 | elapsed time per iteration (ms): 572.0 | learning rate: 2.700304E-05 | global batch size:    64 | lm loss: 7.058404E+00 | loss scale: 1.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:27] iteration      496/    1000 | consumed samples:        31744 | elapsed time per iteration (ms): 573.3 | learning rate: 2.690594E-05 | global batch size:    64 | lm loss: 7.011428E+00 | loss scale: 1.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:27] iteration      497/    1000 | consumed samples:        31808 | elapsed time per iteration (ms): 572.8 | learning rate: 2.680892E-05 | global batch size:    64 | lm loss: 7.051127E+00 | loss scale: 1.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:28] iteration      498/    1000 | consumed samples:        31872 | elapsed time per iteration (ms): 571.7 | learning rate: 2.671199E-05 | global batch size:    64 | lm loss: 6.893631E+00 | loss scale: 1.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:28] iteration      499/    1000 | consumed samples:        31936 | elapsed time per iteration (ms): 572.6 | learning rate: 2.661515E-05 | global batch size:    64 | lm loss: 7.084702E+00 | loss scale: 1.0 | grad norm: 0.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:29] iteration      500/    1000 | consumed samples:        32000 | elapsed time per iteration (ms): 572.3 | learning rate: 2.651839E-05 | global batch size:    64 | lm loss: 6.962146E+00 | loss scale: 1.0 | grad norm: 1.320 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:30] iteration      501/    1000 | consumed samples:        32064 | elapsed time per iteration (ms): 572.0 | learning rate: 2.642172E-05 | global batch size:    64 | lm loss: 6.939859E+00 | loss scale: 1.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:30] iteration      502/    1000 | consumed samples:        32128 | elapsed time per iteration (ms): 572.0 | learning rate: 2.632514E-05 | global batch size:    64 | lm loss: 6.819113E+00 | loss scale: 1.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:31] iteration      503/    1000 | consumed samples:        32192 | elapsed time per iteration (ms): 573.2 | learning rate: 2.622865E-05 | global batch size:    64 | lm loss: 6.959420E+00 | loss scale: 1.0 | grad norm: 1.194 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:31] iteration      504/    1000 | consumed samples:        32256 | elapsed time per iteration (ms): 571.7 | learning rate: 2.613225E-05 | global batch size:    64 | lm loss: 6.882554E+00 | loss scale: 1.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:32] iteration      505/    1000 | consumed samples:        32320 | elapsed time per iteration (ms): 573.7 | learning rate: 2.603595E-05 | global batch size:    64 | lm loss: 7.039774E+00 | loss scale: 1.0 | grad norm: 0.977 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:32] iteration      506/    1000 | consumed samples:        32384 | elapsed time per iteration (ms): 574.0 | learning rate: 2.593974E-05 | global batch size:    64 | lm loss: 7.090798E+00 | loss scale: 1.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:33] iteration      507/    1000 | consumed samples:        32448 | elapsed time per iteration (ms): 577.2 | learning rate: 2.584362E-05 | global batch size:    64 | lm loss: 6.894325E+00 | loss scale: 1.0 | grad norm: 1.126 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:34] iteration      508/    1000 | consumed samples:        32512 | elapsed time per iteration (ms): 574.7 | learning rate: 2.574761E-05 | global batch size:    64 | lm loss: 6.986589E+00 | loss scale: 1.0 | grad norm: 1.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:34] iteration      509/    1000 | consumed samples:        32576 | elapsed time per iteration (ms): 573.0 | learning rate: 2.565169E-05 | global batch size:    64 | lm loss: 7.103178E+00 | loss scale: 1.0 | grad norm: 0.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:35] iteration      510/    1000 | consumed samples:        32640 | elapsed time per iteration (ms): 572.3 | learning rate: 2.555588E-05 | global batch size:    64 | lm loss: 7.027277E+00 | loss scale: 1.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:35] iteration      511/    1000 | consumed samples:        32704 | elapsed time per iteration (ms): 576.9 | learning rate: 2.546016E-05 | global batch size:    64 | lm loss: 7.151406E+00 | loss scale: 1.0 | grad norm: 0.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:36] iteration      512/    1000 | consumed samples:        32768 | elapsed time per iteration (ms): 573.5 | learning rate: 2.536455E-05 | global batch size:    64 | lm loss: 6.913819E+00 | loss scale: 1.0 | grad norm: 0.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:37] iteration      513/    1000 | consumed samples:        32832 | elapsed time per iteration (ms): 572.5 | learning rate: 2.526904E-05 | global batch size:    64 | lm loss: 6.923087E+00 | loss scale: 1.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:37] iteration      514/    1000 | consumed samples:        32896 | elapsed time per iteration (ms): 573.7 | learning rate: 2.517364E-05 | global batch size:    64 | lm loss: 7.051707E+00 | loss scale: 1.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:38] iteration      515/    1000 | consumed samples:        32960 | elapsed time per iteration (ms): 571.5 | learning rate: 2.507834E-05 | global batch size:    64 | lm loss: 7.019988E+00 | loss scale: 1.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:38] iteration      516/    1000 | consumed samples:        33024 | elapsed time per iteration (ms): 572.0 | learning rate: 2.498315E-05 | global batch size:    64 | lm loss: 6.876295E+00 | loss scale: 1.0 | grad norm: 0.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:39] iteration      517/    1000 | consumed samples:        33088 | elapsed time per iteration (ms): 574.8 | learning rate: 2.488807E-05 | global batch size:    64 | lm loss: 6.996930E+00 | loss scale: 1.0 | grad norm: 0.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:39] iteration      518/    1000 | consumed samples:        33152 | elapsed time per iteration (ms): 573.9 | learning rate: 2.479310E-05 | global batch size:    64 | lm loss: 6.835086E+00 | loss scale: 1.0 | grad norm: 1.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:40] iteration      519/    1000 | consumed samples:        33216 | elapsed time per iteration (ms): 574.8 | learning rate: 2.469824E-05 | global batch size:    64 | lm loss: 7.024619E+00 | loss scale: 1.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:41] iteration      520/    1000 | consumed samples:        33280 | elapsed time per iteration (ms): 574.7 | learning rate: 2.460350E-05 | global batch size:    64 | lm loss: 7.052673E+00 | loss scale: 1.0 | grad norm: 0.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:41] iteration      521/    1000 | consumed samples:        33344 | elapsed time per iteration (ms): 573.8 | learning rate: 2.450887E-05 | global batch size:    64 | lm loss: 6.902267E+00 | loss scale: 1.0 | grad norm: 1.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:42] iteration      522/    1000 | consumed samples:        33408 | elapsed time per iteration (ms): 572.6 | learning rate: 2.441435E-05 | global batch size:    64 | lm loss: 6.884510E+00 | loss scale: 1.0 | grad norm: 1.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:42] iteration      523/    1000 | consumed samples:        33472 | elapsed time per iteration (ms): 574.5 | learning rate: 2.431996E-05 | global batch size:    64 | lm loss: 6.986134E+00 | loss scale: 1.0 | grad norm: 1.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:43] iteration      524/    1000 | consumed samples:        33536 | elapsed time per iteration (ms): 574.3 | learning rate: 2.422568E-05 | global batch size:    64 | lm loss: 6.947647E+00 | loss scale: 1.0 | grad norm: 1.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:43] iteration      525/    1000 | consumed samples:        33600 | elapsed time per iteration (ms): 573.2 | learning rate: 2.413152E-05 | global batch size:    64 | lm loss: 7.034398E+00 | loss scale: 1.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:44] iteration      526/    1000 | consumed samples:        33664 | elapsed time per iteration (ms): 571.8 | learning rate: 2.403748E-05 | global batch size:    64 | lm loss: 6.943417E+00 | loss scale: 1.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:45] iteration      527/    1000 | consumed samples:        33728 | elapsed time per iteration (ms): 572.6 | learning rate: 2.394356E-05 | global batch size:    64 | lm loss: 6.847207E+00 | loss scale: 1.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:45] iteration      528/    1000 | consumed samples:        33792 | elapsed time per iteration (ms): 573.6 | learning rate: 2.384977E-05 | global batch size:    64 | lm loss: 7.036130E+00 | loss scale: 1.0 | grad norm: 1.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:46] iteration      529/    1000 | consumed samples:        33856 | elapsed time per iteration (ms): 571.4 | learning rate: 2.375609E-05 | global batch size:    64 | lm loss: 7.116331E+00 | loss scale: 1.0 | grad norm: 0.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:46] iteration      530/    1000 | consumed samples:        33920 | elapsed time per iteration (ms): 572.1 | learning rate: 2.366255E-05 | global batch size:    64 | lm loss: 6.908103E+00 | loss scale: 1.0 | grad norm: 1.230 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:47] iteration      531/    1000 | consumed samples:        33984 | elapsed time per iteration (ms): 577.2 | learning rate: 2.356914E-05 | global batch size:    64 | lm loss: 7.051898E+00 | loss scale: 1.0 | grad norm: 1.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:47] iteration      532/    1000 | consumed samples:        34048 | elapsed time per iteration (ms): 575.6 | learning rate: 2.347585E-05 | global batch size:    64 | lm loss: 7.043319E+00 | loss scale: 1.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:48] iteration      533/    1000 | consumed samples:        34112 | elapsed time per iteration (ms): 576.7 | learning rate: 2.338269E-05 | global batch size:    64 | lm loss: 6.940388E+00 | loss scale: 1.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:49] iteration      534/    1000 | consumed samples:        34176 | elapsed time per iteration (ms): 576.1 | learning rate: 2.328966E-05 | global batch size:    64 | lm loss: 7.146618E+00 | loss scale: 1.0 | grad norm: 1.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:49] iteration      535/    1000 | consumed samples:        34240 | elapsed time per iteration (ms): 573.8 | learning rate: 2.319677E-05 | global batch size:    64 | lm loss: 6.981420E+00 | loss scale: 1.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:50] iteration      536/    1000 | consumed samples:        34304 | elapsed time per iteration (ms): 575.0 | learning rate: 2.310400E-05 | global batch size:    64 | lm loss: 6.949132E+00 | loss scale: 1.0 | grad norm: 0.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:50] iteration      537/    1000 | consumed samples:        34368 | elapsed time per iteration (ms): 572.5 | learning rate: 2.301138E-05 | global batch size:    64 | lm loss: 6.959675E+00 | loss scale: 1.0 | grad norm: 0.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:51] iteration      538/    1000 | consumed samples:        34432 | elapsed time per iteration (ms): 571.6 | learning rate: 2.291888E-05 | global batch size:    64 | lm loss: 6.964067E+00 | loss scale: 1.0 | grad norm: 0.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:51] iteration      539/    1000 | consumed samples:        34496 | elapsed time per iteration (ms): 572.4 | learning rate: 2.282653E-05 | global batch size:    64 | lm loss: 7.015441E+00 | loss scale: 1.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:52] iteration      540/    1000 | consumed samples:        34560 | elapsed time per iteration (ms): 573.2 | learning rate: 2.273432E-05 | global batch size:    64 | lm loss: 6.895053E+00 | loss scale: 1.0 | grad norm: 0.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:53] iteration      541/    1000 | consumed samples:        34624 | elapsed time per iteration (ms): 573.1 | learning rate: 2.264224E-05 | global batch size:    64 | lm loss: 6.962163E+00 | loss scale: 1.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:53] iteration      542/    1000 | consumed samples:        34688 | elapsed time per iteration (ms): 572.1 | learning rate: 2.255031E-05 | global batch size:    64 | lm loss: 6.882352E+00 | loss scale: 1.0 | grad norm: 1.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:54] iteration      543/    1000 | consumed samples:        34752 | elapsed time per iteration (ms): 572.3 | learning rate: 2.245851E-05 | global batch size:    64 | lm loss: 6.894572E+00 | loss scale: 1.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:54] iteration      544/    1000 | consumed samples:        34816 | elapsed time per iteration (ms): 574.5 | learning rate: 2.236686E-05 | global batch size:    64 | lm loss: 7.020858E+00 | loss scale: 1.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:55] iteration      545/    1000 | consumed samples:        34880 | elapsed time per iteration (ms): 574.4 | learning rate: 2.227536E-05 | global batch size:    64 | lm loss: 7.016066E+00 | loss scale: 1.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:55] iteration      546/    1000 | consumed samples:        34944 | elapsed time per iteration (ms): 574.2 | learning rate: 2.218400E-05 | global batch size:    64 | lm loss: 6.919110E+00 | loss scale: 1.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:56] iteration      547/    1000 | consumed samples:        35008 | elapsed time per iteration (ms): 572.6 | learning rate: 2.209279E-05 | global batch size:    64 | lm loss: 6.908974E+00 | loss scale: 1.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:57] iteration      548/    1000 | consumed samples:        35072 | elapsed time per iteration (ms): 572.4 | learning rate: 2.200173E-05 | global batch size:    64 | lm loss: 6.934503E+00 | loss scale: 1.0 | grad norm: 0.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:57] iteration      549/    1000 | consumed samples:        35136 | elapsed time per iteration (ms): 572.0 | learning rate: 2.191082E-05 | global batch size:    64 | lm loss: 6.950576E+00 | loss scale: 1.0 | grad norm: 0.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:58] iteration      550/    1000 | consumed samples:        35200 | elapsed time per iteration (ms): 573.9 | learning rate: 2.182006E-05 | global batch size:    64 | lm loss: 6.991609E+00 | loss scale: 1.0 | grad norm: 1.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:58] iteration      551/    1000 | consumed samples:        35264 | elapsed time per iteration (ms): 571.3 | learning rate: 2.172945E-05 | global batch size:    64 | lm loss: 6.901278E+00 | loss scale: 1.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:59] iteration      552/    1000 | consumed samples:        35328 | elapsed time per iteration (ms): 572.2 | learning rate: 2.163899E-05 | global batch size:    64 | lm loss: 7.043581E+00 | loss scale: 1.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:03:59] iteration      553/    1000 | consumed samples:        35392 | elapsed time per iteration (ms): 575.6 | learning rate: 2.154869E-05 | global batch size:    64 | lm loss: 6.924660E+00 | loss scale: 1.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:00] iteration      554/    1000 | consumed samples:        35456 | elapsed time per iteration (ms): 572.8 | learning rate: 2.145855E-05 | global batch size:    64 | lm loss: 6.839377E+00 | loss scale: 1.0 | grad norm: 0.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:01] iteration      555/    1000 | consumed samples:        35520 | elapsed time per iteration (ms): 573.2 | learning rate: 2.136856E-05 | global batch size:    64 | lm loss: 6.968170E+00 | loss scale: 1.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:01] iteration      556/    1000 | consumed samples:        35584 | elapsed time per iteration (ms): 572.7 | learning rate: 2.127873E-05 | global batch size:    64 | lm loss: 6.878457E+00 | loss scale: 1.0 | grad norm: 1.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:02] iteration      557/    1000 | consumed samples:        35648 | elapsed time per iteration (ms): 574.0 | learning rate: 2.118906E-05 | global batch size:    64 | lm loss: 6.820457E+00 | loss scale: 1.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:02] iteration      558/    1000 | consumed samples:        35712 | elapsed time per iteration (ms): 572.9 | learning rate: 2.109955E-05 | global batch size:    64 | lm loss: 6.945590E+00 | loss scale: 1.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:03] iteration      559/    1000 | consumed samples:        35776 | elapsed time per iteration (ms): 574.5 | learning rate: 2.101020E-05 | global batch size:    64 | lm loss: 6.871126E+00 | loss scale: 1.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:03] iteration      560/    1000 | consumed samples:        35840 | elapsed time per iteration (ms): 573.9 | learning rate: 2.092102E-05 | global batch size:    64 | lm loss: 6.920827E+00 | loss scale: 1.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:04] iteration      561/    1000 | consumed samples:        35904 | elapsed time per iteration (ms): 573.2 | learning rate: 2.083200E-05 | global batch size:    64 | lm loss: 6.946211E+00 | loss scale: 1.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:05] iteration      562/    1000 | consumed samples:        35968 | elapsed time per iteration (ms): 572.4 | learning rate: 2.074314E-05 | global batch size:    64 | lm loss: 6.877362E+00 | loss scale: 1.0 | grad norm: 1.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:05] iteration      563/    1000 | consumed samples:        36032 | elapsed time per iteration (ms): 571.2 | learning rate: 2.065446E-05 | global batch size:    64 | lm loss: 7.012761E+00 | loss scale: 1.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:06] iteration      564/    1000 | consumed samples:        36096 | elapsed time per iteration (ms): 573.1 | learning rate: 2.056594E-05 | global batch size:    64 | lm loss: 6.862052E+00 | loss scale: 1.0 | grad norm: 0.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:06] iteration      565/    1000 | consumed samples:        36160 | elapsed time per iteration (ms): 572.8 | learning rate: 2.047759E-05 | global batch size:    64 | lm loss: 7.020303E+00 | loss scale: 1.0 | grad norm: 0.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:07] iteration      566/    1000 | consumed samples:        36224 | elapsed time per iteration (ms): 574.4 | learning rate: 2.038941E-05 | global batch size:    64 | lm loss: 7.041045E+00 | loss scale: 1.0 | grad norm: 0.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:07] iteration      567/    1000 | consumed samples:        36288 | elapsed time per iteration (ms): 574.8 | learning rate: 2.030140E-05 | global batch size:    64 | lm loss: 6.934620E+00 | loss scale: 1.0 | grad norm: 1.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:08] iteration      568/    1000 | consumed samples:        36352 | elapsed time per iteration (ms): 574.6 | learning rate: 2.021357E-05 | global batch size:    64 | lm loss: 6.924976E+00 | loss scale: 1.0 | grad norm: 0.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:09] iteration      569/    1000 | consumed samples:        36416 | elapsed time per iteration (ms): 574.5 | learning rate: 2.012591E-05 | global batch size:    64 | lm loss: 6.932202E+00 | loss scale: 1.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:09] iteration      570/    1000 | consumed samples:        36480 | elapsed time per iteration (ms): 573.0 | learning rate: 2.003842E-05 | global batch size:    64 | lm loss: 7.099931E+00 | loss scale: 1.0 | grad norm: 0.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:10] iteration      571/    1000 | consumed samples:        36544 | elapsed time per iteration (ms): 572.5 | learning rate: 1.995111E-05 | global batch size:    64 | lm loss: 6.869479E+00 | loss scale: 1.0 | grad norm: 1.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:10] iteration      572/    1000 | consumed samples:        36608 | elapsed time per iteration (ms): 574.1 | learning rate: 1.986398E-05 | global batch size:    64 | lm loss: 6.937565E+00 | loss scale: 1.0 | grad norm: 1.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:11] iteration      573/    1000 | consumed samples:        36672 | elapsed time per iteration (ms): 573.9 | learning rate: 1.977703E-05 | global batch size:    64 | lm loss: 6.900385E+00 | loss scale: 1.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:12] iteration      574/    1000 | consumed samples:        36736 | elapsed time per iteration (ms): 573.3 | learning rate: 1.969026E-05 | global batch size:    64 | lm loss: 6.890650E+00 | loss scale: 1.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:12] iteration      575/    1000 | consumed samples:        36800 | elapsed time per iteration (ms): 572.6 | learning rate: 1.960367E-05 | global batch size:    64 | lm loss: 6.858618E+00 | loss scale: 1.0 | grad norm: 1.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:13] iteration      576/    1000 | consumed samples:        36864 | elapsed time per iteration (ms): 573.9 | learning rate: 1.951726E-05 | global batch size:    64 | lm loss: 6.852910E+00 | loss scale: 1.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:13] iteration      577/    1000 | consumed samples:        36928 | elapsed time per iteration (ms): 575.3 | learning rate: 1.943103E-05 | global batch size:    64 | lm loss: 6.983173E+00 | loss scale: 1.0 | grad norm: 1.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:14] iteration      578/    1000 | consumed samples:        36992 | elapsed time per iteration (ms): 573.5 | learning rate: 1.934499E-05 | global batch size:    64 | lm loss: 6.934175E+00 | loss scale: 1.0 | grad norm: 0.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:14] iteration      579/    1000 | consumed samples:        37056 | elapsed time per iteration (ms): 577.2 | learning rate: 1.925914E-05 | global batch size:    64 | lm loss: 6.767864E+00 | loss scale: 1.0 | grad norm: 1.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:15] iteration      580/    1000 | consumed samples:        37120 | elapsed time per iteration (ms): 575.7 | learning rate: 1.917347E-05 | global batch size:    64 | lm loss: 6.964623E+00 | loss scale: 1.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:16] iteration      581/    1000 | consumed samples:        37184 | elapsed time per iteration (ms): 573.7 | learning rate: 1.908799E-05 | global batch size:    64 | lm loss: 6.984540E+00 | loss scale: 1.0 | grad norm: 0.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:16] iteration      582/    1000 | consumed samples:        37248 | elapsed time per iteration (ms): 571.8 | learning rate: 1.900271E-05 | global batch size:    64 | lm loss: 6.859042E+00 | loss scale: 1.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:17] iteration      583/    1000 | consumed samples:        37312 | elapsed time per iteration (ms): 573.2 | learning rate: 1.891761E-05 | global batch size:    64 | lm loss: 6.847617E+00 | loss scale: 1.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:17] iteration      584/    1000 | consumed samples:        37376 | elapsed time per iteration (ms): 572.8 | learning rate: 1.883270E-05 | global batch size:    64 | lm loss: 6.953912E+00 | loss scale: 1.0 | grad norm: 0.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:18] iteration      585/    1000 | consumed samples:        37440 | elapsed time per iteration (ms): 572.1 | learning rate: 1.874799E-05 | global batch size:    64 | lm loss: 7.001646E+00 | loss scale: 1.0 | grad norm: 1.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:18] iteration      586/    1000 | consumed samples:        37504 | elapsed time per iteration (ms): 572.1 | learning rate: 1.866346E-05 | global batch size:    64 | lm loss: 7.037690E+00 | loss scale: 1.0 | grad norm: 0.918 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:19] iteration      587/    1000 | consumed samples:        37568 | elapsed time per iteration (ms): 573.3 | learning rate: 1.857914E-05 | global batch size:    64 | lm loss: 6.895725E+00 | loss scale: 1.0 | grad norm: 1.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:20] iteration      588/    1000 | consumed samples:        37632 | elapsed time per iteration (ms): 572.3 | learning rate: 1.849501E-05 | global batch size:    64 | lm loss: 6.917046E+00 | loss scale: 1.0 | grad norm: 1.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:20] iteration      589/    1000 | consumed samples:        37696 | elapsed time per iteration (ms): 573.5 | learning rate: 1.841108E-05 | global batch size:    64 | lm loss: 6.883592E+00 | loss scale: 1.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:21] iteration      590/    1000 | consumed samples:        37760 | elapsed time per iteration (ms): 573.4 | learning rate: 1.832735E-05 | global batch size:    64 | lm loss: 6.777170E+00 | loss scale: 1.0 | grad norm: 0.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:21] iteration      591/    1000 | consumed samples:        37824 | elapsed time per iteration (ms): 574.0 | learning rate: 1.824381E-05 | global batch size:    64 | lm loss: 6.910943E+00 | loss scale: 1.0 | grad norm: 1.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:22] iteration      592/    1000 | consumed samples:        37888 | elapsed time per iteration (ms): 578.1 | learning rate: 1.816048E-05 | global batch size:    64 | lm loss: 6.786879E+00 | loss scale: 1.0 | grad norm: 0.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:22] iteration      593/    1000 | consumed samples:        37952 | elapsed time per iteration (ms): 575.3 | learning rate: 1.807735E-05 | global batch size:    64 | lm loss: 6.871988E+00 | loss scale: 1.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:23] iteration      594/    1000 | consumed samples:        38016 | elapsed time per iteration (ms): 573.4 | learning rate: 1.799443E-05 | global batch size:    64 | lm loss: 6.952513E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:24] iteration      595/    1000 | consumed samples:        38080 | elapsed time per iteration (ms): 572.5 | learning rate: 1.791171E-05 | global batch size:    64 | lm loss: 6.950261E+00 | loss scale: 1.0 | grad norm: 1.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:24] iteration      596/    1000 | consumed samples:        38144 | elapsed time per iteration (ms): 572.3 | learning rate: 1.782919E-05 | global batch size:    64 | lm loss: 7.002854E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:25] iteration      597/    1000 | consumed samples:        38208 | elapsed time per iteration (ms): 573.2 | learning rate: 1.774688E-05 | global batch size:    64 | lm loss: 6.950767E+00 | loss scale: 1.0 | grad norm: 1.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:25] iteration      598/    1000 | consumed samples:        38272 | elapsed time per iteration (ms): 572.6 | learning rate: 1.766478E-05 | global batch size:    64 | lm loss: 6.985342E+00 | loss scale: 1.0 | grad norm: 0.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:26] iteration      599/    1000 | consumed samples:        38336 | elapsed time per iteration (ms): 576.7 | learning rate: 1.758288E-05 | global batch size:    64 | lm loss: 6.873536E+00 | loss scale: 1.0 | grad norm: 1.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:26] iteration      600/    1000 | consumed samples:        38400 | elapsed time per iteration (ms): 576.2 | learning rate: 1.750120E-05 | global batch size:    64 | lm loss: 6.882525E+00 | loss scale: 1.0 | grad norm: 1.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:27] iteration      601/    1000 | consumed samples:        38464 | elapsed time per iteration (ms): 573.4 | learning rate: 1.741972E-05 | global batch size:    64 | lm loss: 6.947653E+00 | loss scale: 1.0 | grad norm: 1.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:28] iteration      602/    1000 | consumed samples:        38528 | elapsed time per iteration (ms): 572.4 | learning rate: 1.733846E-05 | global batch size:    64 | lm loss: 6.890934E+00 | loss scale: 1.0 | grad norm: 1.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:28] iteration      603/    1000 | consumed samples:        38592 | elapsed time per iteration (ms): 571.5 | learning rate: 1.725742E-05 | global batch size:    64 | lm loss: 7.085617E+00 | loss scale: 1.0 | grad norm: 1.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:29] iteration      604/    1000 | consumed samples:        38656 | elapsed time per iteration (ms): 573.3 | learning rate: 1.717658E-05 | global batch size:    64 | lm loss: 6.886146E+00 | loss scale: 1.0 | grad norm: 1.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:29] iteration      605/    1000 | consumed samples:        38720 | elapsed time per iteration (ms): 577.5 | learning rate: 1.709596E-05 | global batch size:    64 | lm loss: 6.986619E+00 | loss scale: 1.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:30] iteration      606/    1000 | consumed samples:        38784 | elapsed time per iteration (ms): 573.4 | learning rate: 1.701556E-05 | global batch size:    64 | lm loss: 6.892655E+00 | loss scale: 1.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:30] iteration      607/    1000 | consumed samples:        38848 | elapsed time per iteration (ms): 572.2 | learning rate: 1.693538E-05 | global batch size:    64 | lm loss: 6.782146E+00 | loss scale: 1.0 | grad norm: 1.165 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:31] iteration      608/    1000 | consumed samples:        38912 | elapsed time per iteration (ms): 572.1 | learning rate: 1.685542E-05 | global batch size:    64 | lm loss: 6.869110E+00 | loss scale: 1.0 | grad norm: 1.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:32] iteration      609/    1000 | consumed samples:        38976 | elapsed time per iteration (ms): 573.8 | learning rate: 1.677567E-05 | global batch size:    64 | lm loss: 6.942862E+00 | loss scale: 1.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:32] iteration      610/    1000 | consumed samples:        39040 | elapsed time per iteration (ms): 573.1 | learning rate: 1.669615E-05 | global batch size:    64 | lm loss: 6.799913E+00 | loss scale: 1.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:33] iteration      611/    1000 | consumed samples:        39104 | elapsed time per iteration (ms): 573.4 | learning rate: 1.661684E-05 | global batch size:    64 | lm loss: 6.947205E+00 | loss scale: 1.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:33] iteration      612/    1000 | consumed samples:        39168 | elapsed time per iteration (ms): 573.3 | learning rate: 1.653777E-05 | global batch size:    64 | lm loss: 6.978197E+00 | loss scale: 1.0 | grad norm: 1.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:34] iteration      613/    1000 | consumed samples:        39232 | elapsed time per iteration (ms): 572.1 | learning rate: 1.645891E-05 | global batch size:    64 | lm loss: 7.058391E+00 | loss scale: 1.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:34] iteration      614/    1000 | consumed samples:        39296 | elapsed time per iteration (ms): 573.1 | learning rate: 1.638028E-05 | global batch size:    64 | lm loss: 6.925652E+00 | loss scale: 1.0 | grad norm: 1.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:35] iteration      615/    1000 | consumed samples:        39360 | elapsed time per iteration (ms): 572.6 | learning rate: 1.630188E-05 | global batch size:    64 | lm loss: 6.784329E+00 | loss scale: 1.0 | grad norm: 1.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:36] iteration      616/    1000 | consumed samples:        39424 | elapsed time per iteration (ms): 572.0 | learning rate: 1.622370E-05 | global batch size:    64 | lm loss: 6.984637E+00 | loss scale: 1.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:36] iteration      617/    1000 | consumed samples:        39488 | elapsed time per iteration (ms): 572.2 | learning rate: 1.614575E-05 | global batch size:    64 | lm loss: 6.884388E+00 | loss scale: 1.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:37] iteration      618/    1000 | consumed samples:        39552 | elapsed time per iteration (ms): 572.1 | learning rate: 1.606804E-05 | global batch size:    64 | lm loss: 6.829203E+00 | loss scale: 1.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:37] iteration      619/    1000 | consumed samples:        39616 | elapsed time per iteration (ms): 572.7 | learning rate: 1.599055E-05 | global batch size:    64 | lm loss: 6.856539E+00 | loss scale: 1.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:38] iteration      620/    1000 | consumed samples:        39680 | elapsed time per iteration (ms): 572.4 | learning rate: 1.591329E-05 | global batch size:    64 | lm loss: 6.988801E+00 | loss scale: 1.0 | grad norm: 2.354 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:38] iteration      621/    1000 | consumed samples:        39744 | elapsed time per iteration (ms): 572.1 | learning rate: 1.583627E-05 | global batch size:    64 | lm loss: 6.885118E+00 | loss scale: 1.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:39] iteration      622/    1000 | consumed samples:        39808 | elapsed time per iteration (ms): 572.2 | learning rate: 1.575948E-05 | global batch size:    64 | lm loss: 6.866023E+00 | loss scale: 1.0 | grad norm: 1.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:40] iteration      623/    1000 | consumed samples:        39872 | elapsed time per iteration (ms): 571.3 | learning rate: 1.568292E-05 | global batch size:    64 | lm loss: 6.957486E+00 | loss scale: 1.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:40] iteration      624/    1000 | consumed samples:        39936 | elapsed time per iteration (ms): 573.0 | learning rate: 1.560661E-05 | global batch size:    64 | lm loss: 6.828773E+00 | loss scale: 1.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:41] iteration      625/    1000 | consumed samples:        40000 | elapsed time per iteration (ms): 574.9 | learning rate: 1.553052E-05 | global batch size:    64 | lm loss: 6.842049E+00 | loss scale: 1.0 | grad norm: 1.207 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:41] iteration      626/    1000 | consumed samples:        40064 | elapsed time per iteration (ms): 575.4 | learning rate: 1.545468E-05 | global batch size:    64 | lm loss: 6.979619E+00 | loss scale: 1.0 | grad norm: 0.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:42] iteration      627/    1000 | consumed samples:        40128 | elapsed time per iteration (ms): 573.2 | learning rate: 1.537907E-05 | global batch size:    64 | lm loss: 6.893954E+00 | loss scale: 1.0 | grad norm: 0.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:42] iteration      628/    1000 | consumed samples:        40192 | elapsed time per iteration (ms): 572.5 | learning rate: 1.530371E-05 | global batch size:    64 | lm loss: 6.922648E+00 | loss scale: 1.0 | grad norm: 0.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:43] iteration      629/    1000 | consumed samples:        40256 | elapsed time per iteration (ms): 574.4 | learning rate: 1.522858E-05 | global batch size:    64 | lm loss: 7.005535E+00 | loss scale: 1.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:44] iteration      630/    1000 | consumed samples:        40320 | elapsed time per iteration (ms): 573.8 | learning rate: 1.515370E-05 | global batch size:    64 | lm loss: 6.890708E+00 | loss scale: 1.0 | grad norm: 0.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:44] iteration      631/    1000 | consumed samples:        40384 | elapsed time per iteration (ms): 572.9 | learning rate: 1.507906E-05 | global batch size:    64 | lm loss: 6.892363E+00 | loss scale: 1.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:45] iteration      632/    1000 | consumed samples:        40448 | elapsed time per iteration (ms): 571.9 | learning rate: 1.500466E-05 | global batch size:    64 | lm loss: 6.807141E+00 | loss scale: 1.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:45] iteration      633/    1000 | consumed samples:        40512 | elapsed time per iteration (ms): 573.2 | learning rate: 1.493051E-05 | global batch size:    64 | lm loss: 7.066406E+00 | loss scale: 1.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:46] iteration      634/    1000 | consumed samples:        40576 | elapsed time per iteration (ms): 574.6 | learning rate: 1.485661E-05 | global batch size:    64 | lm loss: 6.839535E+00 | loss scale: 1.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:47] iteration      635/    1000 | consumed samples:        40640 | elapsed time per iteration (ms): 574.6 | learning rate: 1.478295E-05 | global batch size:    64 | lm loss: 6.772027E+00 | loss scale: 1.0 | grad norm: 1.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:47] iteration      636/    1000 | consumed samples:        40704 | elapsed time per iteration (ms): 573.8 | learning rate: 1.470954E-05 | global batch size:    64 | lm loss: 6.852069E+00 | loss scale: 1.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:48] iteration      637/    1000 | consumed samples:        40768 | elapsed time per iteration (ms): 572.9 | learning rate: 1.463638E-05 | global batch size:    64 | lm loss: 6.876533E+00 | loss scale: 1.0 | grad norm: 0.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:48] iteration      638/    1000 | consumed samples:        40832 | elapsed time per iteration (ms): 572.5 | learning rate: 1.456347E-05 | global batch size:    64 | lm loss: 6.886605E+00 | loss scale: 1.0 | grad norm: 1.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:49] iteration      639/    1000 | consumed samples:        40896 | elapsed time per iteration (ms): 573.5 | learning rate: 1.449081E-05 | global batch size:    64 | lm loss: 6.980742E+00 | loss scale: 1.0 | grad norm: 1.319 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:49] iteration      640/    1000 | consumed samples:        40960 | elapsed time per iteration (ms): 571.8 | learning rate: 1.441840E-05 | global batch size:    64 | lm loss: 6.913362E+00 | loss scale: 1.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:50] iteration      641/    1000 | consumed samples:        41024 | elapsed time per iteration (ms): 574.8 | learning rate: 1.434625E-05 | global batch size:    64 | lm loss: 6.989388E+00 | loss scale: 1.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:51] iteration      642/    1000 | consumed samples:        41088 | elapsed time per iteration (ms): 572.9 | learning rate: 1.427435E-05 | global batch size:    64 | lm loss: 6.978404E+00 | loss scale: 1.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:51] iteration      643/    1000 | consumed samples:        41152 | elapsed time per iteration (ms): 572.2 | learning rate: 1.420270E-05 | global batch size:    64 | lm loss: 6.947526E+00 | loss scale: 1.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:52] iteration      644/    1000 | consumed samples:        41216 | elapsed time per iteration (ms): 572.9 | learning rate: 1.413131E-05 | global batch size:    64 | lm loss: 6.896800E+00 | loss scale: 1.0 | grad norm: 1.160 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:52] iteration      645/    1000 | consumed samples:        41280 | elapsed time per iteration (ms): 572.6 | learning rate: 1.406018E-05 | global batch size:    64 | lm loss: 7.097973E+00 | loss scale: 1.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:53] iteration      646/    1000 | consumed samples:        41344 | elapsed time per iteration (ms): 572.2 | learning rate: 1.398930E-05 | global batch size:    64 | lm loss: 6.915025E+00 | loss scale: 1.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:53] iteration      647/    1000 | consumed samples:        41408 | elapsed time per iteration (ms): 572.4 | learning rate: 1.391869E-05 | global batch size:    64 | lm loss: 6.890501E+00 | loss scale: 1.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:54] iteration      648/    1000 | consumed samples:        41472 | elapsed time per iteration (ms): 572.6 | learning rate: 1.384833E-05 | global batch size:    64 | lm loss: 6.893182E+00 | loss scale: 1.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:55] iteration      649/    1000 | consumed samples:        41536 | elapsed time per iteration (ms): 572.4 | learning rate: 1.377824E-05 | global batch size:    64 | lm loss: 6.949166E+00 | loss scale: 1.0 | grad norm: 1.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:55] iteration      650/    1000 | consumed samples:        41600 | elapsed time per iteration (ms): 572.1 | learning rate: 1.370840E-05 | global batch size:    64 | lm loss: 6.790866E+00 | loss scale: 1.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:56] iteration      651/    1000 | consumed samples:        41664 | elapsed time per iteration (ms): 572.2 | learning rate: 1.363883E-05 | global batch size:    64 | lm loss: 7.032323E+00 | loss scale: 1.0 | grad norm: 0.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:56] iteration      652/    1000 | consumed samples:        41728 | elapsed time per iteration (ms): 572.9 | learning rate: 1.356952E-05 | global batch size:    64 | lm loss: 6.810049E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:57] iteration      653/    1000 | consumed samples:        41792 | elapsed time per iteration (ms): 572.4 | learning rate: 1.350048E-05 | global batch size:    64 | lm loss: 7.003486E+00 | loss scale: 1.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:57] iteration      654/    1000 | consumed samples:        41856 | elapsed time per iteration (ms): 573.0 | learning rate: 1.343170E-05 | global batch size:    64 | lm loss: 6.882355E+00 | loss scale: 1.0 | grad norm: 1.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:58] iteration      655/    1000 | consumed samples:        41920 | elapsed time per iteration (ms): 572.7 | learning rate: 1.336319E-05 | global batch size:    64 | lm loss: 6.827237E+00 | loss scale: 1.0 | grad norm: 1.183 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:59] iteration      656/    1000 | consumed samples:        41984 | elapsed time per iteration (ms): 572.1 | learning rate: 1.329495E-05 | global batch size:    64 | lm loss: 6.957908E+00 | loss scale: 1.0 | grad norm: 0.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:04:59] iteration      657/    1000 | consumed samples:        42048 | elapsed time per iteration (ms): 573.3 | learning rate: 1.322697E-05 | global batch size:    64 | lm loss: 6.863202E+00 | loss scale: 1.0 | grad norm: 0.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:00] iteration      658/    1000 | consumed samples:        42112 | elapsed time per iteration (ms): 571.9 | learning rate: 1.315927E-05 | global batch size:    64 | lm loss: 6.828285E+00 | loss scale: 1.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:00] iteration      659/    1000 | consumed samples:        42176 | elapsed time per iteration (ms): 572.9 | learning rate: 1.309183E-05 | global batch size:    64 | lm loss: 6.855188E+00 | loss scale: 1.0 | grad norm: 0.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:01] iteration      660/    1000 | consumed samples:        42240 | elapsed time per iteration (ms): 573.5 | learning rate: 1.302466E-05 | global batch size:    64 | lm loss: 7.008691E+00 | loss scale: 1.0 | grad norm: 1.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:01] iteration      661/    1000 | consumed samples:        42304 | elapsed time per iteration (ms): 573.6 | learning rate: 1.295777E-05 | global batch size:    64 | lm loss: 6.884602E+00 | loss scale: 1.0 | grad norm: 1.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:02] iteration      662/    1000 | consumed samples:        42368 | elapsed time per iteration (ms): 574.0 | learning rate: 1.289115E-05 | global batch size:    64 | lm loss: 6.980980E+00 | loss scale: 1.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:03] iteration      663/    1000 | consumed samples:        42432 | elapsed time per iteration (ms): 574.5 | learning rate: 1.282480E-05 | global batch size:    64 | lm loss: 6.868489E+00 | loss scale: 1.0 | grad norm: 0.976 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:03] iteration      664/    1000 | consumed samples:        42496 | elapsed time per iteration (ms): 574.8 | learning rate: 1.275873E-05 | global batch size:    64 | lm loss: 6.926242E+00 | loss scale: 1.0 | grad norm: 0.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:04] iteration      665/    1000 | consumed samples:        42560 | elapsed time per iteration (ms): 574.7 | learning rate: 1.269294E-05 | global batch size:    64 | lm loss: 6.845824E+00 | loss scale: 1.0 | grad norm: 1.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:04] iteration      666/    1000 | consumed samples:        42624 | elapsed time per iteration (ms): 573.3 | learning rate: 1.262742E-05 | global batch size:    64 | lm loss: 6.849319E+00 | loss scale: 1.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:05] iteration      667/    1000 | consumed samples:        42688 | elapsed time per iteration (ms): 571.8 | learning rate: 1.256218E-05 | global batch size:    64 | lm loss: 6.934675E+00 | loss scale: 1.0 | grad norm: 0.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:05] iteration      668/    1000 | consumed samples:        42752 | elapsed time per iteration (ms): 572.5 | learning rate: 1.249721E-05 | global batch size:    64 | lm loss: 6.864026E+00 | loss scale: 1.0 | grad norm: 1.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:06] iteration      669/    1000 | consumed samples:        42816 | elapsed time per iteration (ms): 573.7 | learning rate: 1.243253E-05 | global batch size:    64 | lm loss: 6.878362E+00 | loss scale: 1.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:07] iteration      670/    1000 | consumed samples:        42880 | elapsed time per iteration (ms): 577.4 | learning rate: 1.236812E-05 | global batch size:    64 | lm loss: 6.941517E+00 | loss scale: 1.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:07] iteration      671/    1000 | consumed samples:        42944 | elapsed time per iteration (ms): 575.2 | learning rate: 1.230400E-05 | global batch size:    64 | lm loss: 6.842687E+00 | loss scale: 1.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:08] iteration      672/    1000 | consumed samples:        43008 | elapsed time per iteration (ms): 574.0 | learning rate: 1.224016E-05 | global batch size:    64 | lm loss: 6.987464E+00 | loss scale: 1.0 | grad norm: 1.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:08] iteration      673/    1000 | consumed samples:        43072 | elapsed time per iteration (ms): 572.8 | learning rate: 1.217660E-05 | global batch size:    64 | lm loss: 6.804333E+00 | loss scale: 1.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:09] iteration      674/    1000 | consumed samples:        43136 | elapsed time per iteration (ms): 571.9 | learning rate: 1.211332E-05 | global batch size:    64 | lm loss: 6.918369E+00 | loss scale: 1.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:09] iteration      675/    1000 | consumed samples:        43200 | elapsed time per iteration (ms): 571.9 | learning rate: 1.205033E-05 | global batch size:    64 | lm loss: 6.929011E+00 | loss scale: 1.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:10] iteration      676/    1000 | consumed samples:        43264 | elapsed time per iteration (ms): 571.5 | learning rate: 1.198762E-05 | global batch size:    64 | lm loss: 6.857622E+00 | loss scale: 1.0 | grad norm: 0.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:11] iteration      677/    1000 | consumed samples:        43328 | elapsed time per iteration (ms): 572.5 | learning rate: 1.192520E-05 | global batch size:    64 | lm loss: 6.911674E+00 | loss scale: 1.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:11] iteration      678/    1000 | consumed samples:        43392 | elapsed time per iteration (ms): 572.6 | learning rate: 1.186307E-05 | global batch size:    64 | lm loss: 6.818565E+00 | loss scale: 1.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:12] iteration      679/    1000 | consumed samples:        43456 | elapsed time per iteration (ms): 571.9 | learning rate: 1.180122E-05 | global batch size:    64 | lm loss: 6.780861E+00 | loss scale: 1.0 | grad norm: 1.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:12] iteration      680/    1000 | consumed samples:        43520 | elapsed time per iteration (ms): 571.8 | learning rate: 1.173967E-05 | global batch size:    64 | lm loss: 6.929988E+00 | loss scale: 1.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:13] iteration      681/    1000 | consumed samples:        43584 | elapsed time per iteration (ms): 572.2 | learning rate: 1.167840E-05 | global batch size:    64 | lm loss: 6.772047E+00 | loss scale: 1.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:13] iteration      682/    1000 | consumed samples:        43648 | elapsed time per iteration (ms): 572.3 | learning rate: 1.161742E-05 | global batch size:    64 | lm loss: 6.959042E+00 | loss scale: 1.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:14] iteration      683/    1000 | consumed samples:        43712 | elapsed time per iteration (ms): 572.4 | learning rate: 1.155674E-05 | global batch size:    64 | lm loss: 6.819054E+00 | loss scale: 1.0 | grad norm: 0.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:15] iteration      684/    1000 | consumed samples:        43776 | elapsed time per iteration (ms): 572.1 | learning rate: 1.149634E-05 | global batch size:    64 | lm loss: 6.868639E+00 | loss scale: 1.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:15] iteration      685/    1000 | consumed samples:        43840 | elapsed time per iteration (ms): 571.9 | learning rate: 1.143624E-05 | global batch size:    64 | lm loss: 6.838169E+00 | loss scale: 1.0 | grad norm: 0.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:16] iteration      686/    1000 | consumed samples:        43904 | elapsed time per iteration (ms): 573.3 | learning rate: 1.137643E-05 | global batch size:    64 | lm loss: 6.794387E+00 | loss scale: 1.0 | grad norm: 1.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:16] iteration      687/    1000 | consumed samples:        43968 | elapsed time per iteration (ms): 575.6 | learning rate: 1.131692E-05 | global batch size:    64 | lm loss: 6.768700E+00 | loss scale: 1.0 | grad norm: 0.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:17] iteration      688/    1000 | consumed samples:        44032 | elapsed time per iteration (ms): 574.2 | learning rate: 1.125770E-05 | global batch size:    64 | lm loss: 6.890195E+00 | loss scale: 1.0 | grad norm: 0.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:17] iteration      689/    1000 | consumed samples:        44096 | elapsed time per iteration (ms): 573.3 | learning rate: 1.119878E-05 | global batch size:    64 | lm loss: 6.909555E+00 | loss scale: 1.0 | grad norm: 1.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:18] iteration      690/    1000 | consumed samples:        44160 | elapsed time per iteration (ms): 572.1 | learning rate: 1.114016E-05 | global batch size:    64 | lm loss: 6.823194E+00 | loss scale: 1.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:19] iteration      691/    1000 | consumed samples:        44224 | elapsed time per iteration (ms): 571.6 | learning rate: 1.108183E-05 | global batch size:    64 | lm loss: 6.856674E+00 | loss scale: 1.0 | grad norm: 0.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:19] iteration      692/    1000 | consumed samples:        44288 | elapsed time per iteration (ms): 572.5 | learning rate: 1.102380E-05 | global batch size:    64 | lm loss: 6.898502E+00 | loss scale: 1.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:20] iteration      693/    1000 | consumed samples:        44352 | elapsed time per iteration (ms): 574.9 | learning rate: 1.096607E-05 | global batch size:    64 | lm loss: 6.869724E+00 | loss scale: 1.0 | grad norm: 1.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:20] iteration      694/    1000 | consumed samples:        44416 | elapsed time per iteration (ms): 573.1 | learning rate: 1.090864E-05 | global batch size:    64 | lm loss: 6.965701E+00 | loss scale: 1.0 | grad norm: 0.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:21] iteration      695/    1000 | consumed samples:        44480 | elapsed time per iteration (ms): 574.4 | learning rate: 1.085151E-05 | global batch size:    64 | lm loss: 6.964120E+00 | loss scale: 1.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:21] iteration      696/    1000 | consumed samples:        44544 | elapsed time per iteration (ms): 576.8 | learning rate: 1.079468E-05 | global batch size:    64 | lm loss: 6.965400E+00 | loss scale: 1.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:22] iteration      697/    1000 | consumed samples:        44608 | elapsed time per iteration (ms): 574.9 | learning rate: 1.073816E-05 | global batch size:    64 | lm loss: 6.857654E+00 | loss scale: 1.0 | grad norm: 0.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:23] iteration      698/    1000 | consumed samples:        44672 | elapsed time per iteration (ms): 574.2 | learning rate: 1.068194E-05 | global batch size:    64 | lm loss: 6.894195E+00 | loss scale: 1.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:23] iteration      699/    1000 | consumed samples:        44736 | elapsed time per iteration (ms): 572.1 | learning rate: 1.062602E-05 | global batch size:    64 | lm loss: 6.864139E+00 | loss scale: 1.0 | grad norm: 0.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:24] iteration      700/    1000 | consumed samples:        44800 | elapsed time per iteration (ms): 573.0 | learning rate: 1.057040E-05 | global batch size:    64 | lm loss: 6.970941E+00 | loss scale: 1.0 | grad norm: 1.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:24] iteration      701/    1000 | consumed samples:        44864 | elapsed time per iteration (ms): 575.2 | learning rate: 1.051510E-05 | global batch size:    64 | lm loss: 6.930655E+00 | loss scale: 1.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:25] iteration      702/    1000 | consumed samples:        44928 | elapsed time per iteration (ms): 574.8 | learning rate: 1.046009E-05 | global batch size:    64 | lm loss: 6.913915E+00 | loss scale: 1.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:25] iteration      703/    1000 | consumed samples:        44992 | elapsed time per iteration (ms): 575.2 | learning rate: 1.040540E-05 | global batch size:    64 | lm loss: 6.923656E+00 | loss scale: 1.0 | grad norm: 0.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:26] iteration      704/    1000 | consumed samples:        45056 | elapsed time per iteration (ms): 573.7 | learning rate: 1.035101E-05 | global batch size:    64 | lm loss: 6.934560E+00 | loss scale: 1.0 | grad norm: 0.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:27] iteration      705/    1000 | consumed samples:        45120 | elapsed time per iteration (ms): 573.2 | learning rate: 1.029693E-05 | global batch size:    64 | lm loss: 6.965773E+00 | loss scale: 1.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:27] iteration      706/    1000 | consumed samples:        45184 | elapsed time per iteration (ms): 571.7 | learning rate: 1.024316E-05 | global batch size:    64 | lm loss: 6.861597E+00 | loss scale: 1.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:28] iteration      707/    1000 | consumed samples:        45248 | elapsed time per iteration (ms): 573.1 | learning rate: 1.018970E-05 | global batch size:    64 | lm loss: 6.783163E+00 | loss scale: 1.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:28] iteration      708/    1000 | consumed samples:        45312 | elapsed time per iteration (ms): 571.5 | learning rate: 1.013655E-05 | global batch size:    64 | lm loss: 6.997662E+00 | loss scale: 1.0 | grad norm: 0.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:29] iteration      709/    1000 | consumed samples:        45376 | elapsed time per iteration (ms): 571.5 | learning rate: 1.008372E-05 | global batch size:    64 | lm loss: 6.839869E+00 | loss scale: 1.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:29] iteration      710/    1000 | consumed samples:        45440 | elapsed time per iteration (ms): 572.6 | learning rate: 1.003119E-05 | global batch size:    64 | lm loss: 6.757129E+00 | loss scale: 1.0 | grad norm: 0.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:30] iteration      711/    1000 | consumed samples:        45504 | elapsed time per iteration (ms): 572.8 | learning rate: 9.978976E-06 | global batch size:    64 | lm loss: 6.930756E+00 | loss scale: 1.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:31] iteration      712/    1000 | consumed samples:        45568 | elapsed time per iteration (ms): 572.6 | learning rate: 9.927076E-06 | global batch size:    64 | lm loss: 6.880136E+00 | loss scale: 1.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:31] iteration      713/    1000 | consumed samples:        45632 | elapsed time per iteration (ms): 573.4 | learning rate: 9.875490E-06 | global batch size:    64 | lm loss: 6.850342E+00 | loss scale: 1.0 | grad norm: 1.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:32] iteration      714/    1000 | consumed samples:        45696 | elapsed time per iteration (ms): 572.3 | learning rate: 9.824219E-06 | global batch size:    64 | lm loss: 6.887316E+00 | loss scale: 1.0 | grad norm: 1.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:32] iteration      715/    1000 | consumed samples:        45760 | elapsed time per iteration (ms): 571.7 | learning rate: 9.773264E-06 | global batch size:    64 | lm loss: 6.945277E+00 | loss scale: 1.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:33] iteration      716/    1000 | consumed samples:        45824 | elapsed time per iteration (ms): 572.7 | learning rate: 9.722624E-06 | global batch size:    64 | lm loss: 6.965514E+00 | loss scale: 1.0 | grad norm: 1.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:34] iteration      717/    1000 | consumed samples:        45888 | elapsed time per iteration (ms): 573.2 | learning rate: 9.672302E-06 | global batch size:    64 | lm loss: 6.898789E+00 | loss scale: 1.0 | grad norm: 1.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:34] iteration      718/    1000 | consumed samples:        45952 | elapsed time per iteration (ms): 572.2 | learning rate: 9.622298E-06 | global batch size:    64 | lm loss: 6.870871E+00 | loss scale: 1.0 | grad norm: 1.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:35] iteration      719/    1000 | consumed samples:        46016 | elapsed time per iteration (ms): 571.8 | learning rate: 9.572611E-06 | global batch size:    64 | lm loss: 6.920159E+00 | loss scale: 1.0 | grad norm: 1.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:35] iteration      720/    1000 | consumed samples:        46080 | elapsed time per iteration (ms): 572.0 | learning rate: 9.523244E-06 | global batch size:    64 | lm loss: 6.800398E+00 | loss scale: 1.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:36] iteration      721/    1000 | consumed samples:        46144 | elapsed time per iteration (ms): 572.7 | learning rate: 9.474195E-06 | global batch size:    64 | lm loss: 6.892540E+00 | loss scale: 1.0 | grad norm: 1.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:36] iteration      722/    1000 | consumed samples:        46208 | elapsed time per iteration (ms): 572.8 | learning rate: 9.425468E-06 | global batch size:    64 | lm loss: 6.882118E+00 | loss scale: 1.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:37] iteration      723/    1000 | consumed samples:        46272 | elapsed time per iteration (ms): 574.8 | learning rate: 9.377061E-06 | global batch size:    64 | lm loss: 6.979013E+00 | loss scale: 1.0 | grad norm: 1.137 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:38] iteration      724/    1000 | consumed samples:        46336 | elapsed time per iteration (ms): 575.0 | learning rate: 9.328976E-06 | global batch size:    64 | lm loss: 6.899084E+00 | loss scale: 1.0 | grad norm: 1.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:38] iteration      725/    1000 | consumed samples:        46400 | elapsed time per iteration (ms): 574.7 | learning rate: 9.281214E-06 | global batch size:    64 | lm loss: 6.820255E+00 | loss scale: 1.0 | grad norm: 1.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:39] iteration      726/    1000 | consumed samples:        46464 | elapsed time per iteration (ms): 573.2 | learning rate: 9.233774E-06 | global batch size:    64 | lm loss: 6.905478E+00 | loss scale: 1.0 | grad norm: 0.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:39] iteration      727/    1000 | consumed samples:        46528 | elapsed time per iteration (ms): 574.0 | learning rate: 9.186659E-06 | global batch size:    64 | lm loss: 6.938837E+00 | loss scale: 1.0 | grad norm: 1.061 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:40] iteration      728/    1000 | consumed samples:        46592 | elapsed time per iteration (ms): 574.5 | learning rate: 9.139867E-06 | global batch size:    64 | lm loss: 6.888055E+00 | loss scale: 1.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:40] iteration      729/    1000 | consumed samples:        46656 | elapsed time per iteration (ms): 576.2 | learning rate: 9.093400E-06 | global batch size:    64 | lm loss: 6.760523E+00 | loss scale: 1.0 | grad norm: 1.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:41] iteration      730/    1000 | consumed samples:        46720 | elapsed time per iteration (ms): 575.7 | learning rate: 9.047259E-06 | global batch size:    64 | lm loss: 6.806893E+00 | loss scale: 1.0 | grad norm: 1.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:42] iteration      731/    1000 | consumed samples:        46784 | elapsed time per iteration (ms): 572.1 | learning rate: 9.001443E-06 | global batch size:    64 | lm loss: 6.858335E+00 | loss scale: 1.0 | grad norm: 0.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:42] iteration      732/    1000 | consumed samples:        46848 | elapsed time per iteration (ms): 572.9 | learning rate: 8.955954E-06 | global batch size:    64 | lm loss: 6.993052E+00 | loss scale: 1.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:43] iteration      733/    1000 | consumed samples:        46912 | elapsed time per iteration (ms): 574.7 | learning rate: 8.910793E-06 | global batch size:    64 | lm loss: 6.803837E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:43] iteration      734/    1000 | consumed samples:        46976 | elapsed time per iteration (ms): 573.2 | learning rate: 8.865960E-06 | global batch size:    64 | lm loss: 6.848375E+00 | loss scale: 1.0 | grad norm: 1.249 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:44] iteration      735/    1000 | consumed samples:        47040 | elapsed time per iteration (ms): 575.4 | learning rate: 8.821456E-06 | global batch size:    64 | lm loss: 6.863081E+00 | loss scale: 1.0 | grad norm: 0.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:44] iteration      736/    1000 | consumed samples:        47104 | elapsed time per iteration (ms): 573.8 | learning rate: 8.777280E-06 | global batch size:    64 | lm loss: 6.909451E+00 | loss scale: 1.0 | grad norm: 0.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:45] iteration      737/    1000 | consumed samples:        47168 | elapsed time per iteration (ms): 571.9 | learning rate: 8.733435E-06 | global batch size:    64 | lm loss: 6.784608E+00 | loss scale: 1.0 | grad norm: 0.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:46] iteration      738/    1000 | consumed samples:        47232 | elapsed time per iteration (ms): 573.5 | learning rate: 8.689919E-06 | global batch size:    64 | lm loss: 6.834009E+00 | loss scale: 1.0 | grad norm: 0.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:46] iteration      739/    1000 | consumed samples:        47296 | elapsed time per iteration (ms): 574.0 | learning rate: 8.646735E-06 | global batch size:    64 | lm loss: 6.959486E+00 | loss scale: 1.0 | grad norm: 1.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:47] iteration      740/    1000 | consumed samples:        47360 | elapsed time per iteration (ms): 575.6 | learning rate: 8.603883E-06 | global batch size:    64 | lm loss: 7.045331E+00 | loss scale: 1.0 | grad norm: 1.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:47] iteration      741/    1000 | consumed samples:        47424 | elapsed time per iteration (ms): 572.9 | learning rate: 8.561362E-06 | global batch size:    64 | lm loss: 6.795690E+00 | loss scale: 1.0 | grad norm: 0.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:48] iteration      742/    1000 | consumed samples:        47488 | elapsed time per iteration (ms): 572.5 | learning rate: 8.519174E-06 | global batch size:    64 | lm loss: 6.888875E+00 | loss scale: 1.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:48] iteration      743/    1000 | consumed samples:        47552 | elapsed time per iteration (ms): 574.0 | learning rate: 8.477320E-06 | global batch size:    64 | lm loss: 6.875651E+00 | loss scale: 1.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:49] iteration      744/    1000 | consumed samples:        47616 | elapsed time per iteration (ms): 573.4 | learning rate: 8.435799E-06 | global batch size:    64 | lm loss: 6.796446E+00 | loss scale: 1.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:50] iteration      745/    1000 | consumed samples:        47680 | elapsed time per iteration (ms): 575.1 | learning rate: 8.394613E-06 | global batch size:    64 | lm loss: 6.995850E+00 | loss scale: 1.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:50] iteration      746/    1000 | consumed samples:        47744 | elapsed time per iteration (ms): 576.7 | learning rate: 8.353762E-06 | global batch size:    64 | lm loss: 6.914999E+00 | loss scale: 1.0 | grad norm: 0.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:51] iteration      747/    1000 | consumed samples:        47808 | elapsed time per iteration (ms): 574.5 | learning rate: 8.313246E-06 | global batch size:    64 | lm loss: 6.861954E+00 | loss scale: 1.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:51] iteration      748/    1000 | consumed samples:        47872 | elapsed time per iteration (ms): 575.1 | learning rate: 8.273068E-06 | global batch size:    64 | lm loss: 6.924344E+00 | loss scale: 1.0 | grad norm: 0.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:52] iteration      749/    1000 | consumed samples:        47936 | elapsed time per iteration (ms): 572.9 | learning rate: 8.233224E-06 | global batch size:    64 | lm loss: 6.879330E+00 | loss scale: 1.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:52] iteration      750/    1000 | consumed samples:        48000 | elapsed time per iteration (ms): 573.9 | learning rate: 8.193719E-06 | global batch size:    64 | lm loss: 6.981817E+00 | loss scale: 1.0 | grad norm: 0.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:53] iteration      751/    1000 | consumed samples:        48064 | elapsed time per iteration (ms): 575.2 | learning rate: 8.154551E-06 | global batch size:    64 | lm loss: 6.909636E+00 | loss scale: 1.0 | grad norm: 0.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:54] iteration      752/    1000 | consumed samples:        48128 | elapsed time per iteration (ms): 574.5 | learning rate: 8.115721E-06 | global batch size:    64 | lm loss: 6.925763E+00 | loss scale: 1.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:54] iteration      753/    1000 | consumed samples:        48192 | elapsed time per iteration (ms): 575.5 | learning rate: 8.077232E-06 | global batch size:    64 | lm loss: 6.953569E+00 | loss scale: 1.0 | grad norm: 1.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:55] iteration      754/    1000 | consumed samples:        48256 | elapsed time per iteration (ms): 574.4 | learning rate: 8.039080E-06 | global batch size:    64 | lm loss: 6.808390E+00 | loss scale: 1.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:55] iteration      755/    1000 | consumed samples:        48320 | elapsed time per iteration (ms): 572.7 | learning rate: 8.001269E-06 | global batch size:    64 | lm loss: 6.913234E+00 | loss scale: 1.0 | grad norm: 0.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:56] iteration      756/    1000 | consumed samples:        48384 | elapsed time per iteration (ms): 578.2 | learning rate: 7.963798E-06 | global batch size:    64 | lm loss: 6.958102E+00 | loss scale: 1.0 | grad norm: 1.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:56] iteration      757/    1000 | consumed samples:        48448 | elapsed time per iteration (ms): 575.3 | learning rate: 7.926667E-06 | global batch size:    64 | lm loss: 6.843774E+00 | loss scale: 1.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:57] iteration      758/    1000 | consumed samples:        48512 | elapsed time per iteration (ms): 574.0 | learning rate: 7.889878E-06 | global batch size:    64 | lm loss: 6.801070E+00 | loss scale: 1.0 | grad norm: 1.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:58] iteration      759/    1000 | consumed samples:        48576 | elapsed time per iteration (ms): 574.6 | learning rate: 7.853431E-06 | global batch size:    64 | lm loss: 6.958127E+00 | loss scale: 1.0 | grad norm: 1.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:58] iteration      760/    1000 | consumed samples:        48640 | elapsed time per iteration (ms): 574.3 | learning rate: 7.817327E-06 | global batch size:    64 | lm loss: 6.761730E+00 | loss scale: 1.0 | grad norm: 1.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:59] iteration      761/    1000 | consumed samples:        48704 | elapsed time per iteration (ms): 573.8 | learning rate: 7.781565E-06 | global batch size:    64 | lm loss: 6.912533E+00 | loss scale: 1.0 | grad norm: 0.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:05:59] iteration      762/    1000 | consumed samples:        48768 | elapsed time per iteration (ms): 572.0 | learning rate: 7.746146E-06 | global batch size:    64 | lm loss: 6.815417E+00 | loss scale: 1.0 | grad norm: 0.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:00] iteration      763/    1000 | consumed samples:        48832 | elapsed time per iteration (ms): 572.1 | learning rate: 7.711073E-06 | global batch size:    64 | lm loss: 6.814238E+00 | loss scale: 1.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:00] iteration      764/    1000 | consumed samples:        48896 | elapsed time per iteration (ms): 572.1 | learning rate: 7.676342E-06 | global batch size:    64 | lm loss: 6.755211E+00 | loss scale: 1.0 | grad norm: 0.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:01] iteration      765/    1000 | consumed samples:        48960 | elapsed time per iteration (ms): 572.9 | learning rate: 7.641956E-06 | global batch size:    64 | lm loss: 6.945325E+00 | loss scale: 1.0 | grad norm: 1.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:02] iteration      766/    1000 | consumed samples:        49024 | elapsed time per iteration (ms): 575.3 | learning rate: 7.607917E-06 | global batch size:    64 | lm loss: 6.852453E+00 | loss scale: 1.0 | grad norm: 1.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:02] iteration      767/    1000 | consumed samples:        49088 | elapsed time per iteration (ms): 573.8 | learning rate: 7.574222E-06 | global batch size:    64 | lm loss: 6.694702E+00 | loss scale: 1.0 | grad norm: 1.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:03] iteration      768/    1000 | consumed samples:        49152 | elapsed time per iteration (ms): 573.1 | learning rate: 7.540874E-06 | global batch size:    64 | lm loss: 6.958070E+00 | loss scale: 1.0 | grad norm: 1.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:03] iteration      769/    1000 | consumed samples:        49216 | elapsed time per iteration (ms): 572.0 | learning rate: 7.507872E-06 | global batch size:    64 | lm loss: 6.906590E+00 | loss scale: 1.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:04] iteration      770/    1000 | consumed samples:        49280 | elapsed time per iteration (ms): 572.3 | learning rate: 7.475218E-06 | global batch size:    64 | lm loss: 6.752476E+00 | loss scale: 1.0 | grad norm: 0.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:05] iteration      771/    1000 | consumed samples:        49344 | elapsed time per iteration (ms): 573.1 | learning rate: 7.442911E-06 | global batch size:    64 | lm loss: 6.887848E+00 | loss scale: 1.0 | grad norm: 1.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:05] iteration      772/    1000 | consumed samples:        49408 | elapsed time per iteration (ms): 572.0 | learning rate: 7.410952E-06 | global batch size:    64 | lm loss: 6.950916E+00 | loss scale: 1.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:06] iteration      773/    1000 | consumed samples:        49472 | elapsed time per iteration (ms): 572.8 | learning rate: 7.379342E-06 | global batch size:    64 | lm loss: 6.991114E+00 | loss scale: 1.0 | grad norm: 0.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:06] iteration      774/    1000 | consumed samples:        49536 | elapsed time per iteration (ms): 572.1 | learning rate: 7.348080E-06 | global batch size:    64 | lm loss: 6.902463E+00 | loss scale: 1.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:07] iteration      775/    1000 | consumed samples:        49600 | elapsed time per iteration (ms): 572.1 | learning rate: 7.317167E-06 | global batch size:    64 | lm loss: 6.841457E+00 | loss scale: 1.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:07] iteration      776/    1000 | consumed samples:        49664 | elapsed time per iteration (ms): 572.7 | learning rate: 7.286605E-06 | global batch size:    64 | lm loss: 6.690457E+00 | loss scale: 1.0 | grad norm: 0.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:08] iteration      777/    1000 | consumed samples:        49728 | elapsed time per iteration (ms): 572.8 | learning rate: 7.256392E-06 | global batch size:    64 | lm loss: 6.861629E+00 | loss scale: 1.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:09] iteration      778/    1000 | consumed samples:        49792 | elapsed time per iteration (ms): 572.3 | learning rate: 7.226530E-06 | global batch size:    64 | lm loss: 6.799387E+00 | loss scale: 1.0 | grad norm: 1.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:09] iteration      779/    1000 | consumed samples:        49856 | elapsed time per iteration (ms): 572.2 | learning rate: 7.197018E-06 | global batch size:    64 | lm loss: 6.844146E+00 | loss scale: 1.0 | grad norm: 0.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:10] iteration      780/    1000 | consumed samples:        49920 | elapsed time per iteration (ms): 573.0 | learning rate: 7.167859E-06 | global batch size:    64 | lm loss: 6.761741E+00 | loss scale: 1.0 | grad norm: 0.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:10] iteration      781/    1000 | consumed samples:        49984 | elapsed time per iteration (ms): 572.3 | learning rate: 7.139050E-06 | global batch size:    64 | lm loss: 6.831130E+00 | loss scale: 1.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:11] iteration      782/    1000 | consumed samples:        50048 | elapsed time per iteration (ms): 572.8 | learning rate: 7.110594E-06 | global batch size:    64 | lm loss: 6.852733E+00 | loss scale: 1.0 | grad norm: 0.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:11] iteration      783/    1000 | consumed samples:        50112 | elapsed time per iteration (ms): 571.5 | learning rate: 7.082491E-06 | global batch size:    64 | lm loss: 6.942119E+00 | loss scale: 1.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:12] iteration      784/    1000 | consumed samples:        50176 | elapsed time per iteration (ms): 572.2 | learning rate: 7.054740E-06 | global batch size:    64 | lm loss: 6.984264E+00 | loss scale: 1.0 | grad norm: 0.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:13] iteration      785/    1000 | consumed samples:        50240 | elapsed time per iteration (ms): 571.6 | learning rate: 7.027342E-06 | global batch size:    64 | lm loss: 6.944042E+00 | loss scale: 1.0 | grad norm: 0.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:13] iteration      786/    1000 | consumed samples:        50304 | elapsed time per iteration (ms): 572.7 | learning rate: 7.000298E-06 | global batch size:    64 | lm loss: 6.796418E+00 | loss scale: 1.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:14] iteration      787/    1000 | consumed samples:        50368 | elapsed time per iteration (ms): 575.1 | learning rate: 6.973609E-06 | global batch size:    64 | lm loss: 6.764181E+00 | loss scale: 1.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:14] iteration      788/    1000 | consumed samples:        50432 | elapsed time per iteration (ms): 574.3 | learning rate: 6.947273E-06 | global batch size:    64 | lm loss: 6.839115E+00 | loss scale: 1.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:15] iteration      789/    1000 | consumed samples:        50496 | elapsed time per iteration (ms): 573.6 | learning rate: 6.921292E-06 | global batch size:    64 | lm loss: 6.854980E+00 | loss scale: 1.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:15] iteration      790/    1000 | consumed samples:        50560 | elapsed time per iteration (ms): 572.3 | learning rate: 6.895667E-06 | global batch size:    64 | lm loss: 6.883507E+00 | loss scale: 1.0 | grad norm: 0.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:16] iteration      791/    1000 | consumed samples:        50624 | elapsed time per iteration (ms): 575.5 | learning rate: 6.870397E-06 | global batch size:    64 | lm loss: 6.972423E+00 | loss scale: 1.0 | grad norm: 0.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:17] iteration      792/    1000 | consumed samples:        50688 | elapsed time per iteration (ms): 573.1 | learning rate: 6.845482E-06 | global batch size:    64 | lm loss: 7.006859E+00 | loss scale: 1.0 | grad norm: 0.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:17] iteration      793/    1000 | consumed samples:        50752 | elapsed time per iteration (ms): 572.8 | learning rate: 6.820923E-06 | global batch size:    64 | lm loss: 6.882988E+00 | loss scale: 1.0 | grad norm: 0.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:18] iteration      794/    1000 | consumed samples:        50816 | elapsed time per iteration (ms): 572.0 | learning rate: 6.796722E-06 | global batch size:    64 | lm loss: 6.789972E+00 | loss scale: 1.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:18] iteration      795/    1000 | consumed samples:        50880 | elapsed time per iteration (ms): 571.2 | learning rate: 6.772877E-06 | global batch size:    64 | lm loss: 6.989998E+00 | loss scale: 1.0 | grad norm: 0.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:19] iteration      796/    1000 | consumed samples:        50944 | elapsed time per iteration (ms): 574.0 | learning rate: 6.749388E-06 | global batch size:    64 | lm loss: 6.940460E+00 | loss scale: 1.0 | grad norm: 0.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:19] iteration      797/    1000 | consumed samples:        51008 | elapsed time per iteration (ms): 572.6 | learning rate: 6.726258E-06 | global batch size:    64 | lm loss: 6.913539E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:20] iteration      798/    1000 | consumed samples:        51072 | elapsed time per iteration (ms): 571.5 | learning rate: 6.703485E-06 | global batch size:    64 | lm loss: 6.793193E+00 | loss scale: 1.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:21] iteration      799/    1000 | consumed samples:        51136 | elapsed time per iteration (ms): 572.8 | learning rate: 6.681070E-06 | global batch size:    64 | lm loss: 6.805624E+00 | loss scale: 1.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:21] iteration      800/    1000 | consumed samples:        51200 | elapsed time per iteration (ms): 572.1 | learning rate: 6.659013E-06 | global batch size:    64 | lm loss: 6.942100E+00 | loss scale: 1.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:22] iteration      801/    1000 | consumed samples:        51264 | elapsed time per iteration (ms): 571.7 | learning rate: 6.637315E-06 | global batch size:    64 | lm loss: 7.070765E+00 | loss scale: 1.0 | grad norm: 2.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:22] iteration      802/    1000 | consumed samples:        51328 | elapsed time per iteration (ms): 574.7 | learning rate: 6.615976E-06 | global batch size:    64 | lm loss: 6.869937E+00 | loss scale: 1.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:23] iteration      803/    1000 | consumed samples:        51392 | elapsed time per iteration (ms): 574.7 | learning rate: 6.594997E-06 | global batch size:    64 | lm loss: 6.950780E+00 | loss scale: 1.0 | grad norm: 1.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:23] iteration      804/    1000 | consumed samples:        51456 | elapsed time per iteration (ms): 574.4 | learning rate: 6.574376E-06 | global batch size:    64 | lm loss: 6.919470E+00 | loss scale: 1.0 | grad norm: 0.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:24] iteration      805/    1000 | consumed samples:        51520 | elapsed time per iteration (ms): 573.1 | learning rate: 6.554116E-06 | global batch size:    64 | lm loss: 6.849259E+00 | loss scale: 1.0 | grad norm: 0.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:25] iteration      806/    1000 | consumed samples:        51584 | elapsed time per iteration (ms): 573.3 | learning rate: 6.534216E-06 | global batch size:    64 | lm loss: 6.750214E+00 | loss scale: 1.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:25] iteration      807/    1000 | consumed samples:        51648 | elapsed time per iteration (ms): 572.8 | learning rate: 6.514676E-06 | global batch size:    64 | lm loss: 6.821174E+00 | loss scale: 1.0 | grad norm: 0.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:26] iteration      808/    1000 | consumed samples:        51712 | elapsed time per iteration (ms): 572.0 | learning rate: 6.495496E-06 | global batch size:    64 | lm loss: 6.937348E+00 | loss scale: 1.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:26] iteration      809/    1000 | consumed samples:        51776 | elapsed time per iteration (ms): 572.6 | learning rate: 6.476677E-06 | global batch size:    64 | lm loss: 7.017335E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:27] iteration      810/    1000 | consumed samples:        51840 | elapsed time per iteration (ms): 572.5 | learning rate: 6.458220E-06 | global batch size:    64 | lm loss: 6.976093E+00 | loss scale: 1.0 | grad norm: 0.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:27] iteration      811/    1000 | consumed samples:        51904 | elapsed time per iteration (ms): 572.4 | learning rate: 6.440124E-06 | global batch size:    64 | lm loss: 6.875061E+00 | loss scale: 1.0 | grad norm: 0.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:28] iteration      812/    1000 | consumed samples:        51968 | elapsed time per iteration (ms): 572.0 | learning rate: 6.422390E-06 | global batch size:    64 | lm loss: 6.762973E+00 | loss scale: 1.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:29] iteration      813/    1000 | consumed samples:        52032 | elapsed time per iteration (ms): 571.9 | learning rate: 6.405017E-06 | global batch size:    64 | lm loss: 6.880774E+00 | loss scale: 1.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:29] iteration      814/    1000 | consumed samples:        52096 | elapsed time per iteration (ms): 574.8 | learning rate: 6.388007E-06 | global batch size:    64 | lm loss: 6.839143E+00 | loss scale: 1.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:30] iteration      815/    1000 | consumed samples:        52160 | elapsed time per iteration (ms): 575.3 | learning rate: 6.371358E-06 | global batch size:    64 | lm loss: 6.819571E+00 | loss scale: 1.0 | grad norm: 0.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:30] iteration      816/    1000 | consumed samples:        52224 | elapsed time per iteration (ms): 573.5 | learning rate: 6.355073E-06 | global batch size:    64 | lm loss: 6.851063E+00 | loss scale: 1.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:31] iteration      817/    1000 | consumed samples:        52288 | elapsed time per iteration (ms): 571.4 | learning rate: 6.339150E-06 | global batch size:    64 | lm loss: 6.938902E+00 | loss scale: 1.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:31] iteration      818/    1000 | consumed samples:        52352 | elapsed time per iteration (ms): 574.0 | learning rate: 6.323590E-06 | global batch size:    64 | lm loss: 6.816165E+00 | loss scale: 1.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:32] iteration      819/    1000 | consumed samples:        52416 | elapsed time per iteration (ms): 574.5 | learning rate: 6.308393E-06 | global batch size:    64 | lm loss: 6.854779E+00 | loss scale: 1.0 | grad norm: 0.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:33] iteration      820/    1000 | consumed samples:        52480 | elapsed time per iteration (ms): 572.6 | learning rate: 6.293561E-06 | global batch size:    64 | lm loss: 6.907674E+00 | loss scale: 1.0 | grad norm: 0.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:33] iteration      821/    1000 | consumed samples:        52544 | elapsed time per iteration (ms): 572.3 | learning rate: 6.279091E-06 | global batch size:    64 | lm loss: 6.801591E+00 | loss scale: 1.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:34] iteration      822/    1000 | consumed samples:        52608 | elapsed time per iteration (ms): 572.4 | learning rate: 6.264985E-06 | global batch size:    64 | lm loss: 6.869106E+00 | loss scale: 1.0 | grad norm: 1.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:34] iteration      823/    1000 | consumed samples:        52672 | elapsed time per iteration (ms): 573.0 | learning rate: 6.251244E-06 | global batch size:    64 | lm loss: 6.877841E+00 | loss scale: 1.0 | grad norm: 1.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:35] iteration      824/    1000 | consumed samples:        52736 | elapsed time per iteration (ms): 571.3 | learning rate: 6.237866E-06 | global batch size:    64 | lm loss: 6.843092E+00 | loss scale: 1.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:35] iteration      825/    1000 | consumed samples:        52800 | elapsed time per iteration (ms): 572.6 | learning rate: 6.224853E-06 | global batch size:    64 | lm loss: 6.765574E+00 | loss scale: 1.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:36] iteration      826/    1000 | consumed samples:        52864 | elapsed time per iteration (ms): 573.6 | learning rate: 6.212204E-06 | global batch size:    64 | lm loss: 6.755085E+00 | loss scale: 1.0 | grad norm: 0.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:37] iteration      827/    1000 | consumed samples:        52928 | elapsed time per iteration (ms): 572.2 | learning rate: 6.199920E-06 | global batch size:    64 | lm loss: 6.916397E+00 | loss scale: 1.0 | grad norm: 1.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:37] iteration      828/    1000 | consumed samples:        52992 | elapsed time per iteration (ms): 577.2 | learning rate: 6.188001E-06 | global batch size:    64 | lm loss: 6.913103E+00 | loss scale: 1.0 | grad norm: 0.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:38] iteration      829/    1000 | consumed samples:        53056 | elapsed time per iteration (ms): 573.9 | learning rate: 6.176448E-06 | global batch size:    64 | lm loss: 6.990028E+00 | loss scale: 1.0 | grad norm: 0.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:38] iteration      830/    1000 | consumed samples:        53120 | elapsed time per iteration (ms): 573.2 | learning rate: 6.165259E-06 | global batch size:    64 | lm loss: 6.962235E+00 | loss scale: 1.0 | grad norm: 0.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:39] iteration      831/    1000 | consumed samples:        53184 | elapsed time per iteration (ms): 573.4 | learning rate: 6.154436E-06 | global batch size:    64 | lm loss: 6.912378E+00 | loss scale: 1.0 | grad norm: 0.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:39] iteration      832/    1000 | consumed samples:        53248 | elapsed time per iteration (ms): 573.2 | learning rate: 6.143978E-06 | global batch size:    64 | lm loss: 6.834008E+00 | loss scale: 1.0 | grad norm: 0.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:40] iteration      833/    1000 | consumed samples:        53312 | elapsed time per iteration (ms): 571.6 | learning rate: 6.133886E-06 | global batch size:    64 | lm loss: 6.913952E+00 | loss scale: 1.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:41] iteration      834/    1000 | consumed samples:        53376 | elapsed time per iteration (ms): 571.9 | learning rate: 6.124159E-06 | global batch size:    64 | lm loss: 6.843165E+00 | loss scale: 1.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:41] iteration      835/    1000 | consumed samples:        53440 | elapsed time per iteration (ms): 572.0 | learning rate: 6.114799E-06 | global batch size:    64 | lm loss: 6.704617E+00 | loss scale: 1.0 | grad norm: 0.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:42] iteration      836/    1000 | consumed samples:        53504 | elapsed time per iteration (ms): 572.4 | learning rate: 6.105804E-06 | global batch size:    64 | lm loss: 6.962509E+00 | loss scale: 1.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:42] iteration      837/    1000 | consumed samples:        53568 | elapsed time per iteration (ms): 572.3 | learning rate: 6.097177E-06 | global batch size:    64 | lm loss: 6.874334E+00 | loss scale: 1.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:43] iteration      838/    1000 | consumed samples:        53632 | elapsed time per iteration (ms): 572.2 | learning rate: 6.088915E-06 | global batch size:    64 | lm loss: 6.968664E+00 | loss scale: 1.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:43] iteration      839/    1000 | consumed samples:        53696 | elapsed time per iteration (ms): 572.1 | learning rate: 6.081019E-06 | global batch size:    64 | lm loss: 6.829715E+00 | loss scale: 1.0 | grad norm: 0.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:44] iteration      840/    1000 | consumed samples:        53760 | elapsed time per iteration (ms): 572.5 | learning rate: 6.073490E-06 | global batch size:    64 | lm loss: 6.724341E+00 | loss scale: 1.0 | grad norm: 0.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:45] iteration      841/    1000 | consumed samples:        53824 | elapsed time per iteration (ms): 572.7 | learning rate: 6.066328E-06 | global batch size:    64 | lm loss: 6.789851E+00 | loss scale: 1.0 | grad norm: 1.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:45] iteration      842/    1000 | consumed samples:        53888 | elapsed time per iteration (ms): 571.3 | learning rate: 6.059532E-06 | global batch size:    64 | lm loss: 6.766556E+00 | loss scale: 1.0 | grad norm: 0.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:46] iteration      843/    1000 | consumed samples:        53952 | elapsed time per iteration (ms): 574.4 | learning rate: 6.053103E-06 | global batch size:    64 | lm loss: 6.889353E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:46] iteration      844/    1000 | consumed samples:        54016 | elapsed time per iteration (ms): 575.6 | learning rate: 6.047042E-06 | global batch size:    64 | lm loss: 6.835626E+00 | loss scale: 1.0 | grad norm: 0.795 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:47] iteration      845/    1000 | consumed samples:        54080 | elapsed time per iteration (ms): 576.9 | learning rate: 6.041346E-06 | global batch size:    64 | lm loss: 6.787337E+00 | loss scale: 1.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:47] iteration      846/    1000 | consumed samples:        54144 | elapsed time per iteration (ms): 574.1 | learning rate: 6.036018E-06 | global batch size:    64 | lm loss: 6.795457E+00 | loss scale: 1.0 | grad norm: 0.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:48] iteration      847/    1000 | consumed samples:        54208 | elapsed time per iteration (ms): 572.1 | learning rate: 6.031058E-06 | global batch size:    64 | lm loss: 6.844342E+00 | loss scale: 1.0 | grad norm: 1.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:49] iteration      848/    1000 | consumed samples:        54272 | elapsed time per iteration (ms): 572.2 | learning rate: 6.026464E-06 | global batch size:    64 | lm loss: 6.876665E+00 | loss scale: 1.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:49] iteration      849/    1000 | consumed samples:        54336 | elapsed time per iteration (ms): 572.2 | learning rate: 6.022238E-06 | global batch size:    64 | lm loss: 6.813282E+00 | loss scale: 1.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:50] iteration      850/    1000 | consumed samples:        54400 | elapsed time per iteration (ms): 572.0 | learning rate: 6.018379E-06 | global batch size:    64 | lm loss: 6.907479E+00 | loss scale: 1.0 | grad norm: 0.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:50] iteration      851/    1000 | consumed samples:        54464 | elapsed time per iteration (ms): 571.9 | learning rate: 6.014887E-06 | global batch size:    64 | lm loss: 6.873754E+00 | loss scale: 1.0 | grad norm: 0.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:51] iteration      852/    1000 | consumed samples:        54528 | elapsed time per iteration (ms): 573.0 | learning rate: 6.011763E-06 | global batch size:    64 | lm loss: 6.912411E+00 | loss scale: 1.0 | grad norm: 0.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:52] iteration      853/    1000 | consumed samples:        54592 | elapsed time per iteration (ms): 573.0 | learning rate: 6.009006E-06 | global batch size:    64 | lm loss: 6.837519E+00 | loss scale: 1.0 | grad norm: 0.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:52] iteration      854/    1000 | consumed samples:        54656 | elapsed time per iteration (ms): 573.0 | learning rate: 6.006617E-06 | global batch size:    64 | lm loss: 6.965310E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:53] iteration      855/    1000 | consumed samples:        54720 | elapsed time per iteration (ms): 575.0 | learning rate: 6.004595E-06 | global batch size:    64 | lm loss: 6.832516E+00 | loss scale: 1.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:53] iteration      856/    1000 | consumed samples:        54784 | elapsed time per iteration (ms): 573.3 | learning rate: 6.002941E-06 | global batch size:    64 | lm loss: 6.897264E+00 | loss scale: 1.0 | grad norm: 0.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:54] iteration      857/    1000 | consumed samples:        54848 | elapsed time per iteration (ms): 572.0 | learning rate: 6.001654E-06 | global batch size:    64 | lm loss: 6.875136E+00 | loss scale: 1.0 | grad norm: 0.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:54] iteration      858/    1000 | consumed samples:        54912 | elapsed time per iteration (ms): 577.7 | learning rate: 6.000735E-06 | global batch size:    64 | lm loss: 6.857144E+00 | loss scale: 1.0 | grad norm: 0.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:55] iteration      859/    1000 | consumed samples:        54976 | elapsed time per iteration (ms): 571.9 | learning rate: 6.000184E-06 | global batch size:    64 | lm loss: 6.855719E+00 | loss scale: 1.0 | grad norm: 0.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:56] iteration      860/    1000 | consumed samples:        55040 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.865855E+00 | loss scale: 1.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:56] iteration      861/    1000 | consumed samples:        55104 | elapsed time per iteration (ms): 571.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.775424E+00 | loss scale: 1.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:57] iteration      862/    1000 | consumed samples:        55168 | elapsed time per iteration (ms): 572.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.854476E+00 | loss scale: 1.0 | grad norm: 0.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:57] iteration      863/    1000 | consumed samples:        55232 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.995156E+00 | loss scale: 1.0 | grad norm: 0.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:58] iteration      864/    1000 | consumed samples:        55296 | elapsed time per iteration (ms): 575.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.913671E+00 | loss scale: 1.0 | grad norm: 0.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:58] iteration      865/    1000 | consumed samples:        55360 | elapsed time per iteration (ms): 575.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.925228E+00 | loss scale: 1.0 | grad norm: 1.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:06:59] iteration      866/    1000 | consumed samples:        55424 | elapsed time per iteration (ms): 574.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.884448E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:00] iteration      867/    1000 | consumed samples:        55488 | elapsed time per iteration (ms): 571.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.820304E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:00] iteration      868/    1000 | consumed samples:        55552 | elapsed time per iteration (ms): 572.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.988505E+00 | loss scale: 1.0 | grad norm: 0.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:01] iteration      869/    1000 | consumed samples:        55616 | elapsed time per iteration (ms): 571.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.789683E+00 | loss scale: 1.0 | grad norm: 0.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:01] iteration      870/    1000 | consumed samples:        55680 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.950197E+00 | loss scale: 1.0 | grad norm: 1.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:02] iteration      871/    1000 | consumed samples:        55744 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.853168E+00 | loss scale: 1.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:02] iteration      872/    1000 | consumed samples:        55808 | elapsed time per iteration (ms): 572.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.899974E+00 | loss scale: 1.0 | grad norm: 0.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:03] iteration      873/    1000 | consumed samples:        55872 | elapsed time per iteration (ms): 572.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.790445E+00 | loss scale: 1.0 | grad norm: 1.218 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:04] iteration      874/    1000 | consumed samples:        55936 | elapsed time per iteration (ms): 571.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.879133E+00 | loss scale: 1.0 | grad norm: 0.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:04] iteration      875/    1000 | consumed samples:        56000 | elapsed time per iteration (ms): 572.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.859550E+00 | loss scale: 1.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:05] iteration      876/    1000 | consumed samples:        56064 | elapsed time per iteration (ms): 572.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.953911E+00 | loss scale: 1.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:05] iteration      877/    1000 | consumed samples:        56128 | elapsed time per iteration (ms): 571.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.905210E+00 | loss scale: 1.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:06] iteration      878/    1000 | consumed samples:        56192 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.890712E+00 | loss scale: 1.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:06] iteration      879/    1000 | consumed samples:        56256 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.881915E+00 | loss scale: 1.0 | grad norm: 0.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:07] iteration      880/    1000 | consumed samples:        56320 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.048547E+00 | loss scale: 1.0 | grad norm: 0.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:08] iteration      881/    1000 | consumed samples:        56384 | elapsed time per iteration (ms): 572.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.782342E+00 | loss scale: 1.0 | grad norm: 0.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:08] iteration      882/    1000 | consumed samples:        56448 | elapsed time per iteration (ms): 571.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.800546E+00 | loss scale: 1.0 | grad norm: 0.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:09] iteration      883/    1000 | consumed samples:        56512 | elapsed time per iteration (ms): 572.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.900536E+00 | loss scale: 1.0 | grad norm: 0.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:09] iteration      884/    1000 | consumed samples:        56576 | elapsed time per iteration (ms): 574.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.818955E+00 | loss scale: 1.0 | grad norm: 0.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:10] iteration      885/    1000 | consumed samples:        56640 | elapsed time per iteration (ms): 576.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.845206E+00 | loss scale: 1.0 | grad norm: 0.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:10] iteration      886/    1000 | consumed samples:        56704 | elapsed time per iteration (ms): 577.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.741704E+00 | loss scale: 1.0 | grad norm: 1.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:11] iteration      887/    1000 | consumed samples:        56768 | elapsed time per iteration (ms): 573.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.838834E+00 | loss scale: 1.0 | grad norm: 0.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:12] iteration      888/    1000 | consumed samples:        56832 | elapsed time per iteration (ms): 574.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.951637E+00 | loss scale: 1.0 | grad norm: 0.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:12] iteration      889/    1000 | consumed samples:        56896 | elapsed time per iteration (ms): 572.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.845475E+00 | loss scale: 1.0 | grad norm: 0.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:13] iteration      890/    1000 | consumed samples:        56960 | elapsed time per iteration (ms): 572.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.791308E+00 | loss scale: 1.0 | grad norm: 0.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:13] iteration      891/    1000 | consumed samples:        57024 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.834394E+00 | loss scale: 1.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:14] iteration      892/    1000 | consumed samples:        57088 | elapsed time per iteration (ms): 571.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.863573E+00 | loss scale: 1.0 | grad norm: 0.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:14] iteration      893/    1000 | consumed samples:        57152 | elapsed time per iteration (ms): 577.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.996076E+00 | loss scale: 1.0 | grad norm: 0.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:15] iteration      894/    1000 | consumed samples:        57216 | elapsed time per iteration (ms): 575.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.895008E+00 | loss scale: 1.0 | grad norm: 0.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:16] iteration      895/    1000 | consumed samples:        57280 | elapsed time per iteration (ms): 573.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.701585E+00 | loss scale: 1.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:16] iteration      896/    1000 | consumed samples:        57344 | elapsed time per iteration (ms): 574.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.818861E+00 | loss scale: 1.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:17] iteration      897/    1000 | consumed samples:        57408 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.929470E+00 | loss scale: 1.0 | grad norm: 0.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:17] iteration      898/    1000 | consumed samples:        57472 | elapsed time per iteration (ms): 575.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.904587E+00 | loss scale: 1.0 | grad norm: 0.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:18] iteration      899/    1000 | consumed samples:        57536 | elapsed time per iteration (ms): 575.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.850657E+00 | loss scale: 1.0 | grad norm: 0.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:18] iteration      900/    1000 | consumed samples:        57600 | elapsed time per iteration (ms): 572.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.820277E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:19] iteration      901/    1000 | consumed samples:        57664 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.866218E+00 | loss scale: 1.0 | grad norm: 0.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:20] iteration      902/    1000 | consumed samples:        57728 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.785452E+00 | loss scale: 1.0 | grad norm: 0.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:20] iteration      903/    1000 | consumed samples:        57792 | elapsed time per iteration (ms): 572.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.796647E+00 | loss scale: 1.0 | grad norm: 0.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:21] iteration      904/    1000 | consumed samples:        57856 | elapsed time per iteration (ms): 572.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.896352E+00 | loss scale: 1.0 | grad norm: 0.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:21] iteration      905/    1000 | consumed samples:        57920 | elapsed time per iteration (ms): 571.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.020618E+00 | loss scale: 1.0 | grad norm: 0.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:22] iteration      906/    1000 | consumed samples:        57984 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.885046E+00 | loss scale: 1.0 | grad norm: 0.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:22] iteration      907/    1000 | consumed samples:        58048 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.794010E+00 | loss scale: 1.0 | grad norm: 0.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:23] iteration      908/    1000 | consumed samples:        58112 | elapsed time per iteration (ms): 572.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.895487E+00 | loss scale: 1.0 | grad norm: 0.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:24] iteration      909/    1000 | consumed samples:        58176 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.992984E+00 | loss scale: 1.0 | grad norm: 0.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:24] iteration      910/    1000 | consumed samples:        58240 | elapsed time per iteration (ms): 572.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.924779E+00 | loss scale: 1.0 | grad norm: 0.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:25] iteration      911/    1000 | consumed samples:        58304 | elapsed time per iteration (ms): 574.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.825556E+00 | loss scale: 1.0 | grad norm: 0.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:25] iteration      912/    1000 | consumed samples:        58368 | elapsed time per iteration (ms): 573.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.896084E+00 | loss scale: 1.0 | grad norm: 0.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:26] iteration      913/    1000 | consumed samples:        58432 | elapsed time per iteration (ms): 574.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.864846E+00 | loss scale: 1.0 | grad norm: 0.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:26] iteration      914/    1000 | consumed samples:        58496 | elapsed time per iteration (ms): 574.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.017978E+00 | loss scale: 1.0 | grad norm: 0.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:27] iteration      915/    1000 | consumed samples:        58560 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.001158E+00 | loss scale: 1.0 | grad norm: 0.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:28] iteration      916/    1000 | consumed samples:        58624 | elapsed time per iteration (ms): 573.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.784133E+00 | loss scale: 1.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:28] iteration      917/    1000 | consumed samples:        58688 | elapsed time per iteration (ms): 571.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.856638E+00 | loss scale: 1.0 | grad norm: 0.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:29] iteration      918/    1000 | consumed samples:        58752 | elapsed time per iteration (ms): 572.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.691690E+00 | loss scale: 1.0 | grad norm: 1.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:29] iteration      919/    1000 | consumed samples:        58816 | elapsed time per iteration (ms): 572.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.860441E+00 | loss scale: 1.0 | grad norm: 0.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:30] iteration      920/    1000 | consumed samples:        58880 | elapsed time per iteration (ms): 573.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.909411E+00 | loss scale: 1.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:30] iteration      921/    1000 | consumed samples:        58944 | elapsed time per iteration (ms): 571.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.714221E+00 | loss scale: 1.0 | grad norm: 0.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:31] iteration      922/    1000 | consumed samples:        59008 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.827231E+00 | loss scale: 1.0 | grad norm: 0.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:32] iteration      923/    1000 | consumed samples:        59072 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.792118E+00 | loss scale: 1.0 | grad norm: 1.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:32] iteration      924/    1000 | consumed samples:        59136 | elapsed time per iteration (ms): 573.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.777743E+00 | loss scale: 1.0 | grad norm: 0.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:33] iteration      925/    1000 | consumed samples:        59200 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.980189E+00 | loss scale: 1.0 | grad norm: 0.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:33] iteration      926/    1000 | consumed samples:        59264 | elapsed time per iteration (ms): 570.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.825654E+00 | loss scale: 1.0 | grad norm: 0.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:34] iteration      927/    1000 | consumed samples:        59328 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.847474E+00 | loss scale: 1.0 | grad norm: 0.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:34] iteration      928/    1000 | consumed samples:        59392 | elapsed time per iteration (ms): 572.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.959472E+00 | loss scale: 1.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:35] iteration      929/    1000 | consumed samples:        59456 | elapsed time per iteration (ms): 571.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.829299E+00 | loss scale: 1.0 | grad norm: 0.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:36] iteration      930/    1000 | consumed samples:        59520 | elapsed time per iteration (ms): 578.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.780760E+00 | loss scale: 1.0 | grad norm: 1.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:36] iteration      931/    1000 | consumed samples:        59584 | elapsed time per iteration (ms): 576.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.887944E+00 | loss scale: 1.0 | grad norm: 0.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:37] iteration      932/    1000 | consumed samples:        59648 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.837282E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:37] iteration      933/    1000 | consumed samples:        59712 | elapsed time per iteration (ms): 571.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.737016E+00 | loss scale: 1.0 | grad norm: 0.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:38] iteration      934/    1000 | consumed samples:        59776 | elapsed time per iteration (ms): 571.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.822821E+00 | loss scale: 1.0 | grad norm: 0.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:39] iteration      935/    1000 | consumed samples:        59840 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.912383E+00 | loss scale: 1.0 | grad norm: 0.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:39] iteration      936/    1000 | consumed samples:        59904 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.894133E+00 | loss scale: 1.0 | grad norm: 0.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:40] iteration      937/    1000 | consumed samples:        59968 | elapsed time per iteration (ms): 572.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.886798E+00 | loss scale: 1.0 | grad norm: 0.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:40] iteration      938/    1000 | consumed samples:        60032 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.863983E+00 | loss scale: 1.0 | grad norm: 0.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:41] iteration      939/    1000 | consumed samples:        60096 | elapsed time per iteration (ms): 572.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.748031E+00 | loss scale: 1.0 | grad norm: 0.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:41] iteration      940/    1000 | consumed samples:        60160 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.932798E+00 | loss scale: 1.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:42] iteration      941/    1000 | consumed samples:        60224 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.036179E+00 | loss scale: 1.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:43] iteration      942/    1000 | consumed samples:        60288 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.909996E+00 | loss scale: 1.0 | grad norm: 0.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:43] iteration      943/    1000 | consumed samples:        60352 | elapsed time per iteration (ms): 573.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.888575E+00 | loss scale: 1.0 | grad norm: 1.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:44] iteration      944/    1000 | consumed samples:        60416 | elapsed time per iteration (ms): 571.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.844439E+00 | loss scale: 1.0 | grad norm: 0.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:44] iteration      945/    1000 | consumed samples:        60480 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.964769E+00 | loss scale: 1.0 | grad norm: 1.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:45] iteration      946/    1000 | consumed samples:        60544 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.912455E+00 | loss scale: 1.0 | grad norm: 0.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:45] iteration      947/    1000 | consumed samples:        60608 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.778695E+00 | loss scale: 1.0 | grad norm: 1.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:46] iteration      948/    1000 | consumed samples:        60672 | elapsed time per iteration (ms): 571.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.845216E+00 | loss scale: 1.0 | grad norm: 0.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:47] iteration      949/    1000 | consumed samples:        60736 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.926582E+00 | loss scale: 1.0 | grad norm: 0.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:47] iteration      950/    1000 | consumed samples:        60800 | elapsed time per iteration (ms): 573.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.859403E+00 | loss scale: 1.0 | grad norm: 1.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:48] iteration      951/    1000 | consumed samples:        60864 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.898248E+00 | loss scale: 1.0 | grad norm: 0.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:48] iteration      952/    1000 | consumed samples:        60928 | elapsed time per iteration (ms): 572.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.763664E+00 | loss scale: 1.0 | grad norm: 1.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:49] iteration      953/    1000 | consumed samples:        60992 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.950638E+00 | loss scale: 1.0 | grad norm: 0.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:49] iteration      954/    1000 | consumed samples:        61056 | elapsed time per iteration (ms): 574.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.937171E+00 | loss scale: 1.0 | grad norm: 1.241 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:50] iteration      955/    1000 | consumed samples:        61120 | elapsed time per iteration (ms): 571.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.820804E+00 | loss scale: 1.0 | grad norm: 0.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:51] iteration      956/    1000 | consumed samples:        61184 | elapsed time per iteration (ms): 572.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.871260E+00 | loss scale: 1.0 | grad norm: 0.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:51] iteration      957/    1000 | consumed samples:        61248 | elapsed time per iteration (ms): 570.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.829557E+00 | loss scale: 1.0 | grad norm: 0.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:52] iteration      958/    1000 | consumed samples:        61312 | elapsed time per iteration (ms): 573.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.862446E+00 | loss scale: 1.0 | grad norm: 0.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:52] iteration      959/    1000 | consumed samples:        61376 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.991190E+00 | loss scale: 1.0 | grad norm: 0.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:53] iteration      960/    1000 | consumed samples:        61440 | elapsed time per iteration (ms): 573.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.972972E+00 | loss scale: 1.0 | grad norm: 0.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:53] iteration      961/    1000 | consumed samples:        61504 | elapsed time per iteration (ms): 574.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.854967E+00 | loss scale: 1.0 | grad norm: 0.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:54] iteration      962/    1000 | consumed samples:        61568 | elapsed time per iteration (ms): 573.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.809289E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:55] iteration      963/    1000 | consumed samples:        61632 | elapsed time per iteration (ms): 573.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.003492E+00 | loss scale: 1.0 | grad norm: 0.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:55] iteration      964/    1000 | consumed samples:        61696 | elapsed time per iteration (ms): 573.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.821235E+00 | loss scale: 1.0 | grad norm: 0.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:56] iteration      965/    1000 | consumed samples:        61760 | elapsed time per iteration (ms): 574.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.032044E+00 | loss scale: 1.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:56] iteration      966/    1000 | consumed samples:        61824 | elapsed time per iteration (ms): 573.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.960375E+00 | loss scale: 1.0 | grad norm: 0.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:57] iteration      967/    1000 | consumed samples:        61888 | elapsed time per iteration (ms): 573.9 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.894216E+00 | loss scale: 1.0 | grad norm: 0.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:57] iteration      968/    1000 | consumed samples:        61952 | elapsed time per iteration (ms): 573.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.870987E+00 | loss scale: 1.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:58] iteration      969/    1000 | consumed samples:        62016 | elapsed time per iteration (ms): 572.0 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.884392E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:59] iteration      970/    1000 | consumed samples:        62080 | elapsed time per iteration (ms): 572.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.823577E+00 | loss scale: 1.0 | grad norm: 1.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:07:59] iteration      971/    1000 | consumed samples:        62144 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.867432E+00 | loss scale: 1.0 | grad norm: 0.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:00] iteration      972/    1000 | consumed samples:        62208 | elapsed time per iteration (ms): 572.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.930151E+00 | loss scale: 1.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:00] iteration      973/    1000 | consumed samples:        62272 | elapsed time per iteration (ms): 572.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.904325E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:01] iteration      974/    1000 | consumed samples:        62336 | elapsed time per iteration (ms): 572.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.041775E+00 | loss scale: 1.0 | grad norm: 0.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:01] iteration      975/    1000 | consumed samples:        62400 | elapsed time per iteration (ms): 574.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.813204E+00 | loss scale: 1.0 | grad norm: 0.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:02] iteration      976/    1000 | consumed samples:        62464 | elapsed time per iteration (ms): 573.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.805802E+00 | loss scale: 1.0 | grad norm: 0.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:03] iteration      977/    1000 | consumed samples:        62528 | elapsed time per iteration (ms): 573.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.887094E+00 | loss scale: 1.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:03] iteration      978/    1000 | consumed samples:        62592 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.879882E+00 | loss scale: 1.0 | grad norm: 0.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:04] iteration      979/    1000 | consumed samples:        62656 | elapsed time per iteration (ms): 572.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.888538E+00 | loss scale: 1.0 | grad norm: 0.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:04] iteration      980/    1000 | consumed samples:        62720 | elapsed time per iteration (ms): 573.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.898946E+00 | loss scale: 1.0 | grad norm: 0.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:05] iteration      981/    1000 | consumed samples:        62784 | elapsed time per iteration (ms): 571.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.887163E+00 | loss scale: 1.0 | grad norm: 0.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:05] iteration      982/    1000 | consumed samples:        62848 | elapsed time per iteration (ms): 574.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.860919E+00 | loss scale: 1.0 | grad norm: 0.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:06] iteration      983/    1000 | consumed samples:        62912 | elapsed time per iteration (ms): 576.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.737216E+00 | loss scale: 1.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:07] iteration      984/    1000 | consumed samples:        62976 | elapsed time per iteration (ms): 574.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.863385E+00 | loss scale: 1.0 | grad norm: 0.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:07] iteration      985/    1000 | consumed samples:        63040 | elapsed time per iteration (ms): 573.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.795630E+00 | loss scale: 1.0 | grad norm: 0.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:08] iteration      986/    1000 | consumed samples:        63104 | elapsed time per iteration (ms): 572.3 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 7.024211E+00 | loss scale: 1.0 | grad norm: 0.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:08] iteration      987/    1000 | consumed samples:        63168 | elapsed time per iteration (ms): 572.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.867089E+00 | loss scale: 1.0 | grad norm: 0.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:09] iteration      988/    1000 | consumed samples:        63232 | elapsed time per iteration (ms): 573.8 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.952852E+00 | loss scale: 1.0 | grad norm: 0.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:09] iteration      989/    1000 | consumed samples:        63296 | elapsed time per iteration (ms): 576.2 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.880599E+00 | loss scale: 1.0 | grad norm: 0.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:10] iteration      990/    1000 | consumed samples:        63360 | elapsed time per iteration (ms): 574.6 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.870563E+00 | loss scale: 1.0 | grad norm: 0.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:11] iteration      991/    1000 | consumed samples:        63424 | elapsed time per iteration (ms): 573.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.755864E+00 | loss scale: 1.0 | grad norm: 0.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:11] iteration      992/    1000 | consumed samples:        63488 | elapsed time per iteration (ms): 573.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.841795E+00 | loss scale: 1.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:12] iteration      993/    1000 | consumed samples:        63552 | elapsed time per iteration (ms): 573.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.817111E+00 | loss scale: 1.0 | grad norm: 0.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:12] iteration      994/    1000 | consumed samples:        63616 | elapsed time per iteration (ms): 573.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.878471E+00 | loss scale: 1.0 | grad norm: 0.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:13] iteration      995/    1000 | consumed samples:        63680 | elapsed time per iteration (ms): 574.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.809060E+00 | loss scale: 1.0 | grad norm: 0.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:13] iteration      996/    1000 | consumed samples:        63744 | elapsed time per iteration (ms): 573.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.808034E+00 | loss scale: 1.0 | grad norm: 0.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:14] iteration      997/    1000 | consumed samples:        63808 | elapsed time per iteration (ms): 574.5 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.857858E+00 | loss scale: 1.0 | grad norm: 0.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:15] iteration      998/    1000 | consumed samples:        63872 | elapsed time per iteration (ms): 573.1 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.849223E+00 | loss scale: 1.0 | grad norm: 0.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:15] iteration      999/    1000 | consumed samples:        63936 | elapsed time per iteration (ms): 575.4 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.812792E+00 | loss scale: 1.0 | grad norm: 0.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 [2025-06-16 08:08:16] iteration     1000/    1000 | consumed samples:        64000 | elapsed time per iteration (ms): 574.7 | learning rate: 6.000000E-06 | global batch size:    64 | lm loss: 6.904909E+00 | loss scale: 1.0 | grad norm: 0.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
(min, max) time across ranks (ms):
    evaluate .......................................: (9444.72, 9444.72)
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 6.816518E+00 | lm loss PPL: 9.128014E+02 | 
------------------------------------------------------------------------------------------------
saving checkpoint at iteration    1000 to /users/jimmys2/ckpt in torch_dist format
  successfully saved checkpoint from iteration    1000 to /users/jimmys2/ckpt [ t 1/1, p 1/1 ]
(min, max) time across ranks (ms):
    save-checkpoint ................................: (1843.94, 1843.94)
[after training is done] datetime: 2025-06-16 08:08:27 
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
Evaluating on 2560 samples
Evaluating iter 1/40
Evaluating iter 2/40
Evaluating iter 3/40
Evaluating iter 4/40
Evaluating iter 5/40
Evaluating iter 6/40
Evaluating iter 7/40
Evaluating iter 8/40
Evaluating iter 9/40
Evaluating iter 10/40
Evaluating iter 11/40
Evaluating iter 12/40
Evaluating iter 13/40
Evaluating iter 14/40
Evaluating iter 15/40
Evaluating iter 16/40
Evaluating iter 17/40
Evaluating iter 18/40
Evaluating iter 19/40
Evaluating iter 20/40
Evaluating iter 21/40
Evaluating iter 22/40
Evaluating iter 23/40
Evaluating iter 24/40
Evaluating iter 25/40
Evaluating iter 26/40
Evaluating iter 27/40
Evaluating iter 28/40
Evaluating iter 29/40
Evaluating iter 30/40
Evaluating iter 31/40
Evaluating iter 32/40
Evaluating iter 33/40
Evaluating iter 34/40
Evaluating iter 35/40
Evaluating iter 36/40
Evaluating iter 37/40
Evaluating iter 38/40
Evaluating iter 39/40
Evaluating iter 40/40
(min, max) time across ranks (ms):
    evaluate .......................................: (9734.43, 9734.43)
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
WARNING:megatron.core.rerun_state_machine:Setting RerunStateMachine mode RerunMode.DISABLED
------------------------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 on validation set | lm loss value: 6.812697E+00 | lm loss PPL: 9.093203E+02 | 
------------------------------------------------------------------------------------------------------------------
